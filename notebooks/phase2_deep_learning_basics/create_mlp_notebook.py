#!/usr/bin/env python3
"""
–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞: Multi-Layer Perceptron (MLP) –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
Phase 2, Step 1: Deep Learning Basics
"""

import json

# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–æ—É—Ç–±—É–∫–∞
notebook = {
    "cells": [],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

cells = []

# ============================================================================
# TITLE
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "# üß† Multi-Layer Perceptron (MLP) –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "**Phase 2: Deep Learning Basics - Step 1**\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ –¶–µ–ª–∏ –Ω–æ—É—Ç–±—É–∫–∞\n",
        "\n",
        "1. **–ü–æ–Ω—è—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É MLP** –∏ backpropagation\n",
        "2. **–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å MLP –Ω–∞ PyTorch** –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "3. **–°—Ä–∞–≤–Ω–∏—Ç—å —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏** (XGBoost –∏–∑ Phase 1)\n",
        "4. **–ò–∑—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:** dropout, batch normalization, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã\n",
        "5. **–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:** learning rate, batch size, epochs, architecture\n",
        "\n",
        "---\n",
        "\n",
        "## üíº –ë–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–∞: Titanic Survival Prediction\n",
        "\n",
        "**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –¢–∏—Ç–∞–Ω–∏–∫–∞.\n",
        "\n",
        "**–ü–æ—á–µ–º—É MLP –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö?**\n",
        "- üìä **–ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** MLP –º–æ–∂–µ—Ç –∑–∞—Ö–≤–∞—Ç–∏—Ç—å —Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
        "- üîó **Feature interactions:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏\n",
        "- üß™ **–ê–Ω—Å–∞–º–±–ª–∏:** MLP + Gradient Boosting —á–∞—Å—Ç–æ –ª—É—á—à–µ\n",
        "\n",
        "**–ß–µ—Å—Ç–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ:**\n",
        "- ‚ùå **MLP –æ–±—ã—á–Ω–æ –•–£–ñ–ï XGBoost** –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "- ‚úÖ **–ù–æ:** –ø–æ–ª–µ–∑–µ–Ω –≤ –∞–Ω—Å–∞–º–±–ª—è—Ö –∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Deep Learning\n",
        "- ‚úÖ **–¶–µ–ª—å:** –ü–æ–Ω—è—Ç—å –æ—Å–Ω–æ–≤—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω—ã –¥–ª—è CNN, RNN, Transformers\n",
        "\n",
        "---"
    ]
})

# ============================================================================
# THEORY PART 1: WHAT IS MLP
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "## üìö –ß–∞—Å—Ç—å 1: –¢–µ–æ—Ä–∏—è Multi-Layer Perceptron\n",
        "\n",
        "### 1.1 –ß—Ç–æ —Ç–∞–∫–æ–µ MLP?\n",
        "\n",
        "**Multi-Layer Perceptron (MLP)** ‚Äî —ç—Ç–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è (fully-connected) –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å.\n",
        "\n",
        "#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
        "\n",
        "**–°–ª–æ–∏:**\n",
        "1. **Input Layer:** –í—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Age, Sex, Fare –¥–ª—è –¢–∏—Ç–∞–Ω–∏–∫–∞)\n",
        "2. **Hidden Layers:** –û–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤\n",
        "3. **Output Layer:** –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (1 –Ω–µ–π—Ä–æ–Ω –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)\n",
        "\n",
        "**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:**\n",
        "\n",
        "–î–ª—è —Å–ª–æ—è $l$:\n",
        "\n",
        "$$z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}$$\n",
        "\n",
        "$$a^{(l)} = \\sigma(z^{(l)})$$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $W^{(l)}$ ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ —Å–ª–æ—è $l$\n",
        "- $b^{(l)}$ ‚Äî –≤–µ–∫—Ç–æ—Ä bias\n",
        "- $a^{(l-1)}$ ‚Äî –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–ª–æ—è\n",
        "- $\\sigma$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
        "\n",
        "**–ü–æ–ª–Ω–∞—è forward pass:**\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "a^{(0)} &= x \\quad \\text{(input)} \\\\\n",
        "z^{(1)} &= W^{(1)} a^{(0)} + b^{(1)} \\\\\n",
        "a^{(1)} &= \\sigma(z^{(1)}) \\\\\n",
        "z^{(2)} &= W^{(2)} a^{(1)} + b^{(2)} \\\\\n",
        "a^{(2)} &= \\sigma(z^{(2)}) \\quad \\text{(output)}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "---"
    ]
})

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ
notebook['cells'] = cells

output_path = '/home/user/test/notebooks/phase2_deep_learning_basics/01_mlp_basics.ipynb'
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f'‚úÖ –°–æ–∑–¥–∞–Ω –Ω–æ—É—Ç–±—É–∫: {output_path}')
print(f'–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ —è—á–µ–π–∫–∏: {len(cells)}')
