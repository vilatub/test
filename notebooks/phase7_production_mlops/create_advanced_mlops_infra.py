#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è notebook –ø–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π MLOps –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ.
–ú–µ—Ç–æ–¥—ã: Kubernetes deployment, Feature Store, Data Drift Detection
"""

import nbformat as nbf

def create_notebook():
    nb = nbf.v4.new_notebook()
    cells = []

    # Cell 1: –ó–∞–≥–æ–ª–æ–≤–æ–∫
    cells.append(nbf.v4.new_markdown_cell("""# –§–∞–∑–∞ 7.3: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è MLOps –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞

## Kubernetes, Feature Store –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞

–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ MLOps:

### –¢–µ–º—ã

1. **Kubernetes Deployment** - –º–∞–Ω–∏—Ñ–µ—Å—Ç—ã –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è ML-–º–æ–¥–µ–ª–µ–π –≤ K8s
2. **Feature Store** - –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
3. **Data Drift Detection** - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö (—Å—Ç–∏–ª—å Evidently)

### –ó–∞–¥–∞—á–∞

–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É —Å –º–æ–¥–µ–ª—å—é –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ (Customer Churn) –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫:
- –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –º–æ–¥–µ–ª—å –≤ Kubernetes
- –û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –¥—Ä–∏—Ñ—Ç–∞

### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å

–≠—Ç–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è production-ready ML —Å–∏—Å—Ç–µ–º, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å, –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ."""))

    # Cell 2: –ò–º–ø–æ—Ä—Ç—ã
    cells.append(nbf.v4.new_code_cell("""import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score
from scipy import stats
from datetime import datetime, timedelta
import json
import yaml
import warnings
warnings.filterwarnings('ignore')

np.random.seed(42)

print("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")"""))

    # Cell 3: –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    cells.append(nbf.v4.new_code_cell("""# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)
def create_churn_data(n_samples=10000, drift=False, drift_magnitude=0.3):
    \"\"\"
    –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ—Ç—Ç–æ–∫–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    n_samples : int
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤
    drift : bool
        –î–æ–±–∞–≤–∏—Ç—å –ª–∏ –¥—Ä–∏—Ñ—Ç –≤ –¥–∞–Ω–Ω—ã–µ
    drift_magnitude : float
        –°–∏–ª–∞ –¥—Ä–∏—Ñ—Ç–∞

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    -----------
    DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤
    \"\"\"
    # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    data = {
        'customer_id': range(1, n_samples + 1),
        'tenure_months': np.random.randint(1, 72, n_samples),
        'monthly_charges': np.random.uniform(20, 100, n_samples),
        'total_charges': np.zeros(n_samples),
        'num_support_tickets': np.random.poisson(2, n_samples),
        'num_referrals': np.random.poisson(1, n_samples),
        'contract_type': np.random.choice(['Month-to-month', 'One year', 'Two year'],
                                          n_samples, p=[0.5, 0.3, 0.2]),
        'payment_method': np.random.choice(['Electronic', 'Mailed', 'Bank', 'Credit'],
                                           n_samples),
        'internet_service': np.random.choice(['DSL', 'Fiber', 'No'],
                                             n_samples, p=[0.35, 0.45, 0.2]),
    }

    # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä–∏—Ñ—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if drift:
        # –î—Ä–∏—Ñ—Ç: —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ü–µ–Ω –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–∏–∫–µ—Ç–æ–≤
        data['monthly_charges'] *= (1 + drift_magnitude)
        data['num_support_tickets'] = np.random.poisson(3.5, n_samples)
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤
        data['contract_type'] = np.random.choice(
            ['Month-to-month', 'One year', 'Two year'],
            n_samples, p=[0.65, 0.25, 0.10]
        )

    # –í—ã—á–∏—Å–ª—è–µ–º total_charges
    data['total_charges'] = data['tenure_months'] * data['monthly_charges'] * \\
                            np.random.uniform(0.9, 1.1, n_samples)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—Ç–æ–∫
    churn_prob = 0.1 + \\
        0.3 * (np.array([1 if c == 'Month-to-month' else 0 for c in data['contract_type']])) + \\
        0.1 * (data['tenure_months'] < 12) / 12 + \\
        0.1 * (data['num_support_tickets'] > 3) + \\
        0.1 * (data['monthly_charges'] > 70)

    churn_prob = np.clip(churn_prob, 0, 1)
    data['churned'] = np.random.binomial(1, churn_prob)

    df = pd.DataFrame(data)
    return df

# –°–æ–∑–¥–∞—ë–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –¥–∞–Ω–Ω—ã–µ —Å –¥—Ä–∏—Ñ—Ç–æ–º
df_train = create_churn_data(n_samples=10000, drift=False)
df_production = create_churn_data(n_samples=3000, drift=True, drift_magnitude=0.3)

print(f"–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ: {df_train.shape}")
print(f"Production –¥–∞–Ω–Ω—ã–µ (—Å –¥—Ä–∏—Ñ—Ç–æ–º): {df_production.shape}")
print(f"\\n–û—Ç—Ç–æ–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏: {df_train['churned'].mean()*100:.1f}%")
print(f"–û—Ç—Ç–æ–∫ –≤ production: {df_production['churned'].mean()*100:.1f}%")"""))

    # Cell 4: Kubernetes –≤–≤–µ–¥–µ–Ω–∏–µ
    cells.append(nbf.v4.new_markdown_cell("""## 1. Kubernetes Deployment

### –ß—Ç–æ —Ç–∞–∫–æ–µ Kubernetes?

Kubernetes (K8s) - —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä–∞—è:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
- –£–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ–º –∏ –æ—Ç–∫–∞—Ç–æ–º

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è ML

1. **Deployment** - –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∂–µ–ª–∞–µ–º–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
2. **Service** - –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–µ—Ç–µ–≤–æ–π –¥–æ—Å—Ç—É–ø
3. **ConfigMap** - —Ö—Ä–∞–Ω–∏—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
4. **Secret** - —Ö—Ä–∞–Ω–∏—Ç sensitive –¥–∞–Ω–Ω—ã–µ
5. **HorizontalPodAutoscaler** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –¥–ª—è ML

- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–ø–ª–∏–∫–∏ –ø—Ä–∏ –Ω–∞–≥—Ä—É–∑–∫–µ
- **–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å** - –æ–∫—Ä—É–∂–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–æ –≤ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞—Ö
- **–ò–∑–æ–ª—è—Ü–∏—è** - –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –≤ —Å–≤–æ—ë–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
- **Rolling updates** - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑ –ø—Ä–æ—Å—Ç–æ—è"""))

    # Cell 5: Kubernetes –º–∞–Ω–∏—Ñ–µ—Å—Ç—ã
    cells.append(nbf.v4.new_code_cell("""# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Kubernetes –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏

def generate_k8s_manifests(model_name, image, replicas=3, cpu_limit='500m', memory_limit='512Mi'):
    \"\"\"
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Kubernetes –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è ML –º–æ–¥–µ–ª–∏.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    model_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    image : str
        Docker –æ–±—Ä–∞–∑
    replicas : int
        –ß–∏—Å–ª–æ —Ä–µ–ø–ª–∏–∫
    cpu_limit : str
        –õ–∏–º–∏—Ç CPU
    memory_limit : str
        –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    -----------
    dict —Å –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞–º–∏
    \"\"\"

    # 1. Deployment
    deployment = {
        'apiVersion': 'apps/v1',
        'kind': 'Deployment',
        'metadata': {
            'name': f'{model_name}-deployment',
            'labels': {
                'app': model_name,
                'version': 'v1'
            }
        },
        'spec': {
            'replicas': replicas,
            'selector': {
                'matchLabels': {
                    'app': model_name
                }
            },
            'template': {
                'metadata': {
                    'labels': {
                        'app': model_name,
                        'version': 'v1'
                    },
                    'annotations': {
                        'prometheus.io/scrape': 'true',
                        'prometheus.io/port': '8000'
                    }
                },
                'spec': {
                    'containers': [{
                        'name': model_name,
                        'image': image,
                        'ports': [{'containerPort': 8000}],
                        'resources': {
                            'requests': {
                                'cpu': '100m',
                                'memory': '256Mi'
                            },
                            'limits': {
                                'cpu': cpu_limit,
                                'memory': memory_limit
                            }
                        },
                        'env': [
                            {'name': 'MODEL_NAME', 'value': model_name},
                            {'name': 'LOG_LEVEL', 'value': 'INFO'}
                        ],
                        'livenessProbe': {
                            'httpGet': {
                                'path': '/health',
                                'port': 8000
                            },
                            'initialDelaySeconds': 30,
                            'periodSeconds': 10
                        },
                        'readinessProbe': {
                            'httpGet': {
                                'path': '/ready',
                                'port': 8000
                            },
                            'initialDelaySeconds': 5,
                            'periodSeconds': 5
                        }
                    }]
                }
            }
        }
    }

    # 2. Service
    service = {
        'apiVersion': 'v1',
        'kind': 'Service',
        'metadata': {
            'name': f'{model_name}-service'
        },
        'spec': {
            'selector': {
                'app': model_name
            },
            'ports': [{
                'protocol': 'TCP',
                'port': 80,
                'targetPort': 8000
            }],
            'type': 'ClusterIP'
        }
    }

    # 3. HorizontalPodAutoscaler
    hpa = {
        'apiVersion': 'autoscaling/v2',
        'kind': 'HorizontalPodAutoscaler',
        'metadata': {
            'name': f'{model_name}-hpa'
        },
        'spec': {
            'scaleTargetRef': {
                'apiVersion': 'apps/v1',
                'kind': 'Deployment',
                'name': f'{model_name}-deployment'
            },
            'minReplicas': 2,
            'maxReplicas': 10,
            'metrics': [{
                'type': 'Resource',
                'resource': {
                    'name': 'cpu',
                    'target': {
                        'type': 'Utilization',
                        'averageUtilization': 70
                    }
                }
            }]
        }
    }

    # 4. ConfigMap –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
    configmap = {
        'apiVersion': 'v1',
        'kind': 'ConfigMap',
        'metadata': {
            'name': f'{model_name}-config'
        },
        'data': {
            'model_config.yaml': yaml.dump({
                'model_name': model_name,
                'version': 'v1',
                'threshold': 0.5,
                'features': ['tenure_months', 'monthly_charges', 'total_charges',
                            'num_support_tickets', 'contract_type']
            })
        }
    }

    return {
        'deployment': deployment,
        'service': service,
        'hpa': hpa,
        'configmap': configmap
    }

# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç—ã
manifests = generate_k8s_manifests(
    model_name='churn-predictor',
    image='ml-registry/churn-model:v1.0',
    replicas=3
)

print("Kubernetes Deployment –º–∞–Ω–∏—Ñ–µ—Å—Ç:")
print("=" * 50)
print(yaml.dump(manifests['deployment'], default_flow_style=False))"""))

    # Cell 6: –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç—ã
    cells.append(nbf.v4.new_code_cell("""# Service –º–∞–Ω–∏—Ñ–µ—Å—Ç
print("Kubernetes Service –º–∞–Ω–∏—Ñ–µ—Å—Ç:")
print("=" * 50)
print(yaml.dump(manifests['service'], default_flow_style=False))

print("\\nHorizontalPodAutoscaler –º–∞–Ω–∏—Ñ–µ—Å—Ç:")
print("=" * 50)
print(yaml.dump(manifests['hpa'], default_flow_style=False))"""))

    # Cell 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤
    cells.append(nbf.v4.new_code_cell("""# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –≤ —Ñ–∞–π–ª—ã
import os

k8s_dir = '/home/user/test/notebooks/phase7_production_mlops/k8s'
os.makedirs(k8s_dir, exist_ok=True)

for name, manifest in manifests.items():
    filepath = os.path.join(k8s_dir, f'{name}.yaml')
    with open(filepath, 'w') as f:
        yaml.dump(manifest, f, default_flow_style=False)
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")

print("\\n–ö–æ–º–∞–Ω–¥—ã –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è:")
print("kubectl apply -f k8s/")
print("kubectl get pods -l app=churn-predictor")
print("kubectl get hpa")"""))

    # Cell 8: Feature Store –≤–≤–µ–¥–µ–Ω–∏–µ
    cells.append(nbf.v4.new_markdown_cell("""## 2. Feature Store

### –ß—Ç–æ —Ç–∞–∫–æ–µ Feature Store?

Feature Store - —ç—Ç–æ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML, –∫–æ—Ç–æ—Ä–æ–µ:
- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
- –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –æ–±—É—á–µ–Ω–∏–µ–º –∏ inference
- –í–µ—Ä—Å–∏–æ–Ω–∏—Ä—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏
- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç point-in-time –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

1. **Feature Registry** - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
2. **Offline Store** - –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
3. **Online Store** - –Ω–∏–∑–∫–æ–ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è inference
4. **Feature Transformation** - –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞

- **–ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ** - –æ–¥–Ω–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–Ω–æ–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
- **–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å** - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ train –∏ serve
- **–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º

–ú—ã —Ä–µ–∞–ª–∏–∑—É–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é Feature Store."""))

    # Cell 9: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Feature Store
    cells.append(nbf.v4.new_code_cell("""class SimpleFeatureStore:
    \"\"\"
    –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Feature Store.

    –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:
    - –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    - –•—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    - –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è inference
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    \"\"\"

    def __init__(self):
        self.feature_registry = {}  # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        self.offline_store = {}     # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        self.online_store = {}      # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        self.statistics = {}        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

    def register_feature(self, name, dtype, description, transformation=None):
        \"\"\"
        –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        ----------
        name : str
            –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞
        dtype : str
            –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö
        description : str
            –û–ø–∏—Å–∞–Ω–∏–µ
        transformation : callable
            –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        \"\"\"
        self.feature_registry[name] = {
            'name': name,
            'dtype': dtype,
            'description': description,
            'transformation': transformation,
            'created_at': datetime.now().isoformat(),
            'version': 1
        }

        self.offline_store[name] = []
        self.online_store[name] = {}
        self.statistics[name] = {
            'count': 0,
            'mean': 0,
            'std': 0,
            'min': float('inf'),
            'max': float('-inf')
        }

        print(f"–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: {name}")

    def ingest(self, entity_id, features, timestamp=None):
        \"\"\"
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        ----------
        entity_id : str/int
            ID —Å—É—â–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, customer_id)
        features : dict
            –°–ª–æ–≤–∞—Ä—å {–Ω–∞–∑–≤–∞–Ω–∏–µ: –∑–Ω–∞—á–µ–Ω–∏–µ}
        timestamp : datetime
            –í—Ä–µ–º—è –∑–∞–ø–∏—Å–∏
        \"\"\"
        if timestamp is None:
            timestamp = datetime.now()

        for name, value in features.items():
            if name not in self.feature_registry:
                raise ValueError(f"–ü—Ä–∏–∑–Ω–∞–∫ {name} –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω")

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
            transform = self.feature_registry[name].get('transformation')
            if transform:
                value = transform(value)

            # Offline store (–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ)
            self.offline_store[name].append({
                'entity_id': entity_id,
                'value': value,
                'timestamp': timestamp
            })

            # Online store (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
            self.online_store[name][entity_id] = value

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._update_statistics(name, value)

    def _update_statistics(self, name, value):
        \"\"\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞.\"\"\"
        stats = self.statistics[name]

        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        n = stats['count']
        old_mean = stats['mean']

        stats['count'] = n + 1
        stats['mean'] = old_mean + (value - old_mean) / (n + 1)

        if n > 0:
            stats['std'] = np.sqrt(
                ((n - 1) * stats['std']**2 + (value - old_mean) * (value - stats['mean'])) / n
            )

        stats['min'] = min(stats['min'], value)
        stats['max'] = max(stats['max'], value)

    def get_online_features(self, entity_id, feature_names):
        \"\"\"
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è inference (–Ω–∏–∑–∫–∞—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å).

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        ----------
        entity_id : str/int
            ID —Å—É—â–Ω–æ—Å—Ç–∏
        feature_names : list
            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        -----------
        dict —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        \"\"\"
        result = {}
        for name in feature_names:
            if name in self.online_store:
                result[name] = self.online_store[name].get(entity_id)
            else:
                result[name] = None
        return result

    def get_historical_features(self, entity_ids, feature_names, start_time=None, end_time=None):
        \"\"\"
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        ----------
        entity_ids : list
            –°–ø–∏—Å–æ–∫ ID —Å—É—â–Ω–æ—Å—Ç–µ–π
        feature_names : list
            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        start_time : datetime
            –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞
        end_time : datetime
            –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        -----------
        DataFrame —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        \"\"\"
        records = []

        for entity_id in entity_ids:
            record = {'entity_id': entity_id}

            for name in feature_names:
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è entity_id
                values = [
                    r for r in self.offline_store.get(name, [])
                    if r['entity_id'] == entity_id
                ]

                if start_time:
                    values = [v for v in values if v['timestamp'] >= start_time]
                if end_time:
                    values = [v for v in values if v['timestamp'] <= end_time]

                if values:
                    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    record[name] = sorted(values, key=lambda x: x['timestamp'])[-1]['value']
                else:
                    record[name] = None

            records.append(record)

        return pd.DataFrame(records)

    def get_feature_statistics(self, name):
        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É.\"\"\"
        return self.statistics.get(name, {})

    def list_features(self):
        \"\"\"–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\"\"\"
        return list(self.feature_registry.keys())

print("–ö–ª–∞—Å—Å SimpleFeatureStore –æ–ø—Ä–µ–¥–µ–ª—ë–Ω")"""))

    # Cell 10: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Feature Store
    cells.append(nbf.v4.new_code_cell("""# –°–æ–∑–¥–∞—ë–º –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Feature Store
fs = SimpleFeatureStore()

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
fs.register_feature(
    name='tenure_months',
    dtype='int',
    description='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—è—Ü–µ–≤ —Å –∫–æ–º–ø–∞–Ω–∏–µ–π'
)

fs.register_feature(
    name='monthly_charges',
    dtype='float',
    description='–ï–∂–µ–º–µ—Å—è—á–Ω—ã–π –ø–ª–∞—Ç—ë–∂'
)

fs.register_feature(
    name='total_charges',
    dtype='float',
    description='–û–±—â–∞—è —Å—É–º–º–∞ –ø–ª–∞—Ç–µ–∂–µ–π'
)

fs.register_feature(
    name='support_tickets_normalized',
    dtype='float',
    description='–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ —Ç–∏–∫–µ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏',
    transformation=lambda x: np.log1p(x)  # log-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
)

fs.register_feature(
    name='avg_monthly_charge',
    dtype='float',
    description='–°—Ä–µ–¥–Ω–∏–π –º–µ—Å—è—á–Ω—ã–π –ø–ª–∞—Ç—ë–∂ (total/tenure)'
)

print("\\n–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
for name in fs.list_features():
    info = fs.feature_registry[name]
    print(f"  {name}: {info['description']}")"""))

    # Cell 11: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Feature Store
    cells.append(nbf.v4.new_code_cell("""# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Feature Store
print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Feature Store...")

# –ë–µ—Ä—ë–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
sample_data = df_train.head(1000)

for _, row in sample_data.iterrows():
    customer_id = row['customer_id']

    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    features = {
        'tenure_months': row['tenure_months'],
        'monthly_charges': row['monthly_charges'],
        'total_charges': row['total_charges'],
        'support_tickets_normalized': row['num_support_tickets'],
        'avg_monthly_charge': row['total_charges'] / max(row['tenure_months'], 1)
    }

    fs.ingest(customer_id, features)

print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sample_data)} –∑–∞–ø–∏—Å–µ–π")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
print("\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
for name in fs.list_features():
    stats = fs.get_feature_statistics(name)
    print(f"\\n{name}:")
    print(f"  Count: {stats['count']}")
    print(f"  Mean: {stats['mean']:.2f}")
    print(f"  Std: {stats['std']:.2f}")
    print(f"  Min: {stats['min']:.2f}")
    print(f"  Max: {stats['max']:.2f}")"""))

    # Cell 12: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    cells.append(nbf.v4.new_code_cell("""# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

# 1. Online features (–¥–ª—è inference)
customer_id = 42
online_features = fs.get_online_features(
    customer_id,
    ['tenure_months', 'monthly_charges', 'support_tickets_normalized']
)

print("Online Features –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞", customer_id)
print(json.dumps(online_features, indent=2, default=str))

# 2. Historical features (–¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
entity_ids = [1, 2, 3, 4, 5]
historical_df = fs.get_historical_features(
    entity_ids,
    ['tenure_months', 'monthly_charges', 'total_charges', 'avg_monthly_charge']
)

print("\\nHistorical Features:")
print(historical_df)"""))

    # Cell 13: Drift Detection –≤–≤–µ–¥–µ–Ω–∏–µ
    cells.append(nbf.v4.new_markdown_cell("""## 3. Data Drift Detection

### –ß—Ç–æ —Ç–∞–∫–æ–µ Data Drift?

Data Drift - —ç—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤—Ä–µ–º–µ–Ω–∏. –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è ML, –ø–æ—Ç–æ–º—É —á—Ç–æ:
- –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏
- –ï—Å–ª–∏ production –¥–∞–Ω–Ω—ã–µ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è, –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞–¥–∞–µ—Ç
- –ù—É–∂–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è

### –¢–∏–ø—ã –¥—Ä–∏—Ñ—Ç–∞

1. **Feature Drift** - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
2. **Label Drift** - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
3. **Concept Drift** - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª—å—é

### –ú–µ—Ç–æ–¥—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è

1. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã**
   - Kolmogorov-Smirnov (K-S test)
   - Chi-squared test
   - Population Stability Index (PSI)

2. **–†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏**
   - Wasserstein distance
   - Jensen-Shannon divergence
   - KL divergence

–ú—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–∏—Ñ—Ç–∞ –≤ —Å—Ç–∏–ª–µ Evidently."""))

    # Cell 14: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Drift Detector
    cells.append(nbf.v4.new_code_cell("""class DriftDetector:
    \"\"\"
    –î–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–∏—Ñ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–∏–ª–µ Evidently.

    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    –º–µ–∂–¥—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º –∏ —Ç–µ–∫—É—â–∏–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏.
    \"\"\"

    def __init__(self, reference_data, feature_names, categorical_features=None):
        \"\"\"
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        ----------
        reference_data : DataFrame
            –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ–±—ã—á–Ω–æ –æ–±—É—á–∞—é—â–∏–µ)
        feature_names : list
            –°–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        categorical_features : list
            –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        \"\"\"
        self.reference_data = reference_data
        self.feature_names = feature_names
        self.categorical_features = categorical_features or []

        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.reference_stats = self._compute_statistics(reference_data)

    def _compute_statistics(self, data):
        \"\"\"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞.\"\"\"
        stats = {}
        for col in self.feature_names:
            if col in data.columns:
                values = data[col].dropna()
                stats[col] = {
                    'mean': values.mean(),
                    'std': values.std(),
                    'median': values.median(),
                    'min': values.min(),
                    'max': values.max(),
                    'percentiles': np.percentile(values, [25, 50, 75]).tolist()
                }
        return stats

    def ks_test(self, reference, current):
        \"\"\"
        Kolmogorov-Smirnov —Ç–µ—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        -----------
        statistic : float
            K-S —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        p_value : float
            p-value
        \"\"\"
        statistic, p_value = stats.ks_2samp(reference, current)
        return statistic, p_value

    def psi(self, reference, current, bins=10):
        \"\"\"
        Population Stability Index.

        PSI < 0.1 - –Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π
        PSI 0.1-0.2 - –Ω–µ–±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        PSI > 0.2 - –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        \"\"\"
        # –°–æ–∑–¥–∞—ë–º bins –Ω–∞ –æ—Å–Ω–æ–≤–µ reference
        _, bin_edges = np.histogram(reference, bins=bins)

        # –°—á–∏—Ç–∞–µ–º –¥–æ–ª–∏ –≤ –∫–∞–∂–¥–æ–º bin
        ref_counts, _ = np.histogram(reference, bins=bin_edges)
        cur_counts, _ = np.histogram(current, bins=bin_edges)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        ref_pct = ref_counts / len(reference)
        cur_pct = cur_counts / len(current)

        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞–ª–æ–µ —á–∏—Å–ª–æ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è log(0)
        ref_pct = np.clip(ref_pct, 0.0001, 1)
        cur_pct = np.clip(cur_pct, 0.0001, 1)

        # PSI
        psi_value = np.sum((cur_pct - ref_pct) * np.log(cur_pct / ref_pct))

        return psi_value

    def detect_drift(self, current_data, threshold_pvalue=0.05, threshold_psi=0.1):
        \"\"\"
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—Ä–∏—Ñ—Ç–∞ –≤ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        ----------
        current_data : DataFrame
            –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        threshold_pvalue : float
            –ü–æ—Ä–æ–≥ p-value –¥–ª—è K-S —Ç–µ—Å—Ç–∞
        threshold_psi : float
            –ü–æ—Ä–æ–≥ PSI

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        -----------
        report : dict
            –û—Ç—á—ë—Ç –æ –¥—Ä–∏—Ñ—Ç–µ
        \"\"\"
        report = {
            'timestamp': datetime.now().isoformat(),
            'n_reference': len(self.reference_data),
            'n_current': len(current_data),
            'features': {},
            'overall_drift': False,
            'drifted_features': []
        }

        for col in self.feature_names:
            if col not in current_data.columns:
                continue

            ref_values = self.reference_data[col].dropna().values
            cur_values = current_data[col].dropna().values

            # K-S —Ç–µ—Å—Ç
            ks_stat, ks_pvalue = self.ks_test(ref_values, cur_values)

            # PSI
            psi_value = self.psi(ref_values, cur_values)

            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
            ref_mean = ref_values.mean()
            cur_mean = cur_values.mean()
            mean_change = (cur_mean - ref_mean) / (ref_mean + 1e-10) * 100

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥—Ä–∏—Ñ—Ç–∞
            is_drifted = (ks_pvalue < threshold_pvalue) or (psi_value > threshold_psi)

            feature_report = {
                'ks_statistic': ks_stat,
                'ks_pvalue': ks_pvalue,
                'psi': psi_value,
                'reference_mean': ref_mean,
                'current_mean': cur_mean,
                'mean_change_pct': mean_change,
                'is_drifted': is_drifted
            }

            report['features'][col] = feature_report

            if is_drifted:
                report['drifted_features'].append(col)

        report['overall_drift'] = len(report['drifted_features']) > 0

        return report

    def plot_drift_report(self, report, figsize=(14, 10)):
        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –æ –¥—Ä–∏—Ñ—Ç–µ.\"\"\"
        features = list(report['features'].keys())
        n_features = len(features)

        fig, axes = plt.subplots(2, 2, figsize=figsize)

        # 1. PSI –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
        ax1 = axes[0, 0]
        psi_values = [report['features'][f]['psi'] for f in features]
        colors = ['red' if p > 0.1 else 'orange' if p > 0.05 else 'green' for p in psi_values]
        bars = ax1.barh(features, psi_values, color=colors)
        ax1.axvline(x=0.1, color='red', linestyle='--', label='–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π (0.1)')
        ax1.axvline(x=0.05, color='orange', linestyle='--', label='–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ (0.05)')
        ax1.set_xlabel('PSI')
        ax1.set_title('Population Stability Index')
        ax1.legend()

        # 2. K-S p-values
        ax2 = axes[0, 1]
        pvalues = [report['features'][f]['ks_pvalue'] for f in features]
        colors = ['red' if p < 0.05 else 'green' for p in pvalues]
        ax2.barh(features, pvalues, color=colors)
        ax2.axvline(x=0.05, color='red', linestyle='--', label='Œ± = 0.05')
        ax2.set_xlabel('p-value')
        ax2.set_title('Kolmogorov-Smirnov Test p-values')
        ax2.legend()

        # 3. –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
        ax3 = axes[1, 0]
        mean_changes = [report['features'][f]['mean_change_pct'] for f in features]
        colors = ['red' if abs(m) > 20 else 'orange' if abs(m) > 10 else 'green' for m in mean_changes]
        ax3.barh(features, mean_changes, color=colors)
        ax3.axvline(x=0, color='black', linewidth=0.5)
        ax3.set_xlabel('–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ (%)')
        ax3.set_title('–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ')

        # 4. –°–≤–æ–¥–∫–∞
        ax4 = axes[1, 1]
        ax4.axis('off')

        summary_text = f\"\"\"
        –°–í–û–î–ö–ê –ü–û –î–†–ò–§–¢–£

        –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {report['n_reference']} –∑–∞–ø–∏—Å–µ–π
        –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ: {report['n_current']} –∑–∞–ø–∏—Å–µ–π

        –û–±—â–∏–π –¥—Ä–∏—Ñ—Ç: {'–î–ê' if report['overall_drift'] else '–ù–ï–¢'}

        –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –¥—Ä–∏—Ñ—Ç–æ–º:
        {chr(10).join(['  ‚Ä¢ ' + f for f in report['drifted_features']]) if report['drifted_features'] else '  –ù–µ—Ç'}

        –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        {'‚Ä¢ –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏' if report['overall_drift'] else '‚Ä¢ –ú–æ–¥–µ–ª—å –∞–∫—Ç—É–∞–ª—å–Ω–∞'}
        {'‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö' if report['overall_drift'] else ''}
        \"\"\"

        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes,
                fontsize=11, verticalalignment='top', fontfamily='monospace')

        plt.suptitle('–û—Ç—á—ë—Ç –æ –¥—Ä–∏—Ñ—Ç–µ –¥–∞–Ω–Ω—ã—Ö', fontsize=14)
        plt.tight_layout()
        plt.show()

print("–ö–ª–∞—Å—Å DriftDetector –æ–ø—Ä–µ–¥–µ–ª—ë–Ω")"""))

    # Cell 15: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Drift Detection
    cells.append(nbf.v4.new_code_cell("""# –ü—Ä–∏–º–µ–Ω—è–µ–º Drift Detection

# –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
numeric_features = ['tenure_months', 'monthly_charges', 'total_charges',
                   'num_support_tickets', 'num_referrals']

# –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
detector = DriftDetector(
    reference_data=df_train,
    feature_names=numeric_features
)

# –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –¥—Ä–∏—Ñ—Ç –≤ production –¥–∞–Ω–Ω—ã—Ö
print("–ê–Ω–∞–ª–∏–∑ –¥—Ä–∏—Ñ—Ç–∞...")
drift_report = detector.detect_drift(df_production)

# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
print("\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞:")
print("=" * 50)

for feature, metrics in drift_report['features'].items():
    status = "üî¥ –î–†–ò–§–¢" if metrics['is_drifted'] else "üü¢ OK"
    print(f"\\n{feature} {status}")
    print(f"  PSI: {metrics['psi']:.4f}")
    print(f"  K-S p-value: {metrics['ks_pvalue']:.4f}")
    print(f"  –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: {metrics['mean_change_pct']:+.1f}%")

print(f"\\n–û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {'–î–†–ò–§–¢ –û–ë–ù–ê–†–£–ñ–ï–ù' if drift_report['overall_drift'] else '–î—Ä–∏—Ñ—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω'}")
print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –¥—Ä–∏—Ñ—Ç–æ–º: {drift_report['drifted_features']}")"""))

    # Cell 16: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∏—Ñ—Ç–∞
    cells.append(nbf.v4.new_code_cell("""# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
detector.plot_drift_report(drift_report)"""))

    # Cell 17: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    cells.append(nbf.v4.new_code_cell("""# –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()

for i, col in enumerate(numeric_features):
    ax = axes[i]

    # –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    ax.hist(df_train[col], bins=30, alpha=0.5, label='Reference', density=True)
    # Production –¥–∞–Ω–Ω—ã–µ
    ax.hist(df_production[col], bins=30, alpha=0.5, label='Production', density=True)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    ref_mean = df_train[col].mean()
    prod_mean = df_production[col].mean()

    ax.axvline(ref_mean, color='blue', linestyle='--', linewidth=2)
    ax.axvline(prod_mean, color='orange', linestyle='--', linewidth=2)

    psi = drift_report['features'][col]['psi']
    ax.set_title(f'{col}\\nPSI={psi:.3f}')
    ax.legend()

# –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–π subplot
axes[-1].axis('off')

plt.suptitle('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π: Reference vs Production', fontsize=14)
plt.tight_layout()
plt.show()"""))

    # Cell 18: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    cells.append(nbf.v4.new_code_cell("""# –ü—Ä–∏–º–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–∏—Ñ—Ç–∞

def monitor_data_quality(detector, new_data, alert_threshold=0.15):
    \"\"\"
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    detector : DriftDetector
        –î–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–∏—Ñ—Ç–∞
    new_data : DataFrame
        –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    alert_threshold : float
        –ü–æ—Ä–æ–≥ PSI –¥–ª—è –∞–ª–µ—Ä—Ç–∞

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    -----------
    alerts : list
        –°–ø–∏—Å–æ–∫ –∞–ª–µ—Ä—Ç–æ–≤
    \"\"\"
    report = detector.detect_drift(new_data)

    alerts = []

    for feature, metrics in report['features'].items():
        if metrics['psi'] > alert_threshold:
            alert = {
                'type': 'CRITICAL',
                'feature': feature,
                'message': f'–í—ã—Å–æ–∫–∏–π PSI ({metrics["psi"]:.3f})',
                'action': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ'
            }
            alerts.append(alert)
        elif metrics['psi'] > alert_threshold / 2:
            alert = {
                'type': 'WARNING',
                'feature': feature,
                'message': f'–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π PSI ({metrics["psi"]:.3f})',
                'action': '–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é'
            }
            alerts.append(alert)

    return alerts

# –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
alerts = monitor_data_quality(detector, df_production)

print("–ê–ª–µ—Ä—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:")
print("=" * 50)

for alert in alerts:
    icon = "üî¥" if alert['type'] == 'CRITICAL' else "üü°"
    print(f"\\n{icon} {alert['type']}: {alert['feature']}")
    print(f"   {alert['message']}")
    print(f"   –î–µ–π—Å—Ç–≤–∏–µ: {alert['action']}")

if not alerts:
    print("\\nüü¢ –í—Å–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤ –Ω–æ—Ä–º–µ")"""))

    # Cell 19: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤
    cells.append(nbf.v4.new_code_cell("""# –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
print("=" * 60)
print("–ü–†–û–î–í–ò–ù–£–¢–ê–Ø MLOPS –ò–ù–§–†–ê–°–¢–†–£–ö–¢–£–†–ê - –ò–¢–û–ì–ò")
print("=" * 60)

print("\\n1. Kubernetes Deployment")
print("   –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: Deployment, Service, HPA, ConfigMap")
print("   –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
print("   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ CPU")
print("   ‚Ä¢ Health checks (liveness/readiness)")
print("   ‚Ä¢ Rolling updates –±–µ–∑ –ø—Ä–æ—Å—Ç–æ—è")
print("   ‚Ä¢ Prometheus –º–µ—Ç—Ä–∏–∫–∏")

print("\\n2. Feature Store")
print("   –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: Registry, Offline/Online Store")
print("   –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
print("   ‚Ä¢ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
print("   ‚Ä¢ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏")
print("   ‚Ä¢ –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –¥–ª—è inference")
print("   ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º")

print("\\n3. Drift Detection")
print("   –ú–µ—Ç–æ–¥—ã: K-S —Ç–µ—Å—Ç, PSI")
print("   –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
print("   ‚Ä¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")
print("   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–µ—Ä—Ç—ã")
print("   ‚Ä¢ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∏—Ñ—Ç–∞")
print("   ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º")

print("\\n" + "=" * 60)
print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø PRODUCTION")
print("=" * 60)
print("\\n‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Kubernetes –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏")
print("‚Ä¢ –í–Ω–µ–¥—Ä–∏—Ç–µ Feature Store –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏")
print("‚Ä¢ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞ —Å –∞–ª–µ—Ä—Ç–∞–º–∏")
print("‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –¥—Ä–∏—Ñ—Ç–µ")
print("‚Ä¢ –í–µ–¥–∏—Ç–µ –ª–æ–≥–∏ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")"""))

    # Cell 20: –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    cells.append(nbf.v4.new_markdown_cell("""## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

### –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

1. **Kubernetes Deployment** - —Å–æ–∑–¥–∞–ª–∏ –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è ML –º–æ–¥–µ–ª–∏ —Å –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º, health checks –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ Prometheus.

2. **Feature Store** - —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏ —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â—É—é –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏: —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ inference.

3. **Drift Detection** - –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –¥—Ä–∏—Ñ—Ç –≤ production –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º monthly_charges –∏ num_support_tickets.

### –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –¥—Ä–∏—Ñ—Ç

Production –¥–∞–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞–ª–∏:
- –£–≤–µ–ª–∏—á–µ–Ω–∏–µ monthly_charges –Ω–∞ ~30%
- –†–æ—Å—Ç —á–∏—Å–ª–∞ —Ç–∏–∫–µ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
- –°–º–µ—â–µ–Ω–∏–µ –∫ –º–µ—Å—è—á–Ω—ã–º –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º

–≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏!

### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

1. **CI/CD –¥–ª—è ML** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
2. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - —Ä–∞–Ω–Ω–µ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
3. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** - —Ç—Ä–∏–≥–≥–µ—Ä—ã –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –¥—Ä–∏—Ñ—Ç–µ

### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è

- **Kubernetes**: minikube, kind –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- **Feature Store**: Feast, Tecton, Hopsworks
- **Drift Detection**: Evidently, WhyLabs, Arize

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CI/CD (GitHub Actions, GitLab CI)
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ production
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""))

    nb['cells'] = cells

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    output_path = '/home/user/test/notebooks/phase7_production_mlops/03_advanced_mlops_infra.ipynb'
    with open(output_path, 'w', encoding='utf-8') as f:
        nbf.write(nb, f)

    print(f"‚úÖ Notebook —Å–æ–∑–¥–∞–Ω: {output_path}")
    print(f"–í—Å–µ–≥–æ —è—á–µ–µ–∫: {len(cells)}")
    return output_path

if __name__ == "__main__":
    create_notebook()
