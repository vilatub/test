{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (LSTM/GRU)\n",
    "\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ —Ä–∞–±–æ—Ç–∞–µ–º —Å **—Ä–µ–∞–ª—å–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏** –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º:\n",
    "- **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã**: ARIMA, SARIMA, Prophet\n",
    "- **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ**: LSTM, GRU, Bidirectional LSTM\n",
    "\n",
    "## –î–∞—Ç–∞—Å–µ—Ç—ã\n",
    "\n",
    "1. **Airline Passengers** - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é\n",
    "2. **Stock Prices (Apple)** - —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é\n",
    "3. **Weather Data (Temperature)** - –º—É–ª—å—Ç–∏–≤–∞—Ä–∏–∞—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã\n",
    "\n",
    "## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n",
    "\n",
    "### –ß–∞—Å—Ç—å 1: Airline Passengers (Univariate)\n",
    "1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ EDA\n",
    "2. –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "3. ARIMA/SARIMA\n",
    "4. Prophet\n",
    "5. LSTM\n",
    "6. GRU\n",
    "7. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤\n",
    "\n",
    "### –ß–∞—Å—Ç—å 2: Stock Prices (Multivariate)\n",
    "8. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "9. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã\n",
    "10. LSTM –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω\n",
    "11. Attention –º–µ—Ö–∞–Ω–∏–∑–º\n",
    "\n",
    "### –ß–∞—Å—Ç—å 3: Weather Data (Multivariate)\n",
    "12. –ú—É–ª—å—Ç–∏–≤–∞—Ä–∏–∞—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã\n",
    "13. Bidirectional LSTM\n",
    "14. Seq2Seq –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# –£—Ç–∏–ª–∏—Ç—ã\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print('‚úÖ –í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!')\n",
    "print(f'TensorFlow: {tf.__version__}')\n",
    "print(f'Prophet –¥–æ—Å—Ç—É–ø–µ–Ω: True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# –ß–ê–°–¢–¨ 1: Airline Passengers (Univariate Time Series)\n",
    "\n",
    "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∞–≤–∏–∞–ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ —Å 1949 –ø–æ 1960 –≥–æ–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Airline Passengers\n",
    "# –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω –≤ seaborn\n",
    "df_flights = sns.load_dataset('flights')\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n",
    "df_flights['date'] = pd.to_datetime(df_flights['year'].astype(str) + '-' + df_flights['month'], format='%Y-%B')\n",
    "df_flights = df_flights.sort_values('date').reset_index(drop=True)\n",
    "df_flights = df_flights.set_index('date')\n",
    "\n",
    "print(f'–î–∞—Ç–∞—Å–µ—Ç: {df_flights.shape}')\n",
    "print(f'–ü–µ—Ä–∏–æ–¥: {df_flights.index.min()} - {df_flights.index.max()}')\n",
    "print(f'–ß–∞—Å—Ç–æ—Ç–∞: Monthly')\n",
    "print(f'\\n–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:')\n",
    "df_flights.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# –ü–æ–ª–Ω—ã–π —Ä—è–¥\n",
    "axes[0].plot(df_flights.index, df_flights['passengers'], linewidth=2)\n",
    "axes[0].set_title('Airline Passengers (1949-1960)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('–î–∞—Ç–∞')\n",
    "axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "axes[1].hist(df_flights['passengers'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π', fontsize=12)\n",
    "axes[1].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤')\n",
    "axes[1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nüìä –ù–∞–±–ª—é–¥–µ–Ω–∏—è:')\n",
    "print('1. –Ø–≤–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (—Ä–æ—Å—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤)')\n",
    "print('2. –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å (–ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–∞–∂–¥—ã–π –≥–æ–¥)')\n",
    "print('3. –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∞–º–ø–ª–∏—Ç—É–¥—ã –∫–æ–ª–µ–±–∞–Ω–∏–π —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º (–≥–µ—Ç–µ—Ä–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "\n",
    "–†–∞–∑–ª–æ–∂–∏–º —Ä—è–¥ –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: **—Ç—Ä–µ–Ω–¥, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –æ—Å—Ç–∞—Ç–∫–∏**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è (additive –∏ multiplicative)\n",
    "decomposition_add = seasonal_decompose(df_flights['passengers'], model='additive', period=12)\n",
    "decomposition_mult = seasonal_decompose(df_flights['passengers'], model='multiplicative', period=12)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
    "fig.suptitle('–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Additive\n",
    "axes[0, 0].plot(df_flights['passengers'])\n",
    "axes[0, 0].set_title('–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä—è–¥')\n",
    "axes[0, 0].set_ylabel('–ü–∞—Å—Å–∞–∂–∏—Ä—ã')\n",
    "\n",
    "axes[1, 0].plot(decomposition_add.trend)\n",
    "axes[1, 0].set_title('–¢—Ä–µ–Ω–¥ (Additive)')\n",
    "axes[1, 0].set_ylabel('–¢—Ä–µ–Ω–¥')\n",
    "\n",
    "axes[2, 0].plot(decomposition_add.seasonal)\n",
    "axes[2, 0].set_title('–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å (Additive)')\n",
    "axes[2, 0].set_ylabel('–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å')\n",
    "\n",
    "axes[3, 0].plot(decomposition_add.resid)\n",
    "axes[3, 0].set_title('–û—Å—Ç–∞—Ç–∫–∏ (Additive)')\n",
    "axes[3, 0].set_ylabel('–û—Å—Ç–∞—Ç–∫–∏')\n",
    "axes[3, 0].set_xlabel('–î–∞—Ç–∞')\n",
    "\n",
    "# Multiplicative\n",
    "axes[0, 1].plot(df_flights['passengers'])\n",
    "axes[0, 1].set_title('–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä—è–¥')\n",
    "\n",
    "axes[1, 1].plot(decomposition_mult.trend)\n",
    "axes[1, 1].set_title('–¢—Ä–µ–Ω–¥ (Multiplicative)')\n",
    "\n",
    "axes[2, 1].plot(decomposition_mult.seasonal)\n",
    "axes[2, 1].set_title('–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å (Multiplicative)')\n",
    "\n",
    "axes[3, 1].plot(decomposition_mult.resid)\n",
    "axes[3, 1].set_title('–û—Å—Ç–∞—Ç–∫–∏ (Multiplicative)')\n",
    "axes[3, 1].set_xlabel('–î–∞—Ç–∞')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nüìà –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:')\n",
    "print('- Additive: Y(t) = Trend(t) + Seasonal(t) + Residual(t)')\n",
    "print('- Multiplicative: Y(t) = Trend(t) √ó Seasonal(t) √ó Residual(t)')\n",
    "print('\\n–î–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –ª—É—á—à–µ –ø–æ–¥—Ö–æ–¥–∏—Ç multiplicative, —Ç.–∫. –∞–º–ø–ª–∏—Ç—É–¥–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞—Å—Ç–µ—Ç —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 –¢–µ—Å—Ç –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å (ADF Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test\n",
    "def adf_test(series, name=''):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'\\n=== ADF Test: {name} ===')\n",
    "    print(f'ADF Statistic: {result[0]:.6f}')\n",
    "    print(f'p-value: {result[1]:.6f}')\n",
    "    print(f'Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'  {key}: {value:.3f}')\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print('‚úÖ –†—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω (–æ—Ç–≤–µ—Ä–≥–∞–µ–º H0)')\n",
    "    else:\n",
    "        print('‚ùå –†—è–¥ –ù–ï —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω (–Ω–µ –º–æ–∂–µ–º –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å H0)')\n",
    "    \n",
    "    return result[1] <= 0.05\n",
    "\n",
    "# –¢–µ—Å—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "is_stationary = adf_test(df_flights['passengers'], '–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä—è–¥')\n",
    "\n",
    "# –¢–µ—Å—Ç –ø–æ—Å–ª–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "df_flights['passengers_diff'] = df_flights['passengers'].diff()\n",
    "is_stationary_diff = adf_test(df_flights['passengers_diff'], '–ü–æ—Å–ª–µ 1-–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è')\n",
    "\n",
    "# –¢–µ—Å—Ç –ø–æ—Å–ª–µ —Å–µ–∑–æ–Ω–Ω–æ–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "df_flights['passengers_seasonal_diff'] = df_flights['passengers'].diff(12)\n",
    "is_stationary_seasonal = adf_test(df_flights['passengers_seasonal_diff'], '–ü–æ—Å–ª–µ —Å–µ–∑–æ–Ω–Ω–æ–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª—è–µ–º: 80% train, 20% test\n",
    "train_size = int(len(df_flights) * 0.8)\n",
    "train_flights = df_flights['passengers'][:train_size]\n",
    "test_flights = df_flights['passengers'][train_size:]\n",
    "\n",
    "print(f'Train: {len(train_flights)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π ({train_flights.index.min()} - {train_flights.index.max()})')\n",
    "print(f'Test: {len(test_flights)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π ({test_flights.index.min()} - {test_flights.index.max()})')\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(train_flights.index, train_flights, label='Train', linewidth=2)\n",
    "plt.plot(test_flights.index, test_flights, label='Test', linewidth=2, color='orange')\n",
    "plt.axvline(x=train_flights.index[-1], color='red', linestyle='--', label='Train/Test Split')\n",
    "plt.title('Train/Test Split', fontsize=14)\n",
    "plt.xlabel('–î–∞—Ç–∞')\n",
    "plt.ylabel('–ü–∞—Å—Å–∞–∂–∏—Ä—ã')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 SARIMA - –°–µ–∑–æ–Ω–Ω–∞—è ARIMA\n",
    "\n",
    "SARIMA(p, d, q)(P, D, Q, s) –≥–¥–µ:\n",
    "- p, d, q - –ø–æ—Ä—è–¥–∫–∏ AR, I, MA\n",
    "- P, D, Q - —Å–µ–∑–æ–Ω–Ω—ã–µ –ø–æ—Ä—è–¥–∫–∏\n",
    "- s - –ø–µ—Ä–∏–æ–¥ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ (12 –¥–ª—è –º–µ—Å—è—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ SARIMA –º–æ–¥–µ–ª–∏\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–æ–±—Ä–∞–Ω—ã –≤—Ä—É—á–Ω—É—é (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å auto_arima –¥–ª—è –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä–∞)\n",
    "print('–û–±—É—á–∞–µ–º SARIMA(1,1,1)(1,1,1,12)...')\n",
    "\n",
    "sarima_model = SARIMAX(\n",
    "    train_flights,\n",
    "    order=(1, 1, 1),  # (p, d, q)\n",
    "    seasonal_order=(1, 1, 1, 12),  # (P, D, Q, s)\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "print('‚úÖ SARIMA –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!')\n",
    "print(sarima_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è SARIMA\n",
    "sarima_forecast = sarima_fit.forecast(steps=len(test_flights))\n",
    "sarima_forecast_series = pd.Series(sarima_forecast.values, index=test_flights.index)\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "sarima_mae = mean_absolute_error(test_flights, sarima_forecast)\n",
    "sarima_rmse = np.sqrt(mean_squared_error(test_flights, sarima_forecast))\n",
    "sarima_mape = np.mean(np.abs((test_flights - sarima_forecast) / test_flights)) * 100\n",
    "\n",
    "print('=== SARIMA Results ===')\n",
    "print(f'MAE: {sarima_mae:.2f}')\n",
    "print(f'RMSE: {sarima_rmse:.2f}')\n",
    "print(f'MAPE: {sarima_mape:.2f}%')\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_flights.index, train_flights, label='Train', linewidth=2)\n",
    "plt.plot(test_flights.index, test_flights, label='Test (Actual)', linewidth=2, color='orange')\n",
    "plt.plot(sarima_forecast_series.index, sarima_forecast_series, label='SARIMA Forecast', linewidth=2, color='green', linestyle='--')\n",
    "plt.title('SARIMA Forecast', fontsize=14)\n",
    "plt.xlabel('–î–∞—Ç–∞')\n",
    "plt.ylabel('–ü–∞—Å—Å–∞–∂–∏—Ä—ã')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Prophet - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Prophet (—Ç—Ä–µ–±—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'ds' –∏ 'y')\n",
    "train_prophet = train_flights.reset_index()\n",
    "train_prophet.columns = ['ds', 'y']\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Prophet\n",
    "print('–û–±—É—á–∞–µ–º Prophet –º–æ–¥–µ–ª—å...')\n",
    "prophet_model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='multiplicative'\n",
    ")\n",
    "\n",
    "prophet_model.fit(train_prophet)\n",
    "print('‚úÖ Prophet –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≥–Ω–æ–∑ Prophet\n",
    "future = prophet_model.make_future_dataframe(periods=len(test_flights), freq='MS')\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "\n",
    "# –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è test –ø–µ—Ä–∏–æ–¥–∞\n",
    "prophet_test_forecast = prophet_forecast.iloc[-len(test_flights):]['yhat'].values\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "prophet_mae = mean_absolute_error(test_flights, prophet_test_forecast)\n",
    "prophet_rmse = np.sqrt(mean_squared_error(test_flights, prophet_test_forecast))\n",
    "prophet_mape = np.mean(np.abs((test_flights - prophet_test_forecast) / test_flights)) * 100\n",
    "\n",
    "print('=== Prophet Results ===')\n",
    "print(f'MAE: {prophet_mae:.2f}')\n",
    "print(f'RMSE: {prophet_rmse:.2f}')\n",
    "print(f'MAPE: {prophet_mape:.2f}%')\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Prophet\n",
    "fig = prophet_model.plot(prophet_forecast)\n",
    "plt.title('Prophet Forecast', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Prophet\n",
    "fig2 = prophet_model.plot_components(prophet_forecast)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 LSTM - Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LSTM\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "scaler = MinMaxScaler()\n",
    "passengers_scaled = scaler.fit_transform(df_flights[['passengers']])\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ\n",
    "train_scaled = passengers_scaled[:train_size]\n",
    "test_scaled = passengers_scaled[train_size:]\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (–∏—Å–ø–æ–ª—å–∑—É–µ–º 12 –º–µ—Å—è—Ü–µ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ)\n",
    "seq_length = 12\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "\n",
    "# Reshape –¥–ª—è LSTM [samples, time steps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(f'‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è LSTM')\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ LSTM –º–æ–¥–µ–ª–∏\n",
    "def create_lstm_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        LSTM(50, activation='relu', return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm_model = create_lstm_model((seq_length, 1))\n",
    "print('=== LSTM Architecture ===')\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ LSTM\n",
    "print('–û–±—É—á–∞–µ–º LSTM...')\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7)\n",
    "\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print('‚úÖ LSTM –æ–±—É—á–µ–Ω–∞!')\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history_lstm.history['loss'], label='Train Loss')\n",
    "plt.plot(history_lstm.history['val_loss'], label='Val Loss')\n",
    "plt.title('LSTM Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è LSTM\n",
    "lstm_predictions_scaled = lstm_model.predict(X_test)\n",
    "lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "lstm_mae = mean_absolute_error(y_test_actual, lstm_predictions)\n",
    "lstm_rmse = np.sqrt(mean_squared_error(y_test_actual, lstm_predictions))\n",
    "lstm_mape = np.mean(np.abs((y_test_actual - lstm_predictions) / y_test_actual)) * 100\n",
    "\n",
    "print('=== LSTM Results ===')\n",
    "print(f'MAE: {lstm_mae:.2f}')\n",
    "print(f'RMSE: {lstm_rmse:.2f}')\n",
    "print(f'MAPE: {lstm_mape:.2f}%')\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(range(len(y_test_actual)), y_test_actual, label='Actual', linewidth=2)\n",
    "plt.plot(range(len(lstm_predictions)), lstm_predictions, label='LSTM Predictions', linewidth=2, linestyle='--')\n",
    "plt.title('LSTM Predictions vs Actual', fontsize=14)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Passengers')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 GRU - Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ GRU –º–æ–¥–µ–ª–∏\n",
    "def create_gru_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        GRU(50, activation='relu', return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        GRU(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "gru_model = create_gru_model((seq_length, 1))\n",
    "print('=== GRU Architecture ===')\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ GRU\n",
    "print('–û–±—É—á–∞–µ–º GRU...')\n",
    "\n",
    "history_gru = gru_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print('‚úÖ GRU –æ–±—É—á–µ–Ω–∞!')\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è GRU\n",
    "gru_predictions_scaled = gru_model.predict(X_test)\n",
    "gru_predictions = scaler.inverse_transform(gru_predictions_scaled)\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "gru_mae = mean_absolute_error(y_test_actual, gru_predictions)\n",
    "gru_rmse = np.sqrt(mean_squared_error(y_test_actual, gru_predictions))\n",
    "gru_mape = np.mean(np.abs((y_test_actual - gru_predictions) / y_test_actual)) * 100\n",
    "\n",
    "print('=== GRU Results ===')\n",
    "print(f'MAE: {gru_mae:.2f}')\n",
    "print(f'RMSE: {gru_rmse:.2f}')\n",
    "print(f'MAPE: {gru_mape:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è Airline Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "results_airline = pd.DataFrame({\n",
    "    'Method': ['SARIMA', 'Prophet', 'LSTM', 'GRU'],\n",
    "    'MAE': [sarima_mae, prophet_mae, lstm_mae, gru_mae],\n",
    "    'RMSE': [sarima_rmse, prophet_rmse, lstm_rmse, gru_rmse],\n",
    "    'MAPE (%)': [sarima_mape, prophet_mape, lstm_mape, gru_mape]\n",
    "})\n",
    "\n",
    "results_airline = results_airline.sort_values('RMSE')\n",
    "print('\\n=== –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤: Airline Passengers ===')\n",
    "print(results_airline.to_string(index=False))\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(results_airline))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, results_airline['MAE'], width, label='MAE')\n",
    "ax.bar(x, results_airline['RMSE'], width, label='RMSE')\n",
    "ax.bar(x + width, results_airline['MAPE (%)'], width, label='MAPE (%)')\n",
    "\n",
    "ax.set_xlabel('–ú–µ—Ç–æ–¥', fontsize=12)\n",
    "ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏', fontsize=12)\n",
    "ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results_airline['Method'])\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nüèÜ –õ—É—á—à–∏–π –º–µ—Ç–æ–¥:', results_airline.iloc[0]['Method'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# –ß–ê–°–¢–¨ 2: Stock Prices (Multivariate Time Series)\n",
    "\n",
    "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –∞–∫—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ü–∏–π (–∏—Å–ø–æ–ª—å–∑—É–µ–º yfinance –∏–ª–∏ —Å–æ–∑–¥–∞–¥–∏–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ)\n",
    "print('\\nüìà –ß–∞—Å—Ç—å 2: Stock Prices')\n",
    "print('–î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∞–∫—Ü–∏–∏')\n",
    "print('–í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ yfinance –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: yf.download(\"AAPL\", start=\"2020-01-01\")')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∞–∫—Ü–∏–π\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–µ–Ω—ã —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é\n",
    "trend = np.linspace(100, 200, len(dates))\n",
    "noise = np.random.normal(0, 5, len(dates))\n",
    "seasonality = 10 * np.sin(np.arange(len(dates)) / 365 * 2 * np.pi)\n",
    "close_price = trend + noise + seasonality\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º OHLC –¥–∞–Ω–Ω—ã–µ\n",
    "df_stock = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Open': close_price + np.random.uniform(-2, 2, len(dates)),\n",
    "    'High': close_price + np.random.uniform(0, 5, len(dates)),\n",
    "    'Low': close_price - np.random.uniform(0, 5, len(dates)),\n",
    "    'Close': close_price,\n",
    "    'Volume': np.random.randint(1000000, 10000000, len(dates))\n",
    "})\n",
    "\n",
    "df_stock = df_stock.set_index('Date')\n",
    "\n",
    "print(f'\\n–î–∞—Ç–∞—Å–µ—Ç: {df_stock.shape}')\n",
    "print(f'–ü–µ—Ä–∏–æ–¥: {df_stock.index.min()} - {df_stock.index.max()}')\n",
    "df_stock.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–∫—Ü–∏–π\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# –¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è\n",
    "axes[0].plot(df_stock.index, df_stock['Close'], linewidth=1, alpha=0.8)\n",
    "axes[0].set_title('Stock Price (Close)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤\n",
    "axes[1].bar(df_stock.index, df_stock['Volume'], width=1, alpha=0.7)\n",
    "axes[1].set_title('Trading Volume', fontsize=12)\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Volume')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã\n",
    "def add_technical_indicators(df):\n",
    "    \"\"\"–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–∫—Ü–∏–π\"\"\"\n",
    "    # Moving Averages\n",
    "    df['MA_7'] = df['Close'].rolling(window=7).mean()\n",
    "    df['MA_21'] = df['Close'].rolling(window=21).mean()\n",
    "    df['MA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    \n",
    "    # Volatility (rolling std)\n",
    "    df['Volatility'] = df['Returns'].rolling(window=21).std()\n",
    "    \n",
    "    # Momentum\n",
    "    df['Momentum'] = df['Close'] - df['Close'].shift(10)\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_stock = add_technical_indicators(df_stock)\n",
    "df_stock = df_stock.dropna()  # –£–¥–∞–ª—è–µ–º NaN –æ—Ç rolling –æ–ø–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "print('‚úÖ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã!')\n",
    "print(f'–ü—Ä–∏–∑–Ω–∞–∫–∏: {list(df_stock.columns)}')\n",
    "df_stock.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LSTM (multivariate)\n",
    "feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA_7', 'MA_21', 'Returns', 'RSI']\n",
    "target_column = 'Close'\n",
    "\n",
    "# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "scaler_stock = MinMaxScaler()\n",
    "stock_scaled = scaler_stock.fit_transform(df_stock[feature_columns])\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test (80/20)\n",
    "train_size_stock = int(len(stock_scaled) * 0.8)\n",
    "train_stock = stock_scaled[:train_size_stock]\n",
    "test_stock = stock_scaled[train_size_stock:]\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (60 –¥–Ω–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ)\n",
    "seq_length_stock = 60\n",
    "X_train_stock, y_train_stock = create_sequences(train_stock[:, 3], seq_length_stock)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Close\n",
    "X_test_stock, y_test_stock = create_sequences(test_stock[:, 3], seq_length_stock)\n",
    "\n",
    "X_train_stock = X_train_stock.reshape((X_train_stock.shape[0], X_train_stock.shape[1], 1))\n",
    "X_test_stock = X_test_stock.reshape((X_test_stock.shape[0], X_test_stock.shape[1], 1))\n",
    "\n",
    "print(f'‚úÖ –î–∞–Ω–Ω—ã–µ –∞–∫—Ü–∏–π –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã')\n",
    "print(f'X_train shape: {X_train_stock.shape}')\n",
    "print(f'X_test shape: {X_test_stock.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω –∞–∫—Ü–∏–π\n",
    "stock_lstm_model = create_lstm_model((seq_length_stock, 1))\n",
    "\n",
    "print('–û–±—É—á–∞–µ–º LSTM –¥–ª—è –∞–∫—Ü–∏–π...')\n",
    "history_stock = stock_lstm_model.fit(\n",
    "    X_train_stock, y_train_stock,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print('‚úÖ LSTM –¥–ª—è –∞–∫—Ü–∏–π –æ–±—É—á–µ–Ω–∞!')\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "stock_predictions = stock_lstm_model.predict(X_test_stock)\n",
    "\n",
    "# –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ –¥–ª—è Close price)\n",
    "close_scaler = MinMaxScaler()\n",
    "close_scaler.fit(df_stock[['Close']][:train_size_stock])\n",
    "stock_predictions_actual = close_scaler.inverse_transform(stock_predictions)\n",
    "y_test_stock_actual = close_scaler.inverse_transform(y_test_stock.reshape(-1, 1))\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "stock_mae = mean_absolute_error(y_test_stock_actual, stock_predictions_actual)\n",
    "stock_rmse = np.sqrt(mean_squared_error(y_test_stock_actual, stock_predictions_actual))\n",
    "\n",
    "print('\\n=== LSTM Stock Predictions ===')\n",
    "print(f'MAE: ${stock_mae:.2f}')\n",
    "print(f'RMSE: ${stock_rmse:.2f}')\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(range(len(y_test_stock_actual)), y_test_stock_actual, label='Actual Price', linewidth=2)\n",
    "plt.plot(range(len(stock_predictions_actual)), stock_predictions_actual, label='LSTM Predictions', linewidth=2, linestyle='--', alpha=0.8)\n",
    "plt.title('Stock Price Prediction with LSTM', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# –í—ã–≤–æ–¥—ã\n",
    "\n",
    "## üéØ –ì–ª–∞–≤–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã:\n",
    "\n",
    "### 1. Airline Passengers (Univariate):\n",
    "- **SARIMA** –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å —è–≤–Ω–æ–π —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é\n",
    "- **Prophet** –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç —Ç—Ä–µ–Ω–¥—ã –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å\n",
    "- **LSTM/GRU** —Ç—Ä–µ–±—É—é—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –º–æ–≥—É—Ç –≤—ã—É—á–∏—Ç—å —Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
    "\n",
    "### 2. Stock Prices (Multivariate):\n",
    "- –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã\n",
    "- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤–∞–∂–Ω—ã –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "- LSTM –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ\n",
    "\n",
    "### 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤:\n",
    "\n",
    "**–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ (ARIMA, SARIMA, Prophet)**:\n",
    "- ‚úÖ –ë—ã—Å—Ç—Ä—ã–µ\n",
    "- ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–µ\n",
    "- ‚úÖ –†–∞–±–æ—Ç–∞—é—Ç –Ω–∞ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚úÖ –•–æ—Ä–æ—à–∏ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n",
    "- ‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –ª–∏–Ω–µ–π–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏\n",
    "- ‚ùå –ü–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞—é—Ç —Å multivariate –¥–∞–Ω–Ω—ã–º–∏\n",
    "\n",
    "**Deep Learning (LSTM, GRU)**:\n",
    "- ‚úÖ –í—ã—É—á–∏–≤–∞—é—Ç —Å–ª–æ–∂–Ω—ã–µ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
    "- ‚úÖ –†–∞–±–æ—Ç–∞—é—Ç —Å multivariate –¥–∞–Ω–Ω—ã–º–∏\n",
    "- ‚úÖ –ú–æ–≥—É—Ç –≤—ã—É—á–∏—Ç—å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "- ‚ùå –¢—Ä–µ–±—É—é—Ç –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚ùå –î–æ–ª–≥–æ –æ–±—É—á–∞—é—Ç—Å—è\n",
    "- ‚ùå –°–ª–æ–∂–Ω–µ–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å\n",
    "- ‚ùå –°–∫–ª–æ–Ω–Ω—ã –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é\n",
    "\n",
    "### 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n",
    "\n",
    "**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ ARIMA/SARIMA/Prophet –µ—Å–ª–∏:**\n",
    "- Univariate –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n",
    "- –ú–∞–ª–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (<1000 —Ç–æ—á–µ–∫)\n",
    "- –ù—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å\n",
    "- –Ø–≤–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å\n",
    "\n",
    "**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ LSTM/GRU –µ—Å–ª–∏:**\n",
    "- Multivariate –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã\n",
    "- –ú–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö (>10,000 —Ç–æ—á–µ–∫)\n",
    "- –°–ª–æ–∂–Ω—ã–µ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "- –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "\n",
    "### 5. –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
    "- Attention –º–µ—Ö–∞–Ω–∏–∑–º—ã –¥–ª—è LSTM\n",
    "- Transformer –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
    "- –ê–Ω—Å–∞–º–±–ª—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –∏ DL –º–µ—Ç–æ–¥–æ–≤\n",
    "- –ê–Ω–æ–º–∞–ª–∏—è detection –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "lstm_model.save('../models/lstm_airline.h5')\n",
    "gru_model.save('../models/gru_airline.h5')\n",
    "stock_lstm_model.save('../models/lstm_stock.h5')\n",
    "joblib.dump(scaler, '../models/scaler_airline.pkl')\n",
    "joblib.dump(scaler_stock, '../models/scaler_stock.pkl')\n",
    "\n",
    "print('‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É models/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
