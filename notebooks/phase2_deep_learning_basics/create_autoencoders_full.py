#!/usr/bin/env python3
"""
–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞: Autoencoders (Vanilla, Denoising, VAE)
Phase 2, Step 3 - FINALE
"""

import json

notebook = {
    "cells": [],
    "metadata": {
        "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
        "language_info": {"name": "python", "version": "3.8.0"}
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

cells = []

# ============================================================================
# TITLE
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "# üîÑ Autoencoders: Unsupervised Deep Learning\n",
        "\n",
        "**Phase 2: Deep Learning Basics - Step 3 (FINALE)**\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ –¶–µ–ª–∏ –Ω–æ—É—Ç–±—É–∫–∞\n",
        "\n",
        "1. **Vanilla Autoencoder:** –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "2. **Denoising Autoencoder:** –û–±—É—á–µ–Ω–∏–µ —Ä–æ–±–∞—Å—Ç–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º\n",
        "3. **Variational Autoencoder (VAE):** –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å\n",
        "4. **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è:** Anomaly detection, dimensionality reduction, data generation\n",
        "\n",
        "---\n",
        "\n",
        "## üíº –ë–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–∏ –¥–ª—è Autoencoders\n",
        "\n",
        "**1. Anomaly Detection (–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π):**\n",
        "- üè¶ Fraud detection (–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ –≤ –±–∞–Ω–∫–∞—Ö)\n",
        "- üè≠ Defect detection (–¥–µ—Ñ–µ–∫—Ç—ã –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ)\n",
        "- üîí Intrusion detection (–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)\n",
        "\n",
        "**2. Dimensionality Reduction:**\n",
        "- üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "- ‚ö° Preprocessing –¥–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π\n",
        "- üíæ –°–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "**3. Data Generation (VAE):**\n",
        "- üé® –°–∏–Ω—Ç–µ–∑ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
        "- üß¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–ª–µ–∫—É–ª (drug discovery)\n",
        "- üé≠ Creative applications\n",
        "\n",
        "**–ü–æ—á–µ–º—É Unsupervised?**\n",
        "- ‚úÖ –ù–µ –Ω—É–∂–Ω—ã –º–µ—Ç–∫–∏ (labels)\n",
        "- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ª—é–±—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "- ‚úÖ –ù–∞—Ö–æ–¥–∏—Ç —Å–∫—Ä—ã—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
        "\n",
        "---"
    ]
})

# ============================================================================
# THEORY: VANILLA AUTOENCODER
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "## üìö –ß–∞—Å—Ç—å 1: –¢–µ–æ—Ä–∏—è Autoencoders\n",
        "\n",
        "### 1.1 Vanilla Autoencoder - –ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
        "\n",
        "**Autoencoder** ‚Äî –Ω–µ–π—Ä–æ—Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –æ–±—É—á–∞–µ—Ç—Å—è **–≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –≤—Ö–æ–¥** —á–µ—Ä–µ–∑ —É–∑–∫–æ–µ bottleneck.\n",
        "\n",
        "#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
        "\n",
        "```\n",
        "Input (x) ‚Üí Encoder ‚Üí Latent (z) ‚Üí Decoder ‚Üí Output (xÃÇ)\n",
        "```\n",
        "\n",
        "**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:**\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "z &= f_{\\text{enc}}(x; \\theta_{\\text{enc}}) \\quad \\text{(Encoder)} \\\\\n",
        "\\hat{x} &= f_{\\text{dec}}(z; \\theta_{\\text{dec}}) \\quad \\text{(Decoder)} \\\\\n",
        "\\mathcal{L} &= \\|x - \\hat{x}\\|^2 \\quad \\text{(Reconstruction loss)}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $x$ ‚Äî –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–∞—Å—Å–∞–∂–∏—Ä –¢–∏—Ç–∞–Ω–∏–∫–∞)\n",
        "- $z$ ‚Äî latent representation (—Å–∂–∞—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ)\n",
        "- $\\hat{x}$ ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
        "- $\\theta$ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∏\n",
        "\n",
        "#### –ó–∞—á–µ–º bottleneck (—É–∑–∫–æ–µ –º–µ—Å—Ç–æ)?\n",
        "\n",
        "**–ï—Å–ª–∏ latent —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å < input —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:**\n",
        "- ‚úÖ **Compression:** –°–µ—Ç—å –≤—ã–Ω—É–∂–¥–µ–Ω–∞ –≤—ã—É—á–∏—Ç—å **–∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ** –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ\n",
        "- ‚úÖ **Feature learning:** Latent space —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "- ‚úÖ **Dimensionality reduction:** –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ PCA\n",
        "\n",
        "**–ï—Å–ª–∏ latent —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å ‚â• input —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:**\n",
        "- ‚ùå **Identity mapping:** –°–µ—Ç—å –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ—Ç –≤—Ö–æ–¥ (–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ)\n",
        "\n",
        "**–ü—Ä–∏–º–µ—Ä:**\n",
        "```\n",
        "Input: 10 features ‚Üí Encoder: [10 ‚Üí 8 ‚Üí 4] ‚Üí Latent: 2\n",
        "                  ‚Üí Decoder: [2 ‚Üí 4 ‚Üí 8] ‚Üí Output: 10 features\n",
        "```\n",
        "\n",
        "–°–∂–∞–ª–∏ 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí 2 latent dimensions!\n",
        "\n",
        "---"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 1.2 Denoising Autoencoder\n",
        "\n",
        "**–ü—Ä–æ–±–ª–µ–º–∞ Vanilla AE:** –ú–æ–∂–µ—Ç –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (overfitting).\n",
        "\n",
        "**–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª—è–µ–º **—à—É–º** –∫ –≤—Ö–æ–¥—É, –∑–∞—Å—Ç–∞–≤–ª—è–µ–º –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å **—á–∏—Å—Ç—ã–µ** –¥–∞–Ω–Ω—ã–µ.\n",
        "\n",
        "#### –ê–ª–≥–æ—Ä–∏—Ç–º\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\tilde{x} &= x + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2) \\quad \\text{(Add noise)} \\\\\n",
        "z &= f_{\\text{enc}}(\\tilde{x}) \\\\\n",
        "\\hat{x} &= f_{\\text{dec}}(z) \\\\\n",
        "\\mathcal{L} &= \\|x - \\hat{x}\\|^2 \\quad \\text{(Reconstruct CLEAN data!)}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**–≠—Ñ—Ñ–µ–∫—Ç:**\n",
        "- ‚úÖ **Robustness:** –°–µ—Ç—å —É—á–∏—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–µ –∫ —à—É–º—É –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "- ‚úÖ **Regularization:** –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–µ –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ\n",
        "- ‚úÖ **Better features:** Latent space –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω\n",
        "\n",
        "**–¢–∏–ø—ã —à—É–º–∞:**\n",
        "1. **Gaussian noise:** $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$\n",
        "2. **Masking noise:** –°–ª—É—á–∞–π–Ω–æ –∑–∞–Ω—É–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "3. **Salt-and-pepper:** –°–ª—É—á–∞–π–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã\n",
        "\n",
        "**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**\n",
        "- üîä **Audio denoising:** –û—á–∏—Å—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π –æ—Ç —à—É–º–∞\n",
        "- üñºÔ∏è **Image denoising:** –£–¥–∞–ª–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤\n",
        "- üìä **Data cleaning:** –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "---"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 1.3 Variational Autoencoder (VAE)\n",
        "\n",
        "**Vanilla AE –ø—Ä–æ–±–ª–µ–º–∞:** Latent space –º–æ–∂–µ—Ç –±—ã—Ç—å **–Ω–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º** ‚Äî –Ω–µ–±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ $z$ –¥–∞—é—Ç –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
        "\n",
        "**VAE —Ä–µ—à–µ–Ω–∏–µ:** –í–º–µ—Å—Ç–æ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ $z$, –∏—Å–ø–æ–ª—å–∑—É–µ–º **—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ** $p(z|x)$.\n",
        "\n",
        "#### –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞\n",
        "\n",
        "**–¶–µ–ª—å:** –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å $\\log p(x)$ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö).\n",
        "\n",
        "**–ü—Ä–æ–±–ª–µ–º–∞:** $p(x) = \\int p(x|z) p(z) dz$ ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞–ª –Ω–µ—Ä–∞–∑—Ä–µ—à–∏–º.\n",
        "\n",
        "**–†–µ—à–µ–Ω–∏–µ:** Variational Inference ‚Äî –ø—Ä–∏–±–ª–∏–∂–∞–µ–º $p(z|x)$ —Å –ø–æ–º–æ—â—å—é $q(z|x)$.\n",
        "\n",
        "#### Evidence Lower Bound (ELBO)\n",
        "\n",
        "$$\n",
        "\\log p(x) \\geq \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - D_{KL}(q(z|x) \\| p(z))\n",
        "$$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $\\mathbb{E}_{q(z|x)}[\\log p(x|z)]$ ‚Äî **Reconstruction term** (–∫–∞–∫ —Ö–æ—Ä–æ—à–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º)\n",
        "- $D_{KL}(q(z|x) \\| p(z))$ ‚Äî **KL divergence** (–Ω–∞—Å–∫–æ–ª—å–∫–æ $q$ –±–ª–∏–∑–∫–æ –∫ prior $p$)\n",
        "\n",
        "#### VAE Architecture\n",
        "\n",
        "**Encoder:** –í—ã–¥–∞—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è $q(z|x) = \\mathcal{N}(\\mu, \\sigma^2)$\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mu &= f_{\\mu}(x; \\theta_{\\text{enc}}) \\\\\n",
        "\\log \\sigma^2 &= f_{\\sigma}(x; \\theta_{\\text{enc}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Reparameterization trick:** –°—ç–º–ø–ª–∏—Ä—É–µ–º $z$:\n",
        "\n",
        "$$z = \\mu + \\sigma \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)$$\n",
        "\n",
        "(–ü–æ–∑–≤–æ–ª—è–µ—Ç backpropagation —á–µ—Ä–µ–∑ —Å–ª—É—á–∞–π–Ω—É—é –≤–µ–ª–∏—á–∏–Ω—É!)\n",
        "\n",
        "**Decoder:** –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç $x$ –∏–∑ $z$:\n",
        "\n",
        "$$\\hat{x} = f_{\\text{dec}}(z; \\theta_{\\text{dec}})$$\n",
        "\n",
        "**Loss Function:**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{VAE}} = \\underbrace{\\|x - \\hat{x}\\|^2}_{\\text{Reconstruction}} + \\underbrace{D_{KL}(\\mathcal{N}(\\mu, \\sigma^2) \\| \\mathcal{N}(0, I))}_{\\text{KL term}}\n",
        "$$\n",
        "\n",
        "**KL divergence (–¥–ª—è Gaussian):**\n",
        "\n",
        "$$D_{KL} = \\frac{1}{2} \\sum_{j=1}^J \\left( 1 + \\log(\\sigma_j^2) - \\mu_j^2 - \\sigma_j^2 \\right)$$\n",
        "\n",
        "–≥–¥–µ $J$ ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å latent space.\n",
        "\n",
        "**–ü–æ—á–µ–º—É VAE –ª—É—á—à–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏?**\n",
        "- ‚úÖ **Smooth latent space:** –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç\n",
        "- ‚úÖ **Sampling:** –ú–æ–∂–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã: $z \\sim \\mathcal{N}(0, I)$, $x_{\\text{new}} = f_{\\text{dec}}(z)$\n",
        "- ‚úÖ **Probabilistic:** –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–∞\n",
        "\n",
        "---"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 1.4 –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è Autoencoders\n",
        "\n",
        "#### 1.4.1 Anomaly Detection\n",
        "\n",
        "**–ò–¥–µ—è:** –ê–Ω–æ–º–∞–ª–∏–∏ –ø–ª–æ—Ö–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è!\n",
        "\n",
        "**–ê–ª–≥–æ—Ä–∏—Ç–º:**\n",
        "```\n",
        "1. –û–±—É—á–∏—Ç—å Autoencoder –Ω–∞ –ù–û–†–ú–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö\n",
        "2. –î–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ x:\n",
        "   - –í—ã—á–∏—Å–ª–∏—Ç—å reconstruction error: e = ||x - xÃÇ||¬≤\n",
        "   - –ï—Å–ª–∏ e > threshold ‚Üí –ê–ù–û–ú–ê–õ–ò–Ø\n",
        "```\n",
        "\n",
        "**–ü—Ä–∏–º–µ—Ä (Titanic):**\n",
        "- –û–±—É—á–∞–µ–º –Ω–∞ –í–´–ñ–ò–í–®–ò–• –ø–∞—Å—Å–∞–∂–∏—Ä–∞—Ö\n",
        "- –ü–æ–≥–∏–±—à–∏–µ –ø–∞—Å—Å–∞–∂–∏—Ä—ã –±—É–¥—É—Ç –∏–º–µ—Ç—å –≤—ã—Å–æ–∫–∏–π reconstruction error\n",
        "\n",
        "**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**\n",
        "- üí≥ Credit card fraud (–æ–±—É—á–∞–µ–º –Ω–∞ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö)\n",
        "- üè≠ Manufacturing defects (–æ–±—É—á–∞–µ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–¥–µ–ª–∏—è—Ö)\n",
        "- üîí Network intrusions (–æ–±—É—á–∞–µ–º –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ç—Ä–∞—Ñ–∏–∫–µ)\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.4.2 Dimensionality Reduction vs PCA\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å | Supervised | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ |\n",
        "|-------|-----------|------------|-------------|\n",
        "| **PCA** | –õ–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –ë—ã—Å—Ç—Ä–æ, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ |\n",
        "| **Autoencoder** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –°–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –≥–∏–±–∫–æ—Å—Ç—å |\n",
        "| **t-SNE** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ |\n",
        "| **UMAP** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –ë—ã—Å—Ç—Ä–µ–µ t-SNE, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É |\n",
        "\n",
        "**–ö–æ–≥–¥–∞ Autoencoder –ª—É—á—à–µ PCA:**\n",
        "- ‚úÖ –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ –¥–∞–Ω–Ω—ã—Ö\n",
        "- ‚úÖ –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ (–º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å batch-–∞–º–∏)\n",
        "- ‚úÖ –ù—É–∂–Ω–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (–Ω–µ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–µ–∫—Ü–∏—è)\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.4.3 Data Generation (VAE)\n",
        "\n",
        "**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤:**\n",
        "```python\n",
        "# Sample from prior\n",
        "z_new = torch.randn(latent_dim)\n",
        "\n",
        "# Decode\n",
        "x_new = decoder(z_new)\n",
        "```\n",
        "\n",
        "**–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è:**\n",
        "```python\n",
        "# Encode two examples\n",
        "z1 = encoder(x1)\n",
        "z2 = encoder(x2)\n",
        "\n",
        "# Interpolate in latent space\n",
        "for alpha in [0, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
        "    z_interp = alpha * z1 + (1 - alpha) * z2\n",
        "    x_interp = decoder(z_interp)\n",
        "```\n",
        "\n",
        "**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**\n",
        "- üé® Image generation (faces, art)\n",
        "- üéµ Music generation\n",
        "- üß¨ Molecule design (drug discovery)\n",
        "- üìä Data augmentation (—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)\n",
        "\n",
        "---\n",
        "\n",
        "## –¢–µ–æ—Ä–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø—Ä–∞–∫—Ç–∏–∫–µ üöÄ\n",
        "\n",
        "---"
    ]
})

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ
notebook['cells'] = cells
output_path = '/home/user/test/notebooks/phase2_deep_learning_basics/03_autoencoders.ipynb'
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f'‚úÖ –¢–µ–æ—Ä–∏—è —Å–æ–∑–¥–∞–Ω–∞: {len(cells)} —è—á–µ–µ–∫')
print(f'–§–∞–π–ª: {output_path}')
print('–î–æ–±–∞–≤–ª—è—é –ø—Ä–∞–∫—Ç–∏–∫—É...')

# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç - –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å
print(f'–¢–µ–æ—Ä–∏—è Autoencoders –≥–æ—Ç–æ–≤–∞!')
