{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полный анализ датасета Титаник\n",
    "\n",
    "## Введение\n",
    "\n",
    "Этот ноутбук содержит **подробный анализ** знаменитого датасета Титаник. Мы проведем:\n",
    "\n",
    "1. **Исследовательский анализ данных (EDA)**\n",
    "2. **Визуализацию данных**\n",
    "3. **Предобработку и очистку данных**\n",
    "4. **Feature Engineering**\n",
    "5. **Построение предсказательных моделей**\n",
    "6. **Оценку и сравнение моделей**\n",
    "\n",
    "---\n",
    "\n",
    "## О датасете\n",
    "\n",
    "**Датасет Титаник** содержит информацию о пассажирах легендарного корабля RMS Titanic, затонувшего 15 апреля 1912 года. Наша цель - предсказать выживаемость пассажиров на основе различных характеристик.\n",
    "\n",
    "### Основные признаки:\n",
    "\n",
    "- `PassengerId` - уникальный идентификатор пассажира\n",
    "- `Survived` - выживаемость (0 = Нет, 1 = Да) - **целевая переменная**\n",
    "- `Pclass` - класс билета (1 = 1-й класс, 2 = 2-й класс, 3 = 3-й класс)\n",
    "- `Name` - имя пассажира\n",
    "- `Sex` - пол\n",
    "- `Age` - возраст в годах\n",
    "- `SibSp` - количество братьев/сестер/супругов на борту\n",
    "- `Parch` - количество родителей/детей на борту\n",
    "- `Ticket` - номер билета\n",
    "- `Fare` - стоимость билета\n",
    "- `Cabin` - номер каюты\n",
    "- `Embarked` - порт посадки (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорт необходимых библиотек\n",
    "\n",
    "Начнем с импорта всех необходимых библиотек для анализа данных, визуализации и машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Основные библиотеки для работы с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Настройка стиля визуализации\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с предупреждениями\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Машинное обучение\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "print(\"Все библиотеки успешно импортированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка данных\n",
    "\n",
    "Загружаем датасет Титаник. Данные можно получить из библиотеки seaborn или напрямую с Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Загрузка данных из seaborn\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Создаем копию для сохранения оригинальных данных\n",
    "df_original = df.copy()\n",
    "\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Количество строк: {df.shape[0]}\")\n",
    "print(f\"Количество признаков: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Первичный осмотр данных\n",
    "\n",
    "Изучим структуру данных и получим общее представление о датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Первые строки датасета\n",
    "print(\"Первые 10 строк датасета:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Информация о типах данных и пропущенных значениях\n",
    "print(\"Информация о датасете:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Статистическое описание числовых признаков\n",
    "print(\"Статистическое описание числовых признаков:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Статистика по категориальным признакам\n",
    "print(\"Статистика по категориальным признакам:\")\n",
    "df.describe(include=['object', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Анализ пропущенных значений\n",
    "\n",
    "Пропущенные значения могут существенно влиять на качество моделей. Важно идентифицировать и правильно обработать их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Подсчет пропущенных значений\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Признак': missing_values.index,\n",
    "    'Пропущено значений': missing_values.values,\n",
    "    'Процент': missing_percent.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Пропущено значений'] > 0].sort_values('Пропущено значений', ascending=False)\n",
    "\n",
    "print(\"Пропущенные значения в датасете:\")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация пропущенных значений\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=True, cmap='viridis', yticklabels=False)\n",
    "plt.title('Матрица пропущенных значений', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Признаки', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Исследовательский анализ данных (EDA)\n",
    "\n",
    "### 5.1 Анализ целевой переменной (Survived)\n",
    "\n",
    "Изучим распределение выживших и погибших пассажиров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Подсчет выживших\n",
    "survival_counts = df['survived'].value_counts()\n",
    "survival_percent = 100 * df['survived'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Распределение выживших:\")\n",
    "print(f\"Погибло (0): {survival_counts[0]} ({survival_percent[0]:.2f}%)\")\n",
    "print(f\"Выжило (1): {survival_counts[1]} ({survival_percent[1]:.2f}%)\")\n",
    "print(f\"\\nОбщий уровень выживаемости: {survival_percent[1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Столбчатая диаграмма\n",
    "sns.countplot(data=df, x='survived', ax=axes[0], palette='Set2')\n",
    "axes[0].set_title('Количество выживших и погибших', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Выживаемость (0 = Погиб, 1 = Выжил)', fontsize=12)\n",
    "axes[0].set_ylabel('Количество', fontsize=12)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container)\n",
    "\n",
    "# Круговая диаграмма\n",
    "axes[1].pie(survival_counts, labels=['Погибло', 'Выжило'], autopct='%1.1f%%', \n",
    "            startangle=90, colors=['#ff9999', '#66b3ff'])\n",
    "axes[1].set_title('Процентное соотношение выживших', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Анализ выживаемости по полу\n",
    "\n",
    "Известно, что при эвакуации приоритет отдавался женщинам и детям. Проверим эту гипотезу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Выживаемость по полу\n",
    "sex_survival = pd.crosstab(df['sex'], df['survived'], normalize='index') * 100\n",
    "print(\"Процент выживаемости по полу:\")\n",
    "print(sex_survival)\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Сгруппированная столбчатая диаграмма\n",
    "sex_counts = pd.crosstab(df['sex'], df['survived'])\n",
    "sex_counts.plot(kind='bar', ax=axes[0], color=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0].set_title('Выживаемость по полу', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Пол', fontsize=12)\n",
    "axes[0].set_ylabel('Количество', fontsize=12)\n",
    "axes[0].set_xticklabels(['Женщины', 'Мужчины'], rotation=0)\n",
    "axes[0].legend(['Погибло', 'Выжило'])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Процентная диаграмма\n",
    "sex_survival.plot(kind='bar', ax=axes[1], stacked=True, color=['#ff6b6b', '#4ecdc4'])\n",
    "axes[1].set_title('Процент выживаемости по полу', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Пол', fontsize=12)\n",
    "axes[1].set_ylabel('Процент', fontsize=12)\n",
    "axes[1].set_xticklabels(['Женщины', 'Мужчины'], rotation=0)\n",
    "axes[1].legend(['Погибло', 'Выжило'])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Анализ выживаемости по классу билета\n",
    "\n",
    "Класс билета может отражать социально-экономический статус пассажира и его расположение на корабле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Выживаемость по классу\n",
    "pclass_survival = pd.crosstab(df['pclass'], df['survived'], normalize='index') * 100\n",
    "print(\"Процент выживаемости по классу:\")\n",
    "print(pclass_survival)\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Сгруппированная столбчатая диаграмма\n",
    "pclass_counts = pd.crosstab(df['pclass'], df['survived'])\n",
    "pclass_counts.plot(kind='bar', ax=axes[0], color=['#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Выживаемость по классу билета', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Класс билета', fontsize=12)\n",
    "axes[0].set_ylabel('Количество', fontsize=12)\n",
    "axes[0].set_xticklabels(['1-й класс', '2-й класс', '3-й класс'], rotation=0)\n",
    "axes[0].legend(['Погибло', 'Выжило'])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Процентная диаграмма\n",
    "pclass_survival.plot(kind='bar', ax=axes[1], stacked=True, color=['#e74c3c', '#2ecc71'])\n",
    "axes[1].set_title('Процент выживаемости по классу билета', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Класс билета', fontsize=12)\n",
    "axes[1].set_ylabel('Процент', fontsize=12)\n",
    "axes[1].set_xticklabels(['1-й класс', '2-й класс', '3-й класс'], rotation=0)\n",
    "axes[1].legend(['Погибло', 'Выжило'])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Комбинированный анализ: пол и класс\n",
    "\n",
    "Посмотрим, как взаимодействуют факторы пола и класса билета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Создаем сводную таблицу\n",
    "sex_pclass_survival = df.groupby(['sex', 'pclass'])['survived'].mean() * 100\n",
    "print(\"Процент выживаемости по полу и классу:\")\n",
    "print(sex_pclass_survival)\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df, x='pclass', y='survived', hue='sex', palette='Set1')\n",
    "plt.title('Выживаемость по классу билета и полу', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Класс билета', fontsize=12)\n",
    "plt.ylabel('Доля выживших', fontsize=12)\n",
    "plt.legend(title='Пол', labels=['Женщины', 'Мужчины'])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Анализ возраста\n",
    "\n",
    "Изучим распределение возраста пассажиров и его влияние на выживаемость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Статистика по возрасту\n",
    "print(\"Статистика по возрасту:\")\n",
    "print(df['age'].describe())\n",
    "print(f\"\\nСредний возраст: {df['age'].mean():.2f} лет\")\n",
    "print(f\"Медианный возраст: {df['age'].median():.2f} лет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация распределения возраста\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Гистограмма возраста\n",
    "axes[0, 0].hist(df['age'].dropna(), bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Распределение возраста пассажиров', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Возраст', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Частота', fontsize=12)\n",
    "axes[0, 0].axvline(df['age'].mean(), color='red', linestyle='--', label=f'Среднее: {df['age'].mean():.1f}')\n",
    "axes[0, 0].axvline(df['age'].median(), color='green', linestyle='--', label=f'Медиана: {df['age'].median():.1f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Распределение возраста по выживаемости\n",
    "df[df['survived']==1]['age'].hist(bins=30, ax=axes[0, 1], color='green', alpha=0.6, label='Выжили')\n",
    "df[df['survived']==0]['age'].hist(bins=30, ax=axes[0, 1], color='red', alpha=0.6, label='Погибли')\n",
    "axes[0, 1].set_title('Распределение возраста по выживаемости', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Возраст', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Частота', fontsize=12)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Box plot возраста по выживаемости\n",
    "sns.boxplot(data=df, x='survived', y='age', ax=axes[1, 0], palette='Set2')\n",
    "axes[1, 0].set_title('Возраст по выживаемости (Box Plot)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Выживаемость (0 = Погиб, 1 = Выжил)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Возраст', fontsize=12)\n",
    "\n",
    "# 4. Violin plot возраста по выживаемости и полу\n",
    "sns.violinplot(data=df, x='survived', y='age', hue='sex', split=True, ax=axes[1, 1], palette='muted')\n",
    "axes[1, 1].set_title('Возраст по выживаемости и полу (Violin Plot)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Выживаемость (0 = Погиб, 1 = Выжил)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Возраст', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Анализ стоимости билета (Fare)\n",
    "\n",
    "Стоимость билета также может коррелировать с выживаемостью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Статистика по стоимости билета\n",
    "print(\"Статистика по стоимости билета:\")\n",
    "print(df['fare'].describe())\n",
    "print(f\"\\nСредняя стоимость: ${df['fare'].mean():.2f}\")\n",
    "print(f\"Медианная стоимость: ${df['fare'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Распределение стоимости\n",
    "axes[0].hist(df['fare'], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Распределение стоимости билетов', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Стоимость билета ($)', fontsize=12)\n",
    "axes[0].set_ylabel('Частота', fontsize=12)\n",
    "axes[0].set_xlim(0, 300)  # Ограничение для лучшей видимости\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Box plot стоимости по классу\n",
    "sns.boxplot(data=df, x='pclass', y='fare', ax=axes[1], palette='Pastel1')\n",
    "axes[1].set_title('Стоимость билета по классу', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Класс билета', fontsize=12)\n",
    "axes[1].set_ylabel('Стоимость ($)', fontsize=12)\n",
    "axes[1].set_ylim(0, 300)\n",
    "\n",
    "# 3. Box plot стоимости по выживаемости\n",
    "sns.boxplot(data=df, x='survived', y='fare', ax=axes[2], palette='Set3')\n",
    "axes[2].set_title('Стоимость билета по выживаемости', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Выживаемость (0 = Погиб, 1 = Выжил)', fontsize=12)\n",
    "axes[2].set_ylabel('Стоимость ($)', fontsize=12)\n",
    "axes[2].set_ylim(0, 300)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Анализ порта посадки (Embarked)\n",
    "\n",
    "Порт посадки может косвенно указывать на социально-экономический статус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Выживаемость по порту посадки\n",
    "embarked_survival = pd.crosstab(df['embarked'], df['survived'], normalize='index') * 100\n",
    "print(\"Процент выживаемости по порту посадки:\")\n",
    "print(embarked_survival)\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Количество по портам\n",
    "embarked_counts = df['embarked'].value_counts()\n",
    "sns.countplot(data=df, x='embarked', hue='survived', ax=axes[0], palette='viridis')\n",
    "axes[0].set_title('Выживаемость по порту посадки', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Порт (C=Cherbourg, Q=Queenstown, S=Southampton)', fontsize=12)\n",
    "axes[0].set_ylabel('Количество', fontsize=12)\n",
    "axes[0].legend(['Погибло', 'Выжило'])\n",
    "\n",
    "# Процентная диаграмма\n",
    "embarked_survival.plot(kind='bar', ax=axes[1], stacked=True, color=['#d62728', '#2ca02c'])\n",
    "axes[1].set_title('Процент выживаемости по порту посадки', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Порт посадки', fontsize=12)\n",
    "axes[1].set_ylabel('Процент', fontsize=12)\n",
    "axes[1].set_xticklabels(['Cherbourg', 'Queenstown', 'Southampton'], rotation=45)\n",
    "axes[1].legend(['Погибло', 'Выжило'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Анализ размера семьи\n",
    "\n",
    "Создадим новый признак - размер семьи на борту (Family_Size = SibSp + Parch + 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Создание признака размера семьи\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "\n",
    "print(\"Распределение размера семьи:\")\n",
    "print(df['family_size'].value_counts().sort_index())\n",
    "\n",
    "# Выживаемость по размеру семьи\n",
    "family_survival = df.groupby('family_size')['survived'].mean()\n",
    "print(\"\\nВыживаемость по размеру семьи:\")\n",
    "print(family_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Количество по размеру семьи\n",
    "df['family_size'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='teal', alpha=0.7)\n",
    "axes[0].set_title('Распределение размера семьи', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Размер семьи', fontsize=12)\n",
    "axes[0].set_ylabel('Количество', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Выживаемость по размеру семьи\n",
    "family_survival.plot(kind='bar', ax=axes[1], color='orange', alpha=0.7)\n",
    "axes[1].set_title('Выживаемость по размеру семьи', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Размер семьи', fontsize=12)\n",
    "axes[1].set_ylabel('Доля выживших', fontsize=12)\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "axes[1].axhline(y=df['survived'].mean(), color='r', linestyle='--', label='Средняя выживаемость')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Корреляционный анализ\n",
    "\n",
    "Изучим корреляции между числовыми признаками.\n",
    "\n",
    "**Коэффициент корреляции Пирсона** измеряет линейную зависимость между двумя переменными:\n",
    "\n",
    "$$r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}}$$\n",
    "\n",
    "где:\n",
    "- $r \\in [-1, 1]$\n",
    "- $r = 1$: полная положительная корреляция\n",
    "- $r = -1$: полная отрицательная корреляция\n",
    "- $r = 0$: отсутствие линейной корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Выбираем числовые признаки\n",
    "numeric_features = ['survived', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'family_size']\n",
    "correlation_matrix = df[numeric_features].corr()\n",
    "\n",
    "print(\"Корреляция признаков с выживаемостью:\")\n",
    "print(correlation_matrix['survived'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация корреляционной матрицы\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Корреляционная матрица признаков', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Предобработка данных\n",
    "\n",
    "### 6.1 Обработка пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Создаем копию для предобработки\n",
    "df_processed = df.copy()\n",
    "\n",
    "# 1. Заполнение пропущенных значений Age медианой по группам (пол + класс)\n",
    "df_processed['age'] = df_processed.groupby(['sex', 'pclass'])['age'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# 2. Заполнение Embarked модой (наиболее частым значением)\n",
    "df_processed['embarked'].fillna(df_processed['embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 3. Заполнение Fare медианой\n",
    "df_processed['fare'].fillna(df_processed['fare'].median(), inplace=True)\n",
    "\n",
    "# 4. Удаляем признаки с большим количеством пропусков или малой информативностью\n",
    "df_processed.drop(['deck', 'embark_town'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "print(\"Пропущенные значения после обработки:\")\n",
    "print(df_processed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Feature Engineering\n",
    "\n",
    "Создадим дополнительные признаки для улучшения предсказательной способности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 1. Создаем категориальный признак размера семьи\n",
    "df_processed['is_alone'] = (df_processed['family_size'] == 1).astype(int)\n",
    "\n",
    "# 2. Создаем возрастные группы\n",
    "df_processed['age_group'] = pd.cut(df_processed['age'], \n",
    "                                     bins=[0, 12, 18, 35, 60, 100],\n",
    "                                     labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "\n",
    "# 3. Создаем категории стоимости билета\n",
    "df_processed['fare_category'] = pd.qcut(df_processed['fare'], \n",
    "                                          q=4, \n",
    "                                          labels=['Low', 'Medium', 'High', 'Very High'],\n",
    "                                          duplicates='drop')\n",
    "\n",
    "# 4. Извлекаем титул из имени\n",
    "df_processed['title'] = df_processed['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Группируем редкие титулы\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "    'Rev': 'Rare', 'Dr': 'Rare', 'Col': 'Rare', 'Major': 'Rare', \n",
    "    'Mlle': 'Miss', 'Mme': 'Mrs', 'Don': 'Rare', 'Dona': 'Rare',\n",
    "    'Lady': 'Rare', 'Countess': 'Rare', 'Jonkheer': 'Rare', 'Sir': 'Rare',\n",
    "    'Capt': 'Rare', 'Ms': 'Miss'\n",
    "}\n",
    "df_processed['title'] = df_processed['title'].map(title_mapping)\n",
    "df_processed['title'].fillna('Rare', inplace=True)\n",
    "\n",
    "print(\"Новые признаки созданы!\")\n",
    "print(f\"\\nУникальные титулы: {df_processed['title'].unique()}\")\n",
    "print(f\"\\nРаспределение по титулам:\")\n",
    "print(df_processed['title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Создаем копию для моделирования\n",
    "df_model = df_processed.copy()\n",
    "\n",
    "# Label Encoding для бинарных признаков\n",
    "df_model['sex'] = df_model['sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# One-Hot Encoding для категориальных признаков\n",
    "categorical_features = ['embarked', 'title', 'age_group', 'fare_category']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in df_model.columns:\n",
    "        dummies = pd.get_dummies(df_model[feature], prefix=feature, drop_first=True)\n",
    "        df_model = pd.concat([df_model, dummies], axis=1)\n",
    "        df_model.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "# Удаляем ненужные признаки\n",
    "features_to_drop = ['name', 'ticket', 'cabin', 'alive', 'adult_male', 'who', 'alone', 'class']\n",
    "df_model.drop(features_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "print(\"Финальный набор признаков:\")\n",
    "print(df_model.columns.tolist())\n",
    "print(f\"\\nРазмер датасета: {df_model.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Подготовка данных для моделирования\n",
    "\n",
    "Разделим данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Разделение на признаки (X) и целевую переменную (y)\n",
    "X = df_model.drop('survived', axis=1)\n",
    "y = df_model['survived']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "print(f\"\\nРаспределение классов в обучающей выборке:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nРаспределение классов в тестовой выборке:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Масштабирование признаков\n",
    "\n",
    "Некоторые алгоритмы (например, логистическая регрессия, SVM) чувствительны к масштабу признаков.\n",
    "\n",
    "**Стандартизация (Z-score normalization)**:\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "где $\\mu$ - среднее, $\\sigma$ - стандартное отклонение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Инициализация scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Масштабирование только на обучающих данных\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Преобразование обратно в DataFrame для удобства\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Масштабирование признаков завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Построение моделей машинного обучения\n",
    "\n",
    "Обучим несколько различных моделей и сравним их производительность.\n",
    "\n",
    "### 8.1 Базовая модель - Логистическая регрессия\n",
    "\n",
    "**Логистическая регрессия** использует логистическую функцию (сигмоиду) для предсказания вероятности класса:\n",
    "\n",
    "$$P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "y_pred_proba_log = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Оценка\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Точность логистической регрессии: {acc_log:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_log = cross_val_score(log_reg, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Средняя точность на кросс-валидации: {cv_scores_log.mean():.4f} (+/- {cv_scores_log.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "dt = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_proba_dt = dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Оценка\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Точность дерева решений: {acc_dt:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_dt = cross_val_score(dt, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Средняя точность на кросс-валидации: {cv_scores_dt.mean():.4f} (+/- {cv_scores_dt.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Random Forest (Случайный лес)\n",
    "\n",
    "**Random Forest** - это ансамблевый метод, который строит множество деревьев решений и объединяет их предсказания.\n",
    "\n",
    "Итоговое предсказание для классификации:\n",
    "\n",
    "$$\\hat{y} = \\text{mode}\\{h_1(x), h_2(x), ..., h_B(x)\\}$$\n",
    "\n",
    "где $h_i(x)$ - предсказание $i$-го дерева, $B$ - количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Оценка\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Точность Random Forest: {acc_rf:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_rf = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Средняя точность на кросс-валидации: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Gradient Boosting\n",
    "\n",
    "**Gradient Boosting** последовательно обучает модели, где каждая новая модель корректирует ошибки предыдущих."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=3, learning_rate=0.1)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "y_pred_proba_gb = gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Оценка\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Точность Gradient Boosting: {acc_gb:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_gb = cross_val_score(gb, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Средняя точность на кросс-валидации: {cv_scores_gb.mean():.4f} (+/- {cv_scores_gb.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "svm = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "y_pred_proba_svm = svm.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Оценка\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"Точность SVM: {acc_svm:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_svm = cross_val_score(svm, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Средняя точность на кросс-валидации: {cv_scores_svm.mean():.4f} (+/- {cv_scores_svm.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "y_pred_proba_knn = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Оценка\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"Точность KNN: {acc_knn:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_knn = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Средняя точность на кросс-валидации: {cv_scores_knn.mean():.4f} (+/- {cv_scores_knn.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сравнение моделей\n",
    "\n",
    "Сравним производительность всех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Создаем DataFrame с результатами\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Модель': ['Logistic Regression', 'Decision Tree', 'Random Forest', \n",
    "               'Gradient Boosting', 'SVM', 'KNN'],\n",
    "    'Точность': [acc_log, acc_dt, acc_rf, acc_gb, acc_svm, acc_knn],\n",
    "    'CV Средняя': [cv_scores_log.mean(), cv_scores_dt.mean(), cv_scores_rf.mean(),\n",
    "                   cv_scores_gb.mean(), cv_scores_svm.mean(), cv_scores_knn.mean()],\n",
    "    'CV Std': [cv_scores_log.std(), cv_scores_dt.std(), cv_scores_rf.std(),\n",
    "               cv_scores_gb.std(), cv_scores_svm.std(), cv_scores_knn.std()]\n",
    "})\n",
    "\n",
    "models_comparison = models_comparison.sort_values('Точность', ascending=False)\n",
    "print(\"Сравнение моделей:\")\n",
    "print(models_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация сравнения\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# График точности\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(models_comparison)))\n",
    "bars1 = axes[0].barh(models_comparison['Модель'], models_comparison['Точность'], color=colors)\n",
    "axes[0].set_xlabel('Точность', fontsize=12)\n",
    "axes[0].set_title('Сравнение точности моделей', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlim(0.7, 0.9)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Добавляем значения на графике\n",
    "for i, bar in enumerate(bars1):\n",
    "    width = bar.get_width()\n",
    "    axes[0].text(width, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.4f}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "# График кросс-валидации с доверительными интервалами\n",
    "axes[1].barh(models_comparison['Модель'], models_comparison['CV Средняя'], \n",
    "             xerr=models_comparison['CV Std'], color=colors, capsize=5)\n",
    "axes[1].set_xlabel('Средняя точность (CV)', fontsize=12)\n",
    "axes[1].set_title('Точность на кросс-валидации (с std)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlim(0.7, 0.9)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Детальный анализ лучшей модели\n",
    "\n",
    "Выберем лучшую модель и проведем детальный анализ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Используем Random Forest как одну из лучших моделей\n",
    "best_model = rf\n",
    "y_pred_best = y_pred_rf\n",
    "y_pred_proba_best = y_pred_proba_rf\n",
    "\n",
    "print(\"Детальный отчет по классификации:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Погибло', 'Выжило']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Матрица ошибок (Confusion Matrix)\n",
    "\n",
    "**Матрица ошибок** показывает количество правильных и неправильных предсказаний:\n",
    "\n",
    "|                  | Predicted: 0 | Predicted: 1 |\n",
    "|------------------|--------------|---------------|\n",
    "| **Actual: 0**    | TN           | FP            |\n",
    "| **Actual: 1**    | FN           | TP            |\n",
    "\n",
    "где:\n",
    "- **TP (True Positive)** - правильно предсказано \"выжил\"\n",
    "- **TN (True Negative)** - правильно предсказано \"погиб\"\n",
    "- **FP (False Positive)** - ошибочно предсказано \"выжил\"\n",
    "- **FN (False Negative)** - ошибочно предсказано \"погиб\"\n",
    "\n",
    "**Метрики:**\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$\\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Погибло', 'Выжило'],\n",
    "            yticklabels=['Погибло', 'Выжило'])\n",
    "plt.title('Матрица ошибок (Confusion Matrix)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Истинное значение', fontsize=12)\n",
    "plt.xlabel('Предсказанное значение', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Детальная статистика\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nДетальная статистика:\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"\\nAccuracy: {(tp + tn) / (tp + tn + fp + fn):.4f}\")\n",
    "print(f\"Precision: {tp / (tp + fp):.4f}\")\n",
    "print(f\"Recall: {tp / (tp + fn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 ROC-кривая и AUC\n",
    "\n",
    "**ROC-кривая** (Receiver Operating Characteristic) показывает соотношение между True Positive Rate и False Positive Rate:\n",
    "\n",
    "$$\\text{TPR (Sensitivity)} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$\\text{FPR} = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "**AUC** (Area Under Curve) - площадь под ROC-кривой. Чем ближе к 1, тем лучше модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Вычисляем ROC-кривую для всех моделей\n",
    "models_roc = [\n",
    "    ('Logistic Regression', y_pred_proba_log),\n",
    "    ('Decision Tree', y_pred_proba_dt),\n",
    "    ('Random Forest', y_pred_proba_rf),\n",
    "    ('Gradient Boosting', y_pred_proba_gb),\n",
    "    ('SVM', y_pred_proba_svm),\n",
    "    ('KNN', y_pred_proba_knn)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name, y_proba in models_roc:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Добавляем диагональную линию (случайный классификатор)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Случайный классификатор (AUC = 0.5)')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=12)\n",
    "plt.title('ROC-кривые для всех моделей', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Важность признаков\n",
    "\n",
    "Для моделей на основе деревьев можем определить важность каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Получаем важность признаков из Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Признак': X_train.columns,\n",
    "    'Важность': rf.feature_importances_\n",
    "}).sort_values('Важность', ascending=False)\n",
    "\n",
    "print(\"Топ-15 наиболее важных признаков:\")\n",
    "print(feature_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n",
    "\n",
    "plt.barh(range(len(top_features)), top_features['Важность'], color=colors)\n",
    "plt.yticks(range(len(top_features)), top_features['Признак'])\n",
    "plt.xlabel('Важность признака', fontsize=12)\n",
    "plt.title('Топ-15 наиболее важных признаков (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Оптимизация гиперпараметров\n",
    "\n",
    "Используем Grid Search для поиска оптимальных гиперпараметров для Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Определяем сетку параметров\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Начинаем поиск оптимальных гиперпараметров...\")\n",
    "print(\"Это может занять некоторое время...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nЛучшие параметры: {grid_search.best_params_}\")\n",
    "print(f\"Лучшая точность на кросс-валидации: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Оценка оптимизированной модели на тестовой выборке\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_optimized = best_rf.predict(X_test)\n",
    "\n",
    "acc_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"\\nТочность оптимизированной модели на тестовой выборке: {acc_optimized:.4f}\")\n",
    "print(f\"Улучшение по сравнению с базовой моделью: {(acc_optimized - acc_rf)*100:.2f}%\")\n",
    "\n",
    "print(\"\\nДетальный отчет оптимизированной модели:\")\n",
    "print(classification_report(y_test, y_pred_optimized, target_names=['Погибло', 'Выжило']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Выводы и заключение\n",
    "\n",
    "### Основные выводы из анализа:\n",
    "\n",
    "1. **Выживаемость по полу**: Женщины имели значительно более высокие шансы на выживание (~74%) по сравнению с мужчинами (~19%), что подтверждает правило \"женщины и дети в первую очередь\".\n",
    "\n",
    "2. **Влияние класса билета**: Пассажиры 1-го класса имели шансы на выживание в ~63%, тогда как у пассажиров 3-го класса - только ~24%. Это отражает социально-экономическое неравенство и расположение кают.\n",
    "\n",
    "3. **Возраст**: Дети имели более высокие шансы на выживание, особенно девочки из высших классов.\n",
    "\n",
    "4. **Размер семьи**: Пассажиры с небольшими семьями (2-4 человека) имели лучшие шансы на выживание, чем те, кто путешествовал в одиночку или с очень большими семьями.\n",
    "\n",
    "5. **Производительность моделей**: Наилучшие результаты показали ансамблевые методы (Random Forest и Gradient Boosting) с точностью около 82-85%.\n",
    "\n",
    "### Наиболее важные признаки для предсказания:\n",
    "- Пол (sex)\n",
    "- Класс билета (pclass)\n",
    "- Стоимость билета (fare)\n",
    "- Возраст (age)\n",
    "- Титул (извлеченный из имени)\n",
    "\n",
    "### Рекомендации для дальнейшего улучшения:\n",
    "1. Попробовать другие техники feature engineering\n",
    "2. Использовать более продвинутые методы ансамблирования (Stacking, Blending)\n",
    "3. Применить современные методы градиентного бустинга (XGBoost, LightGBM, CatBoost)\n",
    "4. Провести более глубокий анализ взаимодействий между признаками\n",
    "5. Использовать техники работы с несбалансированными классами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Сохранение лучшей модели\n",
    "\n",
    "Сохраним обученную модель для дальнейшего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Сохранение модели\n",
    "with open('best_titanic_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf, file)\n",
    "\n",
    "# Сохранение scaler\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "print(\"Модель и scaler успешно сохранены!\")\n",
    "print(\"Файлы: best_titanic_model.pkl, scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Конец анализа\n",
    "\n",
    "Этот ноутбук продемонстрировал полный цикл анализа данных и машинного обучения:\n",
    "- Исследовательский анализ данных (EDA)\n",
    "- Визуализацию и понимание данных\n",
    "- Предобработку и feature engineering\n",
    "- Построение и сравнение различных моделей\n",
    "- Оптимизацию гиперпараметров\n",
    "- Интерпретацию результатов\n",
    "\n",
    "Вы можете использовать этот ноутбук как шаблон для анализа других датасетов!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
