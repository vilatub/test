#!/usr/bin/env python3
"""
Phase 4 Step 1: Self-Attention & Transformer Basics
Part 4: Training, Evaluation, Attention Visualization, Comparisons
"""

import json

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π notebook
notebook_path = '/home/user/test/notebooks/phase4_transformers/01_self_attention_transformer.ipynb'
with open(notebook_path, 'r', encoding='utf-8') as f:
    notebook = json.load(f)

cells = notebook['cells']

# ============================================================================
# MODEL TRAINING
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "---\n",
        "\n",
        "## üèãÔ∏è –ß–∞—Å—Ç—å 6: –û–±—É—á–µ–Ω–∏–µ Transformer\n",
        "\n",
        "### 6.1 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Hyperparameters\n",
        "num_features = X_train.shape[1]\n",
        "d_model = 64\n",
        "n_heads = 4\n",
        "n_layers = 2\n",
        "d_ff = 256  # 4 * d_model\n",
        "num_classes = 2\n",
        "dropout = 0.1\n",
        "pooling = 'mean'  # 'mean', 'max', or 'cls'\n",
        "\n",
        "print(\"Model Hyperparameters:\")\n",
        "print(f\"  Input features: {num_features}\")\n",
        "print(f\"  d_model: {d_model}\")\n",
        "print(f\"  n_heads: {n_heads}\")\n",
        "print(f\"  n_layers: {n_layers}\")\n",
        "print(f\"  d_ff: {d_ff}\")\n",
        "print(f\"  dropout: {dropout}\")\n",
        "print(f\"  pooling: {pooling}\")\n",
        "print(f\"  num_classes: {num_classes}\")\n",
        "\n",
        "# Initialize model\n",
        "model = TabularTransformerEncoder(\n",
        "    num_features=num_features,\n",
        "    d_model=d_model,\n",
        "    n_heads=n_heads,\n",
        "    n_layers=n_layers,\n",
        "    d_ff=d_ff,\n",
        "    num_classes=num_classes,\n",
        "    dropout=dropout,\n",
        "    pooling=pooling\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel size:\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
        "                                                   factor=0.5, patience=5)\n",
        "\n",
        "print(\"\\n‚úÖ Model initialized!\")"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 6.2 Training Loop"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Training function\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for X_batch, y_batch in loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Metrics\n",
        "        total_loss += loss.item() * X_batch.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "    \n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            \n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            \n",
        "            total_loss += loss.item() * X_batch.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "    \n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "print(\"‚úÖ Training functions defined\")"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Training loop\n",
        "num_epochs = 50\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'test_loss': [],\n",
        "    'test_acc': []\n",
        "}\n",
        "\n",
        "print(f\"Training for {num_epochs} epochs...\\n\")\n",
        "best_test_acc = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    \n",
        "    # Evaluate\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "    \n",
        "    # Scheduler step\n",
        "    scheduler.step(test_loss)\n",
        "    \n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    \n",
        "    # Track best\n",
        "    if test_acc > best_test_acc:\n",
        "        best_test_acc = test_acc\n",
        "    \n",
        "    # Print progress\n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        print()\n",
        "\n",
        "print(f\"\\n‚úÖ Training completed!\")\n",
        "print(f\"Best Test Accuracy: {best_test_acc:.4f}\")"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history['test_loss'], label='Test Loss', linewidth=2)\n",
        "axes[0].set_title('Loss over Epochs', fontsize=16, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "axes[1].plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
        "axes[1].plot(history['test_acc'], label='Test Accuracy', linewidth=2)\n",
        "axes[1].set_title('Accuracy over Epochs', fontsize=16, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final Train Accuracy: {history['train_acc'][-1]:.4f}\")\n",
        "print(f\"Final Test Accuracy: {history['test_acc'][-1]:.4f}\")\n",
        "print(f\"Best Test Accuracy: {best_test_acc:.4f}\")"
    ]
})

# ============================================================================
# DETAILED EVALUATION
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 6.3 Detailed Evaluation"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Get predictions\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(y_batch.numpy())\n",
        "        y_probs.extend(probs[:, 1].cpu().numpy())  # probability of class 1\n",
        "\n",
        "y_pred = np.array(y_pred)\n",
        "y_true = np.array(y_true)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "auc = roc_auc_score(y_true, y_probs)\n",
        "\n",
        "print(\"Test Set Performance:\")\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "print(f\"  F1 Score:  {f1:.4f}\")\n",
        "print(f\"  ROC AUC:   {auc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Died', 'Survived']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Died', 'Survived'],\n",
        "            yticklabels=['Died', 'Survived'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Predicted', fontsize=12)\n",
        "plt.ylabel('True', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
    ]
})

# ============================================================================
# ATTENTION VISUALIZATION
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "---\n",
        "\n",
        "## üîç –ß–∞—Å—Ç—å 7: Attention Visualization\n",
        "\n",
        "### 7.1 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Attention Weights\n",
        "\n",
        "**–ß—Ç–æ –º—ã –∏—â–µ–º:**\n",
        "- –ö–∞–∫–∏–µ features –º–æ–¥–µ–ª—å —Å—á–∏—Ç–∞–µ—Ç –≤–∞–∂–Ω—ã–º–∏?\n",
        "- –ï—Å—Ç—å –ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ attention –º–µ–∂–¥—É features?\n",
        "- –ö–∞–∫ —Ä–∞–∑–Ω—ã–µ heads —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è?"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –í—ã–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "sample_indices = [0, 5, 10]  # –∏–Ω–¥–µ–∫—Å—ã –≤ test set\n",
        "\n",
        "# Feature names\n",
        "feature_names = [col for col in data.columns if col != 'survived']\n",
        "print(f\"Features ({len(feature_names)}): {feature_names}\")\n",
        "\n",
        "# Get attention weights –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for idx in sample_indices:\n",
        "        x_sample = X_test_tensor[idx:idx+1].to(device)\n",
        "        y_sample = y_test_tensor[idx].item()\n",
        "        \n",
        "        # Forward pass with attention\n",
        "        logits, attention_list = model(x_sample, return_attention=True)\n",
        "        pred_prob = F.softmax(logits, dim=1)[0, 1].item()\n",
        "        pred_class = torch.argmax(logits, dim=1).item()\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Sample {idx}: True={y_sample}, Pred={pred_class}, Prob={pred_prob:.3f}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º attention weights –¥–ª—è –≤—Å–µ—Ö layers\n",
        "        n_layers_viz = len(attention_list)\n",
        "        n_heads_viz = attention_list[0].size(1)\n",
        "        \n",
        "        fig, axes = plt.subplots(n_layers_viz, n_heads_viz, \n",
        "                                figsize=(n_heads_viz * 4, n_layers_viz * 4))\n",
        "        \n",
        "        if n_layers_viz == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "        \n",
        "        for layer_idx in range(n_layers_viz):\n",
        "            attn_weights = attention_list[layer_idx][0].cpu().numpy()  # (n_heads, seq_len, seq_len)\n",
        "            \n",
        "            for head_idx in range(n_heads_viz):\n",
        "                ax = axes[layer_idx, head_idx]\n",
        "                \n",
        "                # Attention matrix –¥–ª—è —ç—Ç–æ–≥–æ head\n",
        "                attn_matrix = attn_weights[head_idx]  # (seq_len, seq_len)\n",
        "                \n",
        "                sns.heatmap(attn_matrix, annot=False, fmt='.2f', cmap='YlOrRd',\n",
        "                           xticklabels=feature_names, yticklabels=feature_names,\n",
        "                           ax=ax, cbar=True, square=True)\n",
        "                ax.set_title(f'Layer {layer_idx+1}, Head {head_idx+1}', \n",
        "                           fontsize=12, fontweight='bold')\n",
        "                ax.set_xlabel('Keys (attending to)')\n",
        "                if head_idx == 0:\n",
        "                    ax.set_ylabel('Queries (attending from)')\n",
        "        \n",
        "        plt.suptitle(f'Sample {idx}: Attention Weights Across Layers and Heads\\n'\n",
        "                    f'True: {y_sample}, Pred: {pred_class}, Prob: {pred_prob:.3f}',\n",
        "                    fontsize=16, fontweight='bold', y=1.01)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Aggregate attention weights across all test samples\n",
        "# –î–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, –∫–∞–∫–∏–µ features –º–æ–¥–µ–ª—å —Å—á–∏—Ç–∞–µ—Ç –≤–∞–∂–Ω—ã–º–∏ –≤ —Å—Ä–µ–¥–Ω–µ–º\n",
        "\n",
        "model.eval()\n",
        "all_attention_weights = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, _ in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        _, attention_list = model(X_batch, return_attention=True)\n",
        "        \n",
        "        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π layer\n",
        "        last_layer_attn = attention_list[-1]  # (batch, n_heads, seq_len, seq_len)\n",
        "        \n",
        "        # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ heads\n",
        "        avg_attn = last_layer_attn.mean(dim=1)  # (batch, seq_len, seq_len)\n",
        "        \n",
        "        all_attention_weights.append(avg_attn.cpu())\n",
        "\n",
        "# Concatenate –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –≤—Å–µ–º samples\n",
        "all_attention_weights = torch.cat(all_attention_weights, dim=0)\n",
        "mean_attention = all_attention_weights.mean(dim=0).numpy()  # (seq_len, seq_len)\n",
        "\n",
        "print(f\"Mean attention shape: {mean_attention.shape}\")\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–µ–¥–Ω—é—é attention matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(mean_attention, annot=True, fmt='.2f', cmap='YlOrRd',\n",
        "           xticklabels=feature_names, yticklabels=feature_names,\n",
        "           cbar_kws={'label': 'Attention Weight'})\n",
        "plt.title('Mean Attention Weights (Last Layer, Averaged over Test Set)', \n",
        "         fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Keys (attending to)', fontsize=12)\n",
        "plt.ylabel('Queries (attending from)', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# –í—ã—á–∏—Å–ª—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å features (—Å–∫–æ–ª—å–∫–æ –Ω–∞ –Ω–∏—Ö –æ–±—Ä–∞—â–∞—é—Ç –≤–Ω–∏–º–∞–Ω–∏–µ)\n",
        "feature_importance = mean_attention.sum(axis=0)  # —Å—É–º–º–∞ –ø–æ columns (–∫—É–¥–∞ —Å–º–æ—Ç—Ä—è—Ç)\n",
        "\n",
        "# –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º\n",
        "feature_importance = feature_importance / feature_importance.sum()\n",
        "\n",
        "# –°–æ—Ä—Ç–∏—Ä—É–µ–º\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance (based on attention):\")\n",
        "print(importance_df)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df['Feature'], importance_df['Importance'], color='steelblue')\n",
        "plt.xlabel('Attention-based Importance', fontsize=12)\n",
        "plt.title('Feature Importance from Attention Weights', fontsize=16, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
    ]
})

# ============================================================================
# COMPARISON WITH BASELINES
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "---\n",
        "\n",
        "## üìä –ß–∞—Å—Ç—å 8: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Baseline –º–æ–¥–µ–ª—è–º–∏\n",
        "\n",
        "### 8.1 Simple MLP Baseline"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Simple MLP –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, dropout=0.3):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        layers = []\n",
        "        \n",
        "        prev_size = input_size\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            prev_size = hidden_size\n",
        "        \n",
        "        layers.append(nn.Linear(prev_size, num_classes))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Train MLP\n",
        "mlp = SimpleMLP(input_size=num_features, hidden_sizes=[64, 32], \n",
        "                num_classes=2, dropout=0.3).to(device)\n",
        "\n",
        "mlp_optimizer = optim.Adam(mlp.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "mlp_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Training MLP for {num_epochs} epochs...\")\n",
        "mlp_best_acc = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    mlp.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        mlp_optimizer.zero_grad()\n",
        "        outputs = mlp(X_batch)\n",
        "        loss = mlp_criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        mlp_optimizer.step()\n",
        "    \n",
        "    # Evaluate\n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        _, test_acc = evaluate(mlp, test_loader, mlp_criterion, device)\n",
        "        if test_acc > mlp_best_acc:\n",
        "            mlp_best_acc = test_acc\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] MLP Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(f\"\\nMLP Best Test Accuracy: {mlp_best_acc:.4f}\")"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 8.2 XGBoost Baseline"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# XGBoost baseline\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    \n",
        "    print(\"Training XGBoost...\")\n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    xgb_pred = xgb_model.predict(X_test)\n",
        "    xgb_acc = accuracy_score(y_test, xgb_pred)\n",
        "    xgb_f1 = f1_score(y_test, xgb_pred)\n",
        "    \n",
        "    print(f\"XGBoost Test Accuracy: {xgb_acc:.4f}\")\n",
        "    print(f\"XGBoost Test F1 Score: {xgb_f1:.4f}\")\n",
        "    \n",
        "    # Feature importance\n",
        "    xgb_importance = xgb_model.feature_importances_\n",
        "    xgb_importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': xgb_importance\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    print(\"\\nXGBoost Feature Importance:\")\n",
        "    print(xgb_importance_df)\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è XGBoost not installed. Skipping XGBoost baseline.\")\n",
        "    print(\"Install with: pip install xgboost\")\n",
        "    xgb_acc = None\n",
        "    xgb_f1 = None"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 8.3 Model Comparison"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Compare all models\n",
        "comparison_data = {\n",
        "    'Model': ['Transformer', 'MLP', 'XGBoost'],\n",
        "    'Accuracy': [accuracy, mlp_best_acc, xgb_acc if xgb_acc else 0],\n",
        "    'F1 Score': [f1, 0, xgb_f1 if xgb_f1 else 0],  # –Ω–µ —Å—á–∏—Ç–∞–ª–∏ F1 –¥–ª—è MLP\n",
        "    'Parameters': [trainable_params, \n",
        "                   sum(p.numel() for p in mlp.parameters()),\n",
        "                   0]  # XGBoost –Ω–µ –∏–º–µ–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*60)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy comparison\n",
        "axes[0].bar(comparison_df['Model'], comparison_df['Accuracy'], \n",
        "           color=['steelblue', 'orange', 'green'])\n",
        "axes[0].set_title('Model Accuracy Comparison', fontsize=16, fontweight='bold')\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].set_ylim([0.7, 0.9])\n",
        "axes[0].grid(alpha=0.3, axis='y')\n",
        "for i, v in enumerate(comparison_df['Accuracy']):\n",
        "    axes[0].text(i, v + 0.01, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
        "\n",
        "# Parameters comparison\n",
        "valid_params = [(m, p) for m, p in zip(comparison_df['Model'], comparison_df['Parameters']) if p > 0]\n",
        "if valid_params:\n",
        "    models, params = zip(*valid_params)\n",
        "    axes[1].bar(models, params, color=['steelblue', 'orange'])\n",
        "    axes[1].set_title('Model Size (Parameters)', fontsize=16, fontweight='bold')\n",
        "    axes[1].set_ylabel('# Parameters', fontsize=12)\n",
        "    axes[1].grid(alpha=0.3, axis='y')\n",
        "    for i, (m, p) in enumerate(valid_params):\n",
        "        axes[1].text(i, p + 500, f\"{p:,}\", ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä –í—ã–≤–æ–¥—ã:\")\n",
        "print(\"  - Transformer –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç competitive —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å baselines\")\n",
        "print(\"  - XGBoost –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É —Å–∏–ª–µ–Ω –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö)\")\n",
        "print(\"  - Transformer –¥–∞–µ—Ç –±–æ–Ω—É—Å: attention weights –¥–ª—è interpretability\")\n",
        "print(\"  - –ù–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö Transformer –º–æ–∂–µ—Ç –ø—Ä–µ–≤–∑–æ–π—Ç–∏ tree-based –º–µ—Ç–æ–¥—ã\")"
    ]
})

# ============================================================================
# CONCLUSIONS
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "---\n",
        "\n",
        "## üéì –ò—Ç–æ–≥–∏ –∏ –í—ã–≤–æ–¥—ã\n",
        "\n",
        "### –ß—Ç–æ –º—ã –∏–∑—É—á–∏–ª–∏\n",
        "\n",
        "#### 1. Self-Attention Mechanism\n",
        "- ‚úÖ **Query, Key, Value**: –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç attention\n",
        "- ‚úÖ **Scaled Dot-Product**: $\\text{Attention}(Q,K,V) = \\text{softmax}(QK^T/\\sqrt{d_k})V$\n",
        "- ‚úÖ **Parallelization**: –≤—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã (vs RNN sequential)\n",
        "- ‚úÖ **Long-range dependencies**: –ø—Ä—è–º—ã–µ —Å–≤—è–∑–∏ O(1) path length\n",
        "\n",
        "#### 2. Multi-Head Attention\n",
        "- ‚úÖ **Multiple perspectives**: —Ä–∞–∑–Ω—ã–µ heads —É—á–∞—Ç —Ä–∞–∑–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
        "- ‚úÖ **Ensemble effect**: –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
        "- ‚úÖ **Richer representations**: $h$ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö attention mechanisms\n",
        "\n",
        "#### 3. Positional Encoding\n",
        "- ‚úÖ **Sinusoidal**: –¥–ª—è sequences (NLP, time series)\n",
        "- ‚úÖ **Learnable**: –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞)\n",
        "- ‚úÖ **–†–µ—à–∞–µ—Ç permutation invariance**: –º–æ–¥–µ–ª—å –∑–Ω–∞–µ—Ç –ø–æ–∑–∏—Ü–∏–∏\n",
        "\n",
        "#### 4. Transformer Encoder\n",
        "- ‚úÖ **Architecture**: Multi-Head Attention ‚Üí Add&Norm ‚Üí FFN ‚Üí Add&Norm\n",
        "- ‚úÖ **Residual connections**: –ø–æ–º–æ–≥–∞—é—Ç gradient flow\n",
        "- ‚úÖ **Layer Normalization**: —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ\n",
        "- ‚úÖ **Feed-Forward Network**: –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ-–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
        "\n",
        "#### 5. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –¢–∞–±–ª–∏—á–Ω—ã–º –î–∞–Ω–Ω—ã–º\n",
        "- ‚úÖ **Feature embedding**: Linear projection –¥–ª—è –∫–∞–∂–¥–æ–π feature\n",
        "- ‚úÖ **Feature interactions**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ attention\n",
        "- ‚úÖ **Interpretability**: attention weights –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤–∞–∂–Ω–æ—Å—Ç—å\n",
        "- ‚úÖ **Competitive performance**: —Å—Ä–∞–≤–Ω–∏–º–æ —Å XGBoost –Ω–∞ Titanic\n",
        "\n",
        "---\n",
        "\n",
        "### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Transformers\n",
        "\n",
        "| Aspect | RNN/LSTM | Transformer |\n",
        "|--------|----------|-------------|\n",
        "| **Processing** | Sequential | Parallel |\n",
        "| **Long-range deps** | O(n) path | O(1) path |\n",
        "| **Training speed** | Slow | Fast (GPU) |\n",
        "| **Interpretability** | Hard | Attention weights |\n",
        "| **Scalability** | Limited | Excellent |\n",
        "| **SOTA results** | 2014-2017 | 2017+ |\n",
        "\n",
        "---\n",
        "\n",
        "### –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Transformers –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö?\n",
        "\n",
        "**‚úÖ –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ–≥–¥–∞:**\n",
        "- –ë–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (>10k samples)\n",
        "- –ú–Ω–æ–≥–æ categorical features\n",
        "- –°–ª–æ–∂–Ω—ã–µ feature interactions\n",
        "- –ù—É–∂–Ω–∞ interpretability\n",
        "- –î–æ—Å—Ç—É–ø–µ–Ω pre-training –Ω–∞ –ø–æ—Ö–æ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "**‚ùå –ú–æ–≥—É—Ç —É—Å—Ç—É–ø–∞—Ç—å tree-based –º–µ—Ç–æ–¥–∞–º –∫–æ–≥–¥–∞:**\n",
        "- –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (<1k samples)\n",
        "- –ü—Ä–æ—Å—Ç—ã–µ feature interactions\n",
        "- –¢–æ–ª—å–∫–æ numerical features\n",
        "- –ù—É–∂–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–µ–∑ —Ç—é–Ω–∏–Ω–≥–∞\n",
        "\n",
        "---\n",
        "\n",
        "### –ß—Ç–æ –¥–∞–ª—å—à–µ?\n",
        "\n",
        "**Phase 4, Step 2: TabTransformer**\n",
        "- –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ embeddings –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö features\n",
        "- Contextual embeddings —á–µ—Ä–µ–∑ Transformer\n",
        "- –õ—É—á—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "**Phase 4, Step 3: Advanced Architectures**\n",
        "- FT-Transformer (Feature Tokenizer)\n",
        "- SAINT (Self-Attention and Intersample Attention)\n",
        "- TabNet (attention-based —Ç–∞–±–ª–∏—á–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)\n",
        "- Temporal Fusion Transformer (–¥–ª—è time series)\n",
        "\n",
        "**Phase 5: Transfer Learning & Pre-training**\n",
        "- Pre-training –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö\n",
        "- Fine-tuning –Ω–∞ —Ü–µ–ª–µ–≤–æ–π –∑–∞–¥–∞—á–µ\n",
        "- Self-supervised learning\n",
        "\n",
        "---\n",
        "\n",
        "### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã\n",
        "\n",
        "**Papers:**\n",
        "- \"Attention is All You Need\" (Vaswani et al., 2017) - –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç—å—è\n",
        "- \"TabTransformer\" (Huang et al., 2020) - Transformer –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "- \"Revisiting Deep Learning Models for Tabular Data\" (Gorishniy et al., 2021)\n",
        "\n",
        "**Tutorials:**\n",
        "- The Illustrated Transformer (Jay Alammar)\n",
        "- Annotated Transformer (Harvard NLP)\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ –ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º!\n",
        "\n",
        "–í—ã –æ—Å–≤–æ–∏–ª–∏ –æ—Å–Ω–æ–≤—ã Transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã!\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –≤—ã –ø–æ–Ω–∏–º–∞–µ—Ç–µ:\n",
        "- üß† –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Self-Attention\n",
        "- üîÆ –ü–æ—á–µ–º—É Transformers —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–ª–∏ ML\n",
        "- üìä –ö–∞–∫ –ø—Ä–∏–º–µ–Ω—è—Ç—å Transformers –∫ —Ç–∞–±–ª–∏—á–Ω—ã–º –¥–∞–Ω–Ω—ã–º\n",
        "- üîç –ö–∞–∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ attention weights\n",
        "\n",
        "**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** TabTransformer –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ features!\n"
    ]
})

# –°–æ—Ö—Ä–∞–Ω—è–µ–º
notebook['cells'] = cells

with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f'‚úÖ Part 4 –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤: {notebook_path}')
print(f'–í—Å–µ–≥–æ —è—á–µ–µ–∫: {len(cells)}')
print('Notebook –ó–ê–í–ï–†–®–ï–ù!')
print('\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞:')
print('  Part 1: Introduction, Theory, Scaled Dot-Product Attention')
print('  Part 2: Multi-Head Attention, Positional Encoding')
print('  Part 3: Transformer Encoder, Titanic Dataset')
print('  Part 4: Training, Evaluation, Attention Viz, Comparisons, Conclusions')
