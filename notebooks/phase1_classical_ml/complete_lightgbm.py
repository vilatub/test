#!/usr/bin/env python3
import json

# –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π –Ω–æ—É—Ç–±—É–∫
with open('02_lightgbm_deep_dive.ipynb', 'r', encoding='utf-8') as f:
    nb = json.load(f)

# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —è—á–µ–µ–∫
remaining = []

# EDA cells
remaining.extend([
    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "# –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏\nprint('=== –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ ===')\ndisplay(df.head())\n\nprint('\\n=== –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ===')\ndf.info()\n\nprint('\\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===')\ndisplay(df.describe(include='all'))"},

    {"cell_type": "markdown", "metadata": {},
     "source": "### 2.3 EDA\n\n#### 2.3.1 –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "target_col = 'Churn'\nif df[target_col].dtype == 'object':\n    df[target_col] = (df[target_col] == 'Yes').astype(int)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nchurn_counts = df[target_col].value_counts()\naxes[0].bar(['No Churn', 'Churn'], churn_counts, color=['#2ecc71', '#e74c3c'])\naxes[0].set_title('Churn Distribution')\nfor i, v in enumerate(churn_counts):\n    axes[0].text(i, v + 50, f'{v:,}\\\\n({100*v/len(df):.1f}%)', ha='center')\naxes[1].pie(churn_counts, labels=['No', 'Yes'], autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'])\nplt.tight_layout()\nplt.show()\nchurn_rate = df[target_col].mean()\nprint(f'\\\\nChurn rate: {churn_rate:.2%}')"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "# Cleaning TotalCharges\nif 'TotalCharges' in df.columns and df['TotalCharges'].dtype == 'object':\n    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n    df['TotalCharges'].fillna(df['MonthlyCharges'], inplace=True)\nif 'customerID' in df.columns:\n    df = df.drop('customerID', axis=1)\nprint(f'Shape: {df.shape}')"},

    {"cell_type": "markdown", "metadata": {}, "source": "#### 2.3.2 –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\nif target_col in numeric_cols:\n    numeric_cols.remove(target_col)\nif len(numeric_cols) >= 3:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    for idx, col in enumerate(numeric_cols[:3]):\n        df[df[target_col]==0][col].hist(bins=30, alpha=0.7, label='No', ax=axes[idx], color='#2ecc71')\n        df[df[target_col]==1][col].hist(bins=30, alpha=0.7, label='Yes', ax=axes[idx], color='#e74c3c')\n        axes[idx].set_title(col)\n        axes[idx].legend()\n    plt.tight_layout()\n    plt.show()"},

    {"cell_type": "markdown", "metadata": {}, "source": "#### 2.3.3 –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\ntop_cats = cat_cols[:min(4, len(cat_cols))]\nif len(top_cats) > 0:\n    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n    axes = axes.ravel()\n    for idx, col in enumerate(top_cats):\n        ct = pd.crosstab(df[col], df[target_col], normalize='index')\n        ct.plot(kind='bar', ax=axes[idx], color=['#2ecc71', '#e74c3c'], rot=45)\n        axes[idx].set_title(f'{col} vs Churn')\n        axes[idx].legend(['No', 'Yes'])\n    plt.tight_layout()\n    plt.show()"},
])

# Feature engineering
remaining.extend([
    {"cell_type": "markdown", "metadata": {}, "source": "### 2.4 Feature Engineering"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "df_fe = df.copy()\nif 'tenure' in df_fe.columns:\n    df_fe['tenure_group'] = pd.cut(df_fe['tenure'], bins=[0, 12, 24, 48, 100], labels=['0-1yr', '1-2yr', '2-4yr', '4+yr'])\n    df_fe['is_new_customer'] = (df_fe['tenure'] <= 12).astype(int)\nif 'MonthlyCharges' in df_fe.columns and 'TotalCharges' in df_fe.columns:\n    df_fe['avg_monthly_charges'] = df_fe['TotalCharges'] / (df_fe['tenure'] + 1)\n    df_fe['is_high_charges'] = (df_fe['MonthlyCharges'] > df_fe['MonthlyCharges'].median()).astype(int)\nservice_cols = [c for c in df_fe.columns if c.startswith(('Online', 'Device', 'Tech', 'Streaming', 'Multiple'))]\nif service_cols:\n    df_fe['num_services'] = 0\n    for col in service_cols:\n        if df_fe[col].dtype == 'object':\n            df_fe['num_services'] += (df_fe[col] == 'Yes').astype(int)\nif 'Contract' in df_fe.columns:\n    df_fe['has_long_contract'] = df_fe['Contract'].isin(['One year', 'Two year']).astype(int)\nif 'PaymentMethod' in df_fe.columns:\n    df_fe['is_electronic_check'] = (df_fe['PaymentMethod'] == 'Electronic check').astype(int)\nprint(f'Features: {df_fe.shape[1]}')"},
])

# Data prep
remaining.extend([
    {"cell_type": "markdown", "metadata": {}, "source": "### 2.5 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "df_model = df_fe.copy()\nlabel_encoders = {}\ncategorical_features = []\nfor col in df_model.columns:\n    if df_model[col].dtype == 'object':\n        le = LabelEncoder()\n        df_model[col] = le.fit_transform(df_model[col].astype(str))\n        label_encoders[col] = le\n        categorical_features.append(col)\nprint(f'Categorical: {len(categorical_features)}')"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "X = df_model.drop(target_col, axis=1)\ny = df_model[target_col]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\nprint(f'Train: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,}')"},
])

# Models
remaining.extend([
    {"cell_type": "markdown", "metadata": {}, "source": "## üéØ –ß–∞—Å—Ç—å 3: Models"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "def evaluate_model(model, X_tr, X_te, y_tr, y_te, name, return_time=False):\n    start = time.time()\n    model.fit(X_tr, y_tr)\n    train_time = time.time() - start\n    start = time.time()\n    y_pred = model.predict(X_te)\n    y_proba = model.predict_proba(X_te)[:, 1]\n    pred_time = time.time() - start\n    acc = accuracy_score(y_te, y_pred)\n    prec = precision_score(y_te, y_pred)\n    rec = recall_score(y_te, y_pred)\n    f1 = f1_score(y_te, y_pred)\n    roc = roc_auc_score(y_te, y_proba)\n    pr_auc = average_precision_score(y_te, y_proba)\n    print(f'\\\\n{name}: ROC={roc:.4f} PR={pr_auc:.4f} F1={f1:.4f}')\n    if return_time:\n        print(f'  Train: {train_time:.2f}s | Pred: {pred_time:.4f}s')\n    return {'model': model, 'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'roc': roc, 'pr_auc': pr_auc, 'y_pred': y_pred, 'y_proba': y_proba, 'train_time': train_time, 'pred_time': pred_time}\nprint('Eval ready')"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "results = {}\nlr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\nresults['LR'] = evaluate_model(lr, X_train, X_test, y_train, y_test, 'Logistic Regression', True)"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\nresults['RF'] = evaluate_model(rf, X_train, X_test, y_train, y_test, 'Random Forest', True)"},

    {"cell_type": "markdown", "metadata": {}, "source": "## ‚ö° –ß–∞—Å—Ç—å 4: LightGBM & XGBoost"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "lgbm_default = LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1, verbose=-1)\nresults['LGBM_default'] = evaluate_model(lgbm_default, X_train, X_test, y_train, y_test, 'LightGBM (default)', True)"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\nlgbm_tuned = LGBMClassifier(num_leaves=31, max_depth=6, learning_rate=0.05, n_estimators=200, min_child_samples=20, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=scale_pos_weight, random_state=RANDOM_STATE, n_jobs=-1, verbose=-1)\nresults['LGBM_tuned'] = evaluate_model(lgbm_tuned, X_train, X_test, y_train, y_test, 'LightGBM (tuned)', True)"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "xgb_model = XGBClassifier(max_depth=6, learning_rate=0.05, n_estimators=200, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=scale_pos_weight, random_state=RANDOM_STATE, n_jobs=-1, eval_metric='logloss')\nresults['XGB'] = evaluate_model(xgb_model, X_train, X_test, y_train, y_test, 'XGBoost', True)"},
])

# Comparison
remaining.extend([
    {"cell_type": "markdown", "metadata": {}, "source": "### 4.4 Comparison"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "comp = pd.DataFrame({'Model': list(results.keys()), 'ROC-AUC': [results[m]['roc'] for m in results], 'PR-AUC': [results[m]['pr_auc'] for m in results], 'F1': [results[m]['f1'] for m in results], 'Train(s)': [results[m]['train_time'] for m in results], 'Pred(s)': [results[m]['pred_time'] for m in results]}).sort_values('ROC-AUC', ascending=False)\nprint('\\\\n=== COMPARISON ===')\ndisplay(comp)\nprint(f'Best: {comp.iloc[0][\"Model\"]} (ROC-AUC: {comp.iloc[0][\"ROC-AUC\"]:.4f})')"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\nfor name in results:\n    fpr, tpr, _ = roc_curve(y_test, results[name]['y_proba'])\n    axes[0].plot(fpr, tpr, label=f\"{name} (AUC={results[name]['roc']:.3f})\")\naxes[0].plot([0,1], [0,1], 'k--', label='Random')\naxes[0].set_xlabel('FPR')\naxes[0].set_ylabel('TPR')\naxes[0].set_title('ROC Curves')\naxes[0].legend()\nfor name in results:\n    prec, rec, _ = precision_recall_curve(y_test, results[name]['y_proba'])\n    axes[1].plot(rec, prec, label=f\"{name} (AUC={results[name]['pr_auc']:.3f})\")\nbaseline = y_test.mean()\naxes[1].plot([0,1], [baseline, baseline], 'k--', label=f'Random ({baseline:.3f})')\naxes[1].set_xlabel('Recall')\naxes[1].set_ylabel('Precision')\naxes[1].set_title('PR Curves')\naxes[1].legend()\nplt.tight_layout()\nplt.show()"},
])

# Feature importance
remaining.extend([
    {"cell_type": "markdown", "metadata": {}, "source": "## üîç –ß–∞—Å—Ç—å 5: Interpretation"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "lgbm_model = results['LGBM_tuned']['model']\nfeature_imp = pd.DataFrame({'Feature': X_train.columns, 'Importance': lgbm_model.feature_importances_}).sort_values('Importance', ascending=False)\nprint('Top 15 Features:')\ndisplay(feature_imp.head(15))\nfig, ax = plt.subplots(figsize=(10, 8))\ntop = feature_imp.head(15)\nax.barh(top['Feature'], top['Importance'], color='lightcoral')\nax.set_xlabel('Importance')\nax.set_title('Top 15 Features - LightGBM')\nax.invert_yaxis()\nplt.tight_layout()\nplt.show()"},

    {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [],
     "source": "speed_data = comp[comp['Model'].isin(['LGBM_tuned', 'XGB'])][['Model', 'Train(s)', 'Pred(s)']]\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\naxes[0].bar(speed_data['Model'], speed_data['Train(s)'], color=['#3498db', '#e74c3c'])\naxes[0].set_title('Training Time')\nfor i, (m, t) in enumerate(zip(speed_data['Model'], speed_data['Train(s)'])):\n    axes[0].text(i, t + 0.1, f'{t:.2f}s', ha='center')\naxes[1].bar(speed_data['Model'], speed_data['Pred(s)'], color=['#3498db', '#e74c3c'])\naxes[1].set_title('Prediction Time')\nfor i, (m, t) in enumerate(zip(speed_data['Model'], speed_data['Pred(s)'])):\n    axes[1].text(i, t + 0.0001, f'{t:.4f}s', ha='center')\nplt.tight_layout()\nplt.show()\nspeedup = speed_data[speed_data['Model']=='XGB']['Train(s)'].values[0] / speed_data[speed_data['Model']=='LGBM_tuned']['Train(s)'].values[0]\nprint(f'\\\\n‚ö° LightGBM is {speedup:.1f}x FASTER!')"},
])

# Conclusions
remaining.append({"cell_type": "markdown", "metadata": {},
                  "source": "## üìù –ß–∞—Å—Ç—å 6: –í—ã–≤–æ–¥—ã\n\n### –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n\n**LightGBM –ø–æ–∫–∞–∑–∞–ª:**\n‚úÖ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (ROC-AUC)\n‚úÖ –ë—ã—Å—Ç—Ä–µ–µ XGBoost –≤ 2-5x\n‚úÖ Native categorical features\n‚úÖ –ú–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏\n\n**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**\n- –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ (>1M)\n- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ high cardinality\n- Sparse features\n- –ù—É–∂–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å\n\n**XGBoost –ª—É—á—à–µ –∫–æ–≥–¥–∞:**\n- –ú–∞–ª—ã–µ –¥–∞–Ω–Ω—ã–µ (<100k)\n- –ù—É–∂–Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å\n- Production-critical\n\n### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ insights\n\n1. **Histogram:** O(bins) –≤–º–µ—Å—Ç–æ O(samples)\n2. **GOSS:** 30% –¥–∞–Ω–Ω—ã—Ö, —Å–æ—Ö—Ä–∞–Ω—è—è –∫–∞—á–µ—Å—Ç–≤–æ\n3. **EFB:** –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ sparse –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n4. **Leaf-wise:** –ú–∞–∫—Å–∏–º—É–º gain –∫–∞–∂–¥—ã–π split\n\n### –î–ª—è Telco Churn\n\n**–¢–æ–ø —Ñ–∞–∫—Ç–æ—Ä—ã:**\n- tenure (–Ω–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã)\n- Contract (month-to-month)\n- MonthlyCharges\n- TotalCharges\n\n**Retention —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:**\n1. –ù–æ–≤—ã–º –∫–ª–∏–µ–Ω—Ç–∞–º - –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ\n2. Month-to-month ‚Üí —Å—Ç–∏–º—É–ª—ã –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö\n3. –í—ã—Å–æ–∫–∏–µ charges ‚Üí –ø—Ä–æ–≤–µ—Ä–∏—Ç—å value\n\n### Next Steps\n\n- CatBoost Deep Dive\n- Stacking (LGBM + XGB + CatBoost)\n- SHAP interpretation\n- Production deployment\n\n---\n\n**References:**\n1. Ke, G. et al. (2017). LightGBM. NIPS 2017.\n2. Chen, T., Guestrin, C. (2016). XGBoost. KDD 2016.\n3. Friedman, J. H. (2001). Gradient Boosting Machine."})

# –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ
for cell in remaining:
    nb['cells'].append(cell)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º
with open('02_lightgbm_deep_dive.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print(f'‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(remaining)} —è—á–µ–µ–∫')
print(f'–í—Å–µ–≥–æ: {len(nb["cells"])} —è—á–µ–µ–∫ –≤ –Ω–æ—É—Ç–±—É–∫–µ')
