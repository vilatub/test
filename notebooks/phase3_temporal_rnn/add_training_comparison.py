#!/usr/bin/env python3
"""
–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è, —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥–æ–≤ –≤ –Ω–æ—É—Ç–±—É–∫ RNN/LSTM/GRU
"""

import json

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –Ω–æ—É—Ç–±—É–∫
notebook_path = '/home/user/test/notebooks/phase3_temporal_rnn/02_rnn_lstm_gru.ipynb'
with open(notebook_path, 'r', encoding='utf-8') as f:
    notebook = json.load(f)

cells = notebook['cells']

# ============================================================================
# TRAINING ALL MODELS
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "## üèãÔ∏è –ß–∞—Å—Ç—å 3: –û–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
        "\n",
        "### 3.1 –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
        "NUM_EPOCHS = 200\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 15\n",
        "\n",
        "# Loss –∏ optimizer –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –¥–ª—è –≤—Å–µ—Ö\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "results = {}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Training Configuration\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Sequence Length: {SEQ_LENGTH}\")\n",
        "print(f\"Early Stopping Patience: {PATIENCE}\")\n",
        "print(\"=\"*60)"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "#### 3.1.1 –û–±—É—á–µ–Ω–∏–µ Vanilla RNN"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training Vanilla RNN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "rnn_optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)\n",
        "rnn_history = train_model(rnn_model, train_loader, criterion, rnn_optimizer, \n",
        "                          NUM_EPOCHS, PATIENCE)\n",
        "\n",
        "# Evaluation\n",
        "rnn_pred, rnn_true, rnn_rmse, rnn_mae = evaluate_model(rnn_model, X_test_tensor, \n",
        "                                                        y_test_tensor, scaler)\n",
        "\n",
        "results['Vanilla RNN'] = {\n",
        "    'model': rnn_model,\n",
        "    'history': rnn_history,\n",
        "    'predictions': rnn_pred,\n",
        "    'rmse': rnn_rmse,\n",
        "    'mae': rnn_mae\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ Vanilla RNN trained\")\n",
        "print(f\"   RMSE: {rnn_rmse:.2f}\")\n",
        "print(f\"   MAE: {rnn_mae:.2f}\")"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "#### 3.1.2 –û–±—É—á–µ–Ω–∏–µ LSTM"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training LSTM\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
        "lstm_history = train_model(lstm_model, train_loader, criterion, lstm_optimizer, \n",
        "                           NUM_EPOCHS, PATIENCE)\n",
        "\n",
        "# Evaluation\n",
        "lstm_pred, lstm_true, lstm_rmse, lstm_mae = evaluate_model(lstm_model, X_test_tensor, \n",
        "                                                           y_test_tensor, scaler)\n",
        "\n",
        "results['LSTM'] = {\n",
        "    'model': lstm_model,\n",
        "    'history': lstm_history,\n",
        "    'predictions': lstm_pred,\n",
        "    'rmse': lstm_rmse,\n",
        "    'mae': lstm_mae\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ LSTM trained\")\n",
        "print(f\"   RMSE: {lstm_rmse:.2f}\")\n",
        "print(f\"   MAE: {lstm_mae:.2f}\")"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "#### 3.1.3 –û–±—É—á–µ–Ω–∏–µ GRU"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training GRU\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "gru_optimizer = optim.Adam(gru_model.parameters(), lr=LEARNING_RATE)\n",
        "gru_history = train_model(gru_model, train_loader, criterion, gru_optimizer, \n",
        "                          NUM_EPOCHS, PATIENCE)\n",
        "\n",
        "# Evaluation\n",
        "gru_pred, gru_true, gru_rmse, gru_mae = evaluate_model(gru_model, X_test_tensor, \n",
        "                                                       y_test_tensor, scaler)\n",
        "\n",
        "results['GRU'] = {\n",
        "    'model': gru_model,\n",
        "    'history': gru_history,\n",
        "    'predictions': gru_pred,\n",
        "    'rmse': gru_rmse,\n",
        "    'mae': gru_mae\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ GRU trained\")\n",
        "print(f\"   RMSE: {gru_rmse:.2f}\")\n",
        "print(f\"   MAE: {gru_mae:.2f}\")"
    ]
})

# ============================================================================
# COMPARISON WITH SARIMA
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 3.2 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–π SARIMA\n",
        "\n",
        "–î–æ–±–∞–≤–∏–º SARIMA –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training SARIMA for comparison\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ (–Ω–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ) –¥–∞–Ω–Ω—ã–µ\n",
        "train_size_orig = int(len(data) * TRAIN_SIZE)\n",
        "train_orig = data[:train_size_orig]\n",
        "test_orig = data[train_size_orig:]\n",
        "\n",
        "# SARIMA(1, 1, 1)(1, 1, 1, 12)\n",
        "sarima_model = SARIMAX(\n",
        "    train_orig,\n",
        "    order=(1, 1, 1),\n",
        "    seasonal_order=(1, 1, 1, 12),\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ")\n",
        "\n",
        "sarima_fitted = sarima_model.fit(disp=False)\n",
        "sarima_forecast = sarima_fitted.forecast(steps=len(test_orig))\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏\n",
        "sarima_rmse = np.sqrt(mean_squared_error(test_orig, sarima_forecast))\n",
        "sarima_mae = mean_absolute_error(test_orig, sarima_forecast)\n",
        "\n",
        "results['SARIMA'] = {\n",
        "    'predictions': sarima_forecast,\n",
        "    'rmse': sarima_rmse,\n",
        "    'mae': sarima_mae\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ SARIMA trained\")\n",
        "print(f\"   RMSE: {sarima_rmse:.2f}\")\n",
        "print(f\"   MAE: {sarima_mae:.2f}\")"
    ]
})

# ============================================================================
# VISUALIZATION
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 3.3 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Training curves\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "\n",
        "ax.plot(results['Vanilla RNN']['history']['train_loss'], label='Vanilla RNN', linewidth=2)\n",
        "ax.plot(results['LSTM']['history']['train_loss'], label='LSTM', linewidth=2)\n",
        "ax.plot(results['GRU']['history']['train_loss'], label='GRU', linewidth=2)\n",
        "\n",
        "ax.set_title('Training Loss Curves', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Epoch', fontsize=12)\n",
        "ax.set_ylabel('Loss (MSE)', fontsize=12)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä RNN –º–æ–¥–µ–ª–∏ –æ–±—É—á–∞—é—Ç—Å—è —Å—Ç–∞–±–∏–ª—å–Ω–æ, LSTM/GRU —Å—Ö–æ–¥—è—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ Vanilla RNN\")"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Predictions visualization\n",
        "# –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è test –¥–∞–Ω–Ω—ã—Ö\n",
        "test_indices = df.index[train_size_orig:]\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Train –¥–∞–Ω–Ω—ã–µ (–∫–æ–Ω—Ç–µ–∫—Å—Ç)\n",
        "plt.plot(df.index[:train_size_orig], data[:train_size_orig], \n",
        "         label='Train', linewidth=2, alpha=0.5, color='gray')\n",
        "\n",
        "# –ò—Å—Ç–∏–Ω–Ω—ã–µ test –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "plt.plot(test_indices, test_orig, label='Test (True)', \n",
        "         linewidth=3, color='black')\n",
        "\n",
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è RNN –º–æ–¥–µ–ª–µ–π\n",
        "plt.plot(test_indices, results['Vanilla RNN']['predictions'], \n",
        "         label=f\"Vanilla RNN (RMSE={rnn_rmse:.1f})\", linewidth=2, linestyle='--')\n",
        "plt.plot(test_indices, results['LSTM']['predictions'], \n",
        "         label=f\"LSTM (RMSE={lstm_rmse:.1f})\", linewidth=2, linestyle='--')\n",
        "plt.plot(test_indices, results['GRU']['predictions'], \n",
        "         label=f\"GRU (RMSE={gru_rmse:.1f})\", linewidth=2, linestyle='--')\n",
        "\n",
        "# SARIMA\n",
        "plt.plot(test_indices, results['SARIMA']['predictions'], \n",
        "         label=f\"SARIMA (RMSE={sarima_rmse:.1f})\", linewidth=2, linestyle=':')\n",
        "\n",
        "plt.axvline(df.index[train_size_orig], color='red', linestyle='--', \n",
        "            alpha=0.3, linewidth=2, label='Train/Test Split')\n",
        "\n",
        "plt.title('Model Comparison: RNN vs LSTM vs GRU vs SARIMA', \n",
        "          fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Time', fontsize=12)\n",
        "plt.ylabel('Number of Passengers', fontsize=12)\n",
        "plt.legend(loc='upper left', fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
    ]
})

# ============================================================================
# METRICS COMPARISON
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 3.4 –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Vanilla RNN', 'LSTM', 'GRU', 'SARIMA'],\n",
        "    'RMSE': [\n",
        "        results['Vanilla RNN']['rmse'],\n",
        "        results['LSTM']['rmse'],\n",
        "        results['GRU']['rmse'],\n",
        "        results['SARIMA']['rmse']\n",
        "    ],\n",
        "    'MAE': [\n",
        "        results['Vanilla RNN']['mae'],\n",
        "        results['LSTM']['mae'],\n",
        "        results['GRU']['mae'],\n",
        "        results['SARIMA']['mae']\n",
        "    ],\n",
        "    'Parameters': [\n",
        "        sum(p.numel() for p in rnn_model.parameters()),\n",
        "        sum(p.numel() for p in lstm_model.parameters()),\n",
        "        sum(p.numel() for p in gru_model.parameters()),\n",
        "        'N/A'\n",
        "    ],\n",
        "    'Type': ['Deep Learning', 'Deep Learning', 'Deep Learning', 'Classical']\n",
        "})\n",
        "\n",
        "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ RMSE\n",
        "comparison_df = comparison_df.sort_values('RMSE')\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# RMSE comparison\n",
        "comparison_df.plot(x='Model', y='RMSE', kind='bar', ax=axes[0], legend=False, color='steelblue')\n",
        "axes[0].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('RMSE', fontsize=12)\n",
        "axes[0].set_xlabel('')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# MAE comparison\n",
        "comparison_df.plot(x='Model', y='MAE', kind='bar', ax=axes[1], legend=False, color='coral')\n",
        "axes[1].set_title('MAE Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('MAE', fontsize=12)\n",
        "axes[1].set_xlabel('')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
    ]
})

# ============================================================================
# CONCLUSIONS
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "## üéì –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
        "\n",
        "### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ Airline Passengers\n",
        "\n",
        "**–û–∂–∏–¥–∞–µ–º–∞—è —Å–∏—Ç—É–∞—Ü–∏—è –¥–ª—è —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:**\n",
        "\n",
        "1. **SARIMA —á–∞—â–µ –≤—Å–µ–≥–æ –ª—É—á—à–µ** RNN-–º–æ–¥–µ–ª–µ–π\n",
        "   - ‚úÖ –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç (144 —Ç–æ—á–∫–∏)\n",
        "   - ‚úÖ –ß–µ—Ç–∫–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å (SARIMA –∑–∞—Ç–æ—á–µ–Ω–∞ –ø–æ–¥ —ç—Ç–æ)\n",
        "   - ‚úÖ Univariate (–æ–¥–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)\n",
        "\n",
        "2. **LSTM/GRU ‚âà —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã** —Å SARIMA –∏–ª–∏ —á—É—Ç—å —Ö—É–∂–µ\n",
        "   - ‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "   - ‚úÖ –ù–æ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
        "\n",
        "3. **Vanilla RNN —Ö—É–∂–µ –≤—Å–µ—Ö**\n",
        "   - ‚ùå –ü—Ä–æ–±–ª–µ–º–∞ vanishing gradient\n",
        "   - ‚ùå –ù–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RNN/LSTM/GRU?\n",
        "\n",
        "**Deep Learning –ª—É—á—à–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –∫–æ–≥–¥–∞:**\n",
        "\n",
        "| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | Classical (ARIMA/SARIMA) | Deep Learning (LSTM/GRU) |\n",
        "|----------------|-------------------------|-------------------------|\n",
        "| **–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö** | < 1000 —Ç–æ—á–µ–∫ | > 1000 —Ç–æ—á–µ–∫ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ) |\n",
        "| **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤** | Univariate (1 –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è) | **Multivariate (–º–Ω–æ–≥–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö)** |\n",
        "| **–ü–∞—Ç—Ç–µ—Ä–Ω—ã** | –õ–∏–Ω–µ–π–Ω—ã–µ, —Å–µ–∑–æ–Ω–Ω—ã–µ | **–ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ, —Å–ª–æ–∂–Ω—ã–µ** |\n",
        "| **–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è** | **–ë—ã—Å—Ç—Ä–æ (—Å–µ–∫—É–Ω–¥—ã)** | –ú–µ–¥–ª–µ–Ω–Ω–æ (–º–∏–Ω—É—Ç—ã/—á–∞—Å—ã) |\n",
        "| **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** | **–í—ã—Å–æ–∫–∞—è** | –ù–∏–∑–∫–∞—è (—á–µ—Ä–Ω—ã–π —è—â–∏–∫) |\n",
        "| **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** | –°—Ä–µ–¥–Ω—è—è (–ø–æ–¥–±–æ—Ä p, d, q) | **–í—ã—Å–æ–∫–∞—è (end-to-end)** |\n",
        "\n",
        "**RNN/LSTM/GRU –ø–æ–±–µ–∂–¥–∞—é—Ç –∫–æ–≥–¥–∞:**\n",
        "- ‚úÖ **Multivariate time series** (–º–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö)\n",
        "- ‚úÖ **–ë–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã** (—Ç—ã—Å—è—á–∏/–º–∏–ª–ª–∏–æ–Ω—ã —Ç–æ—á–µ–∫)\n",
        "- ‚úÖ **–ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏** (—Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)\n",
        "- ‚úÖ **–ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å** (–Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–∏–æ–¥–æ–≤, –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω–∞—è)\n",
        "- ‚úÖ **–ú–Ω–æ–≥–æ –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤** (–ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏)\n",
        "\n",
        "**–ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á –¥–ª—è RNN:**\n",
        "- üè≠ **IoT —Å–µ–Ω—Å–æ—Ä—ã:** —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, –¥–∞–≤–ª–µ–Ω–∏–µ, –≤–∏–±—Ä–∞—Ü–∏—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ\n",
        "- üìà **–§–∏–Ω–∞–Ω—Å—ã:** —Ü–µ–Ω–∞ + –æ–±—ä–µ–º + –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã + –Ω–æ–≤–æ—Å—Ç–∏\n",
        "- ‚ö° **–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞:** –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ + –ø–æ–≥–æ–¥–∞ + –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ + –ø—Ä–∞–∑–¥–Ω–∏–∫–∏\n",
        "- üè• **–ú–µ–¥–∏—Ü–∏–Ω–∞:** –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ (–ø—É–ª—å—Å, –¥–∞–≤–ª–µ–Ω–∏–µ, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞)\n",
        "\n",
        "---\n",
        "\n",
        "### üîß –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
        "\n",
        "**–†–∞–±–æ—á–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏:**\n",
        "\n",
        "```\n",
        "1. –ù–∞—á–Ω–∏—Ç–µ —Å ARIMA/SARIMA (baseline)\n",
        "   ‚Üì\n",
        "2. –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª–µ–Ω:\n",
        "   - –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç (< 1k) ‚Üí –ø–æ–ø—Ä–æ–±—É–π—Ç–µ Prophet\n",
        "   - –ë–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç (> 1k) ‚Üí –ø–æ–ø—Ä–æ–±—É–π—Ç–µ LSTM/GRU\n",
        "   ‚Üì\n",
        "3. –î–ª—è multivariate:\n",
        "   - VAR (Vector AutoRegression) - –∫–ª–∞—Å—Å–∏–∫–∞\n",
        "   - LSTM/GRU - deep learning\n",
        "   ‚Üì\n",
        "4. –ê–Ω—Å–∞–º–±–ª—å:\n",
        "   - SARIMA + LSTM —á–∞—Å—Ç–æ –ª—É—á—à–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "```\n",
        "\n",
        "**–¢—é–Ω–∏–Ω–≥ RNN –º–æ–¥–µ–ª–µ–π:**\n",
        "\n",
        "1. **Sequence length (look-back period)**\n",
        "   - –î–ª—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏: –º–∏–Ω–∏–º—É–º 1 –ø–µ—Ä–∏–æ–¥ (12 –¥–ª—è –º–µ—Å—è—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)\n",
        "   - –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ‚Üí –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ\n",
        "   - –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π ‚Üí –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
        "\n",
        "2. **Hidden size**\n",
        "   - –ú–∞–ª—ã–µ –¥–∞–Ω–Ω—ã–µ: 32-64\n",
        "   - –°—Ä–µ–¥–Ω–∏–µ: 64-128\n",
        "   - –ë–æ–ª—å—à–∏–µ: 128-512\n",
        "\n",
        "3. **Number of layers**\n",
        "   - 1-2 —Å–ª–æ—è –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ\n",
        "   - –ë–æ–ª—å—à–µ ‚Üí –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "4. **Dropout**\n",
        "   - 0.1-0.3 –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
        "   - –ö—Ä–∏—Ç–∏—á–Ω–æ –Ω–∞ –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö\n",
        "\n",
        "5. **Learning rate**\n",
        "   - –ù–∞—á–Ω–∏—Ç–µ —Å 0.001\n",
        "   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ scheduler (ReduceLROnPlateau)\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏\n",
        "\n",
        "**–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ (Phase 3, Step 3):**\n",
        "- **Attention –º–µ—Ö–∞–Ω–∏–∑–º** –¥–ª—è RNN\n",
        "- **Seq2Seq** –º–æ–¥–µ–ª–∏ –¥–ª—è multi-step forecasting\n",
        "- **Encoder-Decoder** –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
        "- **Transformer** –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ (Phase 4)\n",
        "\n",
        "**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è:**\n",
        "- **–ê–Ω—Å–∞–º–±–ª–∏:** SARIMA + LSTM\n",
        "- **Multivariate:** –¥–æ–±–∞–≤–∏—Ç—å –≤–Ω–µ—à–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "- **Transfer learning:** –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥—Ä—É–≥–∏—Ö TS\n",
        "- **Multi-step forecasting:** –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤\n",
        "\n",
        "---\n",
        "\n",
        "### üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
        "\n",
        "**–¢–µ–æ—Ä–∏—è:**\n",
        "- [\"Understanding LSTM Networks\" (Colah's Blog)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "- [\"The Unreasonable Effectiveness of RNN\" (Karpathy)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n",
        "**–ü—Ä–∞–∫—Ç–∏–∫–∞:**\n",
        "- [PyTorch RNN Tutorial](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)\n",
        "- [Time Series with LSTM](https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/)\n",
        "\n",
        "---\n",
        "\n",
        "**Phase 3, Step 2 COMPLETE!** ‚úÖ  \n",
        "**Next:** Advanced RNN - Attention & Seq2Seq (Step 3)"
    ]
})

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –Ω–æ—É—Ç–±—É–∫
notebook['cells'] = cells

with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f'‚úÖ –û–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã: {notebook_path}')
print(f'–í—Å–µ–≥–æ —è—á–µ–µ–∫: {len(cells)}')
print('üéâ –ù–æ—É—Ç–±—É–∫ RNN/LSTM/GRU –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤!')
