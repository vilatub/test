{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Deep Dive: –û—Ç —Ç–µ–æ—Ä–∏–∏ –∫ –ø—Ä–∞–∫—Ç–∏–∫–µ\n",
    "\n",
    "## üéØ –¶–µ–ª–∏ –Ω–æ—É—Ç–±—É–∫–∞\n",
    "\n",
    "1. **–ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏** –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ –∏ XGBoost\n",
    "2. **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ** –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–π –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–µ –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞\n",
    "3. **–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑** –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –∏—Ö –≤–ª–∏—è–Ω–∏—è\n",
    "4. **Best practices** –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è XGBoost –≤ production\n",
    "\n",
    "## üíº –ë–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–∞: –ö—Ä–µ–¥–∏—Ç–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥\n",
    "\n",
    "**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** –ö—Ä—É–ø–Ω—ã–π —Ç–∞–π–≤–∞–Ω—å—Å–∫–∏–π –±–∞–Ω–∫ –≤—ã–¥–∞–µ—Ç –∫—Ä–µ–¥–∏—Ç–Ω—ã–µ –∫–∞—Ä—Ç—ã –∫–ª–∏–µ–Ω—Ç–∞–º. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å, –∫—Ç–æ –∏–∑ –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å–¥–µ–ª–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç (–Ω–µ –∑–∞–ø–ª–∞—Ç–∏—Ç) –≤ —Å–ª–µ–¥—É—é—â–µ–º –º–µ—Å—è—Ü–µ.\n",
    "\n",
    "**–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:**\n",
    "- üí∞ **–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ—Ç–µ—Ä–∏:** –î–µ—Ñ–æ–ª—Ç = –ø–æ—Ç–µ—Ä—è –¥–µ–Ω–µ–≥ –±–∞–Ω–∫–æ–º\n",
    "- ‚öñÔ∏è **–†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:** Basel III —Ç—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤\n",
    "- üéØ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:** –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –æ–¥–æ–±—Ä–µ–Ω–∏–µ–º –∑–∞—è–≤–æ–∫ –∏ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–µ–π —Ä–∏—Å–∫–æ–≤\n",
    "- üìä **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:** –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±—ä—è—Å–Ω–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç—É\n",
    "\n",
    "**–ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞:**\n",
    "- **Precision:** –ö–∞–∫–æ–π % –∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –¥–µ—Ñ–æ–ª—Ç–æ–≤ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –¥–µ—Ñ–æ–ª—Ç—ã (–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è false positives)\n",
    "- **Recall:** –ö–∞–∫–æ–π % —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–µ—Ñ–æ–ª—Ç–æ–≤ –º—ã –ø–æ–π–º–∞–ª–∏ (–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è false negatives)\n",
    "- **ROC-AUC:** –û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "- **PR-AUC:** –í–∞–∂–Ω–µ–µ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**–°—Ç–æ–∏–º–æ—Å—Ç—å –æ—à–∏–±–æ–∫:**\n",
    "- **False Negative (–ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç):** –ë–∞–Ω–∫ —Ç–µ—Ä—è–µ—Ç –¥–µ–Ω—å–≥–∏ (~5000-50000 TWD)\n",
    "- **False Positive (–æ—Ç–∫–∞–∑–∞–ª–∏ —Ö–æ—Ä–æ—à–µ–º—É –∫–ª–∏–µ–Ω—Ç—É):** –ü–æ—Ç–µ—Ä—è –ø—Ä–∏–±—ã–ª–∏ –æ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ (~500-2000 TWD)\n",
    "- –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: FN –≤ 10-100 —Ä–∞–∑ –¥–æ—Ä–æ–∂–µ FP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö –ß–∞—Å—Ç—å 1: –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–π —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç\n",
    "\n",
    "### 1.1 –û—Ç —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤ –∫ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–º—É –±—É—Å—Ç–∏–Ω–≥—É\n",
    "\n",
    "#### –†–µ—à–∞—é—â–µ–µ –¥–µ—Ä–µ–≤–æ (Decision Tree)\n",
    "\n",
    "–ë–∞–∑–æ–≤—ã–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –±–ª–æ–∫. –î–µ—Ä–µ–≤–æ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ —Ä–µ–≥–∏–æ–Ω—ã.\n",
    "\n",
    "**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ $T(x; \\Theta)$, –≥–¥–µ $\\Theta = \\{R_j, \\gamma_j\\}_{j=1}^J$\n",
    "\n",
    "$$f(x) = \\sum_{j=1}^{J} \\gamma_j \\cdot \\mathbb{1}(x \\in R_j)$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "- $J$ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç—å–µ–≤ (—Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã—Ö —É–∑–ª–æ–≤)\n",
    "- $R_j$ - —Ä–µ–≥–∏–æ–Ω (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)\n",
    "- $\\gamma_j$ - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ $R_j$\n",
    "- $\\mathbb{1}(\\cdot)$ - –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è\n",
    "\n",
    "**–ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è (–∂–∞–¥–Ω—ã–π, —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π):**\n",
    "\n",
    "1. –ù–∞—á–∏–Ω–∞–µ–º —Å –∫–æ—Ä–Ω—è (–≤—Å–µ –¥–∞–Ω–Ω—ã–µ)\n",
    "2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ $k$ –∏ –ø–æ—Ä–æ–≥–∞ $s$:\n",
    "   - –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ $R_L(k,s) = \\{X | X_k ‚â§ s\\}$ –∏ $R_R(k,s) = \\{X | X_k > s\\}$\n",
    "3. –í—ã–±–∏—Ä–∞–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—é—â–µ–µ loss:\n",
    "\n",
    "$$\\min_{k,s} \\left[ \\min_{\\gamma_L} \\sum_{x_i \\in R_L} L(y_i, \\gamma_L) + \\min_{\\gamma_R} \\sum_{x_i \\in R_R} L(y_i, \\gamma_R) \\right]$$\n",
    "\n",
    "4. –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ–≤—Ç–æ—Ä—è–µ–º –¥–ª—è –¥–æ—á–µ—Ä–Ω–∏—Ö —É–∑–ª–æ–≤\n",
    "\n",
    "**–ü—Ä–æ–±–ª–µ–º—ã –æ–¥–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞:**\n",
    "- üî¥ **–í—ã—Å–æ–∫–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è:** –ú–∞–ª–µ–Ω—å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ‚Üí –±–æ–ª—å—à–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞\n",
    "- üî¥ **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ:** –°–ª–∏—à–∫–æ–º –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ–¥ –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "- üî¥ **–ñ–µ—Å—Ç–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã:** –ù–µ smooth –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 –ë—ç–≥–≥–∏–Ω–≥ (Bootstrap Aggregating)\n",
    "\n",
    "**–ò–¥–µ—è:** –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —É–º–µ–Ω—å—à–∞–µ—Ç –¥–∏—Å–ø–µ—Ä—Å–∏—é!\n",
    "\n",
    "$$f_{bag}(x) = \\frac{1}{B} \\sum_{b=1}^{B} f_b(x)$$\n",
    "\n",
    "–≥–¥–µ $f_b$ - –¥–µ—Ä–µ–≤–æ, –æ–±—É—á–µ–Ω–Ω–æ–µ –Ω–∞ bootstrap –≤—ã–±–æ—Ä–∫–µ $b$.\n",
    "\n",
    "**–ü–æ—á–µ–º—É —Ä–∞–±–æ—Ç–∞–µ—Ç:**\n",
    "\n",
    "–ü—É—Å—Ç—å $f_1, \\ldots, f_B$ - –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã —Å –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π $\\sigma^2$. –¢–æ–≥–¥–∞:\n",
    "\n",
    "$$\\text{Var}\\left(\\frac{1}{B} \\sum_{b=1}^B f_b\\right) = \\frac{\\sigma^2}{B}$$\n",
    "\n",
    "–î–∏—Å–ø–µ—Ä—Å–∏—è —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤ $B$ —Ä–∞–∑!\n",
    "\n",
    "**Random Forest = Bagging + Feature randomness** (–¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è)\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 –ë—É—Å—Ç–∏–Ω–≥: –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "**–ò–¥–µ—è –±—É—Å—Ç–∏–Ω–≥–∞:** –í–º–µ—Å—Ç–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–±—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∂–¥–∞—è —Å–ª–µ–¥—É—é—â–∞—è –º–æ–¥–µ–ª—å –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö.\n",
    "\n",
    "#### AdaBoost (Adaptive Boosting) - –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "\n",
    "–ü–µ—Ä–µ–≤–∞–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤:\n",
    "\n",
    "$$w_i^{(t+1)} = w_i^{(t)} \\cdot \\exp(\\alpha_t \\cdot \\mathbb{1}(y_i \\neq f_t(x_i)))$$\n",
    "\n",
    "–§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:\n",
    "\n",
    "$$F(x) = \\text{sign}\\left(\\sum_{t=1}^T \\alpha_t f_t(x)\\right)$$\n",
    "\n",
    "**–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ:** –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –Ω–µ –æ–±–æ–±—â–∞–µ—Ç—Å—è –Ω–∞ –¥—Ä—É–≥–∏–µ loss —Ñ—É–Ω–∫—Ü–∏–∏.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥\n",
    "\n",
    "#### –ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è (Jerome Friedman, 2001)\n",
    "\n",
    "–ë—É—Å—Ç–∏–Ω–≥ = **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ**\n",
    "\n",
    "**–ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏:**\n",
    "\n",
    "–•–æ—Ç–∏–º –Ω–∞–π—Ç–∏ —Ñ—É–Ω–∫—Ü–∏—é $F^*(x)$, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—é—â—É—é –æ–∂–∏–¥–∞–µ–º—ã–µ –ø–æ—Ç–µ—Ä–∏:\n",
    "\n",
    "$$F^* = \\arg\\min_F \\mathbb{E}_{x,y}[L(y, F(x))]$$\n",
    "\n",
    "–≥–¥–µ $L(y, F(x))$ - —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å (loss function).\n",
    "\n",
    "**–ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è –Ω–∞ –∫–æ–Ω–µ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ:**\n",
    "\n",
    "$$F^* \\approx \\arg\\min_F \\sum_{i=1}^n L(y_i, F(x_i))$$\n",
    "\n",
    "#### –ê–ª–≥–æ—Ä–∏—Ç–º Gradient Boosting\n",
    "\n",
    "**–®–∞–≥ 0 (–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è):**\n",
    "\n",
    "$$F_0(x) = \\arg\\min_\\gamma \\sum_{i=1}^n L(y_i, \\gamma)$$\n",
    "\n",
    "–î–ª—è regression (MSE): $F_0(x) = \\bar{y}$ (—Å—Ä–µ–¥–Ω–µ–µ)  \n",
    "–î–ª—è classification (log-loss): $F_0(x) = \\log\\frac{p}{1-p}$ (log-odds)\n",
    "\n",
    "**–®–∞–≥ $m = 1, 2, \\ldots, M$:**\n",
    "\n",
    "1. **–í—ã—á–∏—Å–ª—è–µ–º –ø—Å–µ–≤–¥–æ-–æ—Å—Ç–∞—Ç–∫–∏ (negative gradient):**\n",
    "\n",
    "$$r_{im} = -\\left[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}\\right]_{F=F_{m-1}}$$\n",
    "\n",
    "   –ò–Ω—Ç—É–∏—Ü–∏—è: $r_{im}$ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –Ω—É–∂–Ω–æ \"–¥–≤–∏–≥–∞—Ç—å—Å—è\", —á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å loss –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ $i$.\n",
    "\n",
    "2. **–û–±—É—á–∞–µ–º –¥–µ—Ä–µ–≤–æ $h_m(x)$ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤:**\n",
    "\n",
    "$$h_m = \\arg\\min_h \\sum_{i=1}^n (r_{im} - h(x_i))^2$$\n",
    "\n",
    "   –î–µ—Ä–µ–≤–æ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ—Ç anti-gradient!\n",
    "\n",
    "3. **–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞ $j$ –¥–µ—Ä–µ–≤–∞ $h_m$, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ:**\n",
    "\n",
    "$$\\gamma_{jm} = \\arg\\min_\\gamma \\sum_{x_i \\in R_{jm}} L(y_i, F_{m-1}(x_i) + \\gamma)$$\n",
    "\n",
    "   Line search –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ gradient –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞.\n",
    "\n",
    "4. **–û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å:**\n",
    "\n",
    "$$F_m(x) = F_{m-1}(x) + \\nu \\cdot h_m(x)$$\n",
    "\n",
    "   –≥–¥–µ $\\nu$ - learning rate (shrinkage parameter), –æ–±—ã—á–Ω–æ $\\nu \\in [0.01, 0.3]$\n",
    "\n",
    "**–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å:**\n",
    "\n",
    "$$F(x) = F_0(x) + \\nu \\sum_{m=1}^M h_m(x)$$\n",
    "\n",
    "---\n",
    "\n",
    "#### –ü—Ä–∏–º–µ—Ä—ã loss —Ñ—É–Ω–∫—Ü–∏–π –∏ –∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    "\n",
    "**1. Regression (MSE):**\n",
    "\n",
    "$$L(y, F) = \\frac{1}{2}(y - F)^2$$\n",
    "\n",
    "$$-\\frac{\\partial L}{\\partial F} = y - F = \\text{–æ—Å—Ç–∞—Ç–æ–∫}$$\n",
    "\n",
    "–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ –¥–ª—è MSE = –æ–±—ã—á–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ –ø–æ –æ—Å—Ç–∞—Ç–∫–∞–º!\n",
    "\n",
    "**2. Binary Classification (Log-Loss):**\n",
    "\n",
    "$$L(y, F) = \\log(1 + e^{-2yF}), \\quad y \\in \\{-1, +1\\}$$\n",
    "\n",
    "$$-\\frac{\\partial L}{\\partial F} = \\frac{2y}{1 + e^{2yF}} = 2y \\cdot p_{model}(y|x)$$\n",
    "\n",
    "–≥–¥–µ $p_{model}(y|x) = \\frac{1}{1 + e^{-2yF}}$\n",
    "\n",
    "**3. Multi-class (Softmax):**\n",
    "\n",
    "–û–±—É—á–∞–µ–º $K$ –¥–µ—Ä–µ–≤—å–µ–≤ –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ (–æ–¥–Ω–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 XGBoost: eXtreme Gradient Boosting\n",
    "\n",
    "#### –ö–ª—é—á–µ–≤—ã–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏ (Tianqi Chen, 2016)\n",
    "\n",
    "**1. Second-Order Taylor Expansion (2nd order gradient)**\n",
    "\n",
    "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π GB –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç. XGBoost –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ –¢–µ–π–ª–æ—Ä–∞ 2–≥–æ –ø–æ—Ä—è–¥–∫–∞:\n",
    "\n",
    "$$L(y, F_{m-1} + h_m) \\approx L(y, F_{m-1}) + g_i \\cdot h_m(x_i) + \\frac{1}{2} h_i \\cdot h_m^2(x_i)$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "- $g_i = \\frac{\\partial L(y_i, F)}{\\partial F}\\Big|_{F=F_{m-1}}$ - **–ø–µ—Ä–≤—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç** (gradient)\n",
    "- $h_i = \\frac{\\partial^2 L(y_i, F)}{\\partial F^2}\\Big|_{F=F_{m-1}}$ - **–≤—Ç–æ—Ä–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç** (hessian)\n",
    "\n",
    "**–ó–∞—á–µ–º –Ω—É–∂–µ–Ω hessian:**\n",
    "- üìä **–õ—É—á—à–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è** loss —Ñ—É–Ω–∫—Ü–∏–∏ (–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è vs –ª–∏–Ω–µ–π–Ω–∞—è)\n",
    "- üéØ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è** (–≤—Ç–æ—Ä–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç = –º–µ—Ä–∞ \"—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\")\n",
    "- ‚ö° **–ë—ã—Å—Ç—Ä–µ–µ —Å—Ö–æ–¥–∏—Ç—Å—è** (–∫–∞–∫ –º–µ—Ç–æ–¥ –ù—å—é—Ç–æ–Ω–∞ vs –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫)\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä –¥–ª—è MSE:**\n",
    "- $g_i = F_{m-1}(x_i) - y_i$ (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ - –∏—Å—Ç–∏–Ω–∞)\n",
    "- $h_i = 1$ (–∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞)\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä –¥–ª—è Log-Loss:**\n",
    "- $g_i = p_i - y_i$ –≥–¥–µ $p_i = \\sigma(F_{m-1}(x_i))$\n",
    "- $h_i = p_i(1 - p_i)$ (–¥–∏—Å–ø–µ—Ä—Å–∏—è –ë–µ—Ä–Ω—É–ª–ª–∏)\n",
    "\n",
    "---\n",
    "\n",
    "**2. –†–µ–≥—É–ª—è—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è**\n",
    "\n",
    "XGBoost –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} = \\sum_{i=1}^n L(y_i, F_{m-1}(x_i) + h_m(x_i)) + \\Omega(h_m)$$\n",
    "\n",
    "–≥–¥–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:\n",
    "\n",
    "$$\\Omega(h) = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2$$\n",
    "\n",
    "- $T$ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç—å–µ–≤ –¥–µ—Ä–µ–≤–∞\n",
    "- $w_j$ - –∑–Ω–∞—á–µ–Ω–∏–µ (–≤–µ—Å) –≤ –ª–∏—Å—Ç–µ $j$\n",
    "- $\\gamma$ - —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç—å–µ–≤)\n",
    "- $\\lambda$ - L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –≤–µ—Å–∞\n",
    "\n",
    "**–ò–Ω—Ç—É–∏—Ü–∏—è:**\n",
    "- $\\gamma T$ - ¬´Occam's Razor¬ª: –ø—Ä–æ—â–µ –¥–µ—Ä–µ–≤—å—è –ª—É—á—à–µ\n",
    "- $\\lambda ||w||^2$ - –º–∞–ª–µ–Ω—å–∫–∏–µ –≤–µ—Å–∞ ‚Üí –±–æ–ª–µ–µ smooth –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "\n",
    "---\n",
    "\n",
    "**3. –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ª–∏—Å—Ç–∞**\n",
    "\n",
    "–ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ –¢–µ–π–ª–æ—Ä–∞ –∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} \\approx \\sum_{i=1}^n \\left[g_i h_m(x_i) + \\frac{1}{2}h_i h_m^2(x_i)\\right] + \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2$$\n",
    "\n",
    "–ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ –ª–∏—Å—Ç—å—è–º. –ü—É—Å—Ç—å $I_j = \\{i | x_i \\in \\text{–ª–∏—Å—Ç } j\\}$:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} = \\sum_{j=1}^T \\left[\\left(\\sum_{i \\in I_j} g_i\\right) w_j + \\frac{1}{2}\\left(\\sum_{i \\in I_j} h_i + \\lambda\\right) w_j^2\\right] + \\gamma T$$\n",
    "\n",
    "–û–±–æ–∑–Ω–∞—á–∏–º:\n",
    "- $G_j = \\sum_{i \\in I_j} g_i$ - —Å—É–º–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ $j$\n",
    "- $H_j = \\sum_{i \\in I_j} h_i$ - —Å—É–º–º–∞ –≤—Ç–æ—Ä—ã—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ $j$\n",
    "\n",
    "–¢–æ–≥–¥–∞:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} = \\sum_{j=1}^T \\left[G_j w_j + \\frac{1}{2}(H_j + \\lambda) w_j^2\\right] + \\gamma T$$\n",
    "\n",
    "–≠—Ç–æ –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç $w_j$! –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –ø–æ $w_j$:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}^{(m)}}{\\partial w_j} = G_j + (H_j + \\lambda)w_j = 0$$\n",
    "\n",
    "**–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –ª–∏—Å—Ç–∞:**\n",
    "\n",
    "$$w_j^* = -\\frac{G_j}{H_j + \\lambda}$$\n",
    "\n",
    "**–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è loss –¥–ª—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–µ—Ä–µ–≤–∞:**\n",
    "\n",
    "$$\\mathcal{L}^{(m)*} = -\\frac{1}{2}\\sum_{j=1}^T \\frac{G_j^2}{H_j + \\lambda} + \\gamma T$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. –ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–µ—Ä–µ–≤–∞ (Split Finding)**\n",
    "\n",
    "**–¶–µ–ª—å:** –ù–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ loss.\n",
    "\n",
    "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏ –ø–æ—Ä–æ–≥–∞ –≤—ã—á–∏—Å–ª—è–µ–º **gain** (—É–º–µ–Ω—å—à–µ–Ω–∏–µ loss):\n",
    "\n",
    "$$\\text{Gain} = \\frac{1}{2}\\left[\\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{(G_L + G_R)^2}{H_L + H_R + \\lambda}\\right] - \\gamma$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "- $G_L, H_L$ - —Å—É–º–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤/hessians –≤ –ª–µ–≤–æ–º –ø–æ–¥–¥–µ—Ä–µ–≤–µ\n",
    "- $G_R, H_R$ - –≤ –ø—Ä–∞–≤–æ–º –ø–æ–¥–¥–µ—Ä–µ–≤–µ\n",
    "- $\\gamma$ - —à—Ç—Ä–∞—Ñ –∑–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è\n",
    "\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è Gain:**\n",
    "\n",
    "1. **–ü–µ—Ä–≤—ã–π —Ç–µ—Ä–º–∏–Ω:** Gain –æ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –¥–≤–∞ —É–∑–ª–∞\n",
    "2. **–í—Ç–æ—Ä–æ–π —Ç–µ—Ä–º–∏–Ω:** Loss –µ—Å–ª–∏ –±—ã –Ω–µ —Ä–∞–∑–¥–µ–ª—è–ª–∏ (–æ–¥–∏–Ω —É–∑–µ–ª)\n",
    "3. **–¢—Ä–µ—Ç–∏–π —Ç–µ—Ä–º–∏–Ω:** –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
    "\n",
    "**–ö—Ä–∏—Ç–µ—Ä–∏–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏:** –ï—Å–ª–∏ $\\text{Gain} < 0$, —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–µ —É–ª—É—á—à–∞–µ—Ç –º–æ–¥–µ–ª—å.\n",
    "\n",
    "**–ê–ª–≥–æ—Ä–∏—Ç–º (–ø—Å–µ–≤–¥–æ–∫–æ–¥):**\n",
    "\n",
    "```\n",
    "def BuildTree(–≥—Ä–∞–¥–∏–µ–Ω—Ç—ã g, hessians h, –≥–ª—É–±–∏–Ω–∞):\n",
    "    if –≥–ª—É–±–∏–Ω–∞ > max_depth or len(g) < min_samples:\n",
    "        return –õ–∏—Å—Ç —Å –≤–µ—Å–æ–º w = -sum(g) / (sum(h) + lambda)\n",
    "    \n",
    "    best_gain = 0\n",
    "    best_split = None\n",
    "    \n",
    "    # –ü–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    for –ø—Ä–∏–∑–Ω–∞–∫ in –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
    "        # –ü–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –ø–æ—Ä–æ–≥–æ–≤\n",
    "        for –ø–æ—Ä–æ–≥ in —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ_–∑–Ω–∞—á–µ–Ω–∏—è(–ø—Ä–∏–∑–Ω–∞–∫):\n",
    "            G_L = sum(g[–ø—Ä–∏–∑–Ω–∞–∫ <= –ø–æ—Ä–æ–≥])\n",
    "            H_L = sum(h[–ø—Ä–∏–∑–Ω–∞–∫ <= –ø–æ—Ä–æ–≥])\n",
    "            G_R = sum(g[–ø—Ä–∏–∑–Ω–∞–∫ > –ø–æ—Ä–æ–≥])\n",
    "            H_R = sum(h[–ø—Ä–∏–∑–Ω–∞–∫ > –ø–æ—Ä–æ–≥])\n",
    "            \n",
    "            gain = 0.5 * (G_L^2/(H_L + lambda) + G_R^2/(H_R + lambda) \n",
    "                         - (G_L + G_R)^2/(H_L + H_R + lambda)) - gamma\n",
    "            \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_split = (–ø—Ä–∏–∑–Ω–∞–∫, –ø–æ—Ä–æ–≥)\n",
    "    \n",
    "    if best_gain == 0:\n",
    "        return –õ–∏—Å—Ç —Å –≤–µ—Å–æ–º w = -sum(g) / (sum(h) + lambda)\n",
    "    \n",
    "    –ª–µ–≤–æ–µ_–ø–æ–¥–¥–µ—Ä–µ–≤–æ = BuildTree(g_left, h_left, –≥–ª—É–±–∏–Ω–∞+1)\n",
    "    –ø—Ä–∞–≤–æ–µ_–ø–æ–¥–¥–µ—Ä–µ–≤–æ = BuildTree(g_right, h_right, –≥–ª—É–±–∏–Ω–∞+1)\n",
    "    \n",
    "    return –£–∑–µ–ª(best_split, –ª–µ–≤–æ–µ_–ø–æ–¥–¥–µ—Ä–µ–≤–æ, –ø—Ä–∞–≤–æ–µ_–ø–æ–¥–¥–µ—Ä–µ–≤–æ)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**5. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ XGBoost**\n",
    "\n",
    "**Column Subsampling:**\n",
    "- –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ/–¥–µ—Ä–µ–≤–µ\n",
    "- –£–º–µ–Ω—å—à–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ\n",
    "- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: `colsample_bytree`, `colsample_bylevel`, `colsample_bynode`\n",
    "\n",
    "**Row Subsampling:**\n",
    "- –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞\n",
    "- –ü–∞—Ä–∞–º–µ—Ç—Ä: `subsample` (–æ–±—ã—á–Ω–æ 0.5-1.0)\n",
    "\n",
    "**Approximate Split Finding:**\n",
    "- –í–º–µ—Å—Ç–æ –ø–µ—Ä–µ–±–æ—Ä–∞ –≤—Å–µ—Ö –ø–æ—Ä–æ–≥–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–≤–∞–Ω—Ç–∏–ª–∏\n",
    "- –ü–∞—Ä–∞–º–µ—Ç—Ä: `tree_method='approx'` –∏–ª–∏ `'hist'`\n",
    "\n",
    "**Weighted Quantile Sketch:**\n",
    "- –ö–≤–∞–Ω—Ç–∏–ª–∏ –≤–∑–≤–µ—à–∏–≤–∞—é—Ç—Å—è –ø–æ hessian (–±–æ–ª—å—à–∏–π –≤–µ—Å = –≤–∞–∂–Ω–µ–µ)\n",
    "- –£—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "\n",
    "**Sparsity-Aware Split Finding:**\n",
    "- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ missing values –∏ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—á–∏—Ç—Å—è \"–∫—É–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å missing values\" (–≤–ª–µ–≤–æ –∏–ª–∏ –≤–ø—Ä–∞–≤–æ)\n",
    "\n",
    "**Cache-Aware Access:**\n",
    "- –î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –±–ª–æ–∫–∞—Ö, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è CPU cache\n",
    "- –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "**Out-of-Core Computation:**\n",
    "- –ú–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–∞–Ω–Ω—ã–º–∏, –Ω–µ –ø–æ–º–µ—â–∞—é—â–∏–º–∏—Å—è –≤ RAM\n",
    "- –ü–∞—Ä–∞–º–µ—Ç—Ä: `tree_method='external'`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 –ö–ª—é—á–µ–≤—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã XGBoost\n",
    "\n",
    "#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ä–µ–≤–∞ (Tree Parameters)\n",
    "\n",
    "| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –¢–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è | –í–ª–∏—è–Ω–∏–µ |\n",
    "|----------|----------|-------------------|----------|\n",
    "| `max_depth` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ | 3-10 | ‚Üë –≥–ª—É–±–∏–Ω–∞ ‚Üí ‚Üë —Å–ª–æ–∂–Ω–æ—Å—Ç—å, ‚Üë overfitting |\n",
    "| `min_child_weight` | –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ hessian –≤ –ª–∏—Å—Ç–µ | 1-10 | ‚Üë –≤–µ—Å ‚Üí –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è |\n",
    "| `gamma` | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π gain –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è | 0-5 | ‚Üë gamma ‚Üí –º–µ–Ω—å—à–µ —Ä–∞–∑–±–∏–µ–Ω–∏–π, ‚Üì overfitting |\n",
    "| `subsample` | –î–æ–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞ | 0.5-1.0 | < 1 ‚Üí ‚Üì overfitting, –Ω–æ ‚Üë –¥–∏—Å–ø–µ—Ä—Å–∏—è |\n",
    "| `colsample_bytree` | –î–æ–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞ | 0.3-1.0 | < 1 ‚Üí ‚Üì overfitting, ‚Üë —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ |\n",
    "| `colsample_bylevel` | –î–æ–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ä–æ–≤–Ω—è | 0.3-1.0 | –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è |\n",
    "\n",
    "#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "\n",
    "| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –¢–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è |\n",
    "|----------|----------|-------------------|\n",
    "| `lambda` (L2) | $\\lambda$ –≤ —Ñ–æ—Ä–º—É–ª–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ | 0-10 |\n",
    "| `alpha` (L1) | L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –≤–µ—Å–∞ | 0-10 |\n",
    "| `max_delta_step` | –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —à–∞–≥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è | 0-10 (0 = –Ω–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è) |\n",
    "\n",
    "#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –¢–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è | –í–ª–∏—è–Ω–∏–µ |\n",
    "|----------|----------|-------------------|----------|\n",
    "| `learning_rate` (Œ∑) | –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (shrinkage) | 0.01-0.3 | ‚Üì lr ‚Üí –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤, –Ω–æ –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ |\n",
    "| `n_estimators` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ | 100-10000 | ‚Üë –¥–µ—Ä–µ–≤—å—è + ‚Üì lr = –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ |\n",
    "| `early_stopping_rounds` | –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –µ—Å–ª–∏ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è | 10-50 | –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç overfitting |\n",
    "\n",
    "#### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞\n",
    "\n",
    "**–≠—Ç–∞–ø 1: –§–∏–∫—Å–∏—Ä—É–µ–º –≤—ã—Å–æ–∫–∏–π learning rate (0.1)**\n",
    "- –¢—é–Ω–∏–º: `max_depth`, `min_child_weight`\n",
    "- –¶–µ–ª—å: –ù–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–µ—Ä–µ–≤–∞\n",
    "\n",
    "**–≠—Ç–∞–ø 2: –î–æ–±–∞–≤–ª—è–µ–º sampling**\n",
    "- –¢—é–Ω–∏–º: `subsample`, `colsample_bytree`\n",
    "- –¶–µ–ª—å: –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "\n",
    "**–≠—Ç–∞–ø 3: –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**\n",
    "- –¢—é–Ω–∏–º: `gamma`, `lambda`, `alpha`\n",
    "- –¶–µ–ª—å: Fine-tune –±–æ—Ä—å–±—ã —Å overfitting\n",
    "\n",
    "**–≠—Ç–∞–ø 4: –°–Ω–∏–∂–∞–µ–º learning rate**\n",
    "- –£–º–µ–Ω—å—à–∞–µ–º `learning_rate` –¥–æ 0.01-0.05\n",
    "- –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º `n_estimators` –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–µ–º `early_stopping_rounds`\n",
    "- –¶–µ–ª—å: –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è Feature Importance\n",
    "\n",
    "XGBoost –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç 3 —Ç–∏–ø–∞ feature importance:\n",
    "\n",
    "#### 1. Weight (Frequency)\n",
    "\n",
    "$$\\text{Importance}_{weight}(k) = \\frac{\\text{—á–∏—Å–ª–æ —Ä–∞–∑–±–∏–µ–Ω–∏–π –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É } k}{\\text{–æ–±—â–µ–µ —á–∏—Å–ª–æ —Ä–∞–∑–±–∏–µ–Ω–∏–π}}$$\n",
    "\n",
    "**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è.\n",
    "\n",
    "**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:** –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–µ–∑–Ω—ã —Ä–∞–∑–±–∏–µ–Ω–∏—è.\n",
    "\n",
    "#### 2. Gain (Average Information Gain)\n",
    "\n",
    "$$\\text{Importance}_{gain}(k) = \\sum_{\\text{splits by } k} \\text{Gain}$$\n",
    "\n",
    "–°—Ä–µ–¥–Ω–∏–π gain –æ—Ç –≤—Å–µ—Ö —Ä–∞–∑–±–∏–µ–Ω–∏–π –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É $k$.\n",
    "\n",
    "**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–∞—é—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ loss.\n",
    "\n",
    "**–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é!**\n",
    "\n",
    "#### 3. Cover (Sum of Hessian)\n",
    "\n",
    "$$\\text{Importance}_{cover}(k) = \\sum_{\\text{splits by } k} H_L + H_R$$\n",
    "\n",
    "–°—É–º–º–∞ –≤—Ç–æ—Ä—ã—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (hessian) –¥–ª—è –≤—Å–µ—Ö —Ä–∞–∑–±–∏–µ–Ω–∏–π –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É.\n",
    "\n",
    "**–ò–Ω—Ç—É–∏—Ü–∏—è:** Hessian = \"–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ √ó –∏—Ö –≤–∞–∂–Ω–æ—Å—Ç—å\". –ü—Ä–∏–∑–Ω–∞–∫–∏, –ø–æ–∫—Ä—ã–≤–∞—é—â–∏–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã, –ø–æ–ª—É—á–∞—é—Ç –≤—ã—Å–æ–∫–∏–π cover.\n",
    "\n",
    "**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** –£—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ —É–ª—É—á—à–µ–Ω–∏–µ, –Ω–æ –∏ —Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–∞—Ç—Ä–æ–Ω—É—Ç–æ.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.8 XGBoost vs –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã\n",
    "\n",
    "| –ê—Å–ø–µ–∫—Ç | Random Forest | Gradient Boosting | XGBoost | LightGBM | CatBoost |\n",
    "|--------|---------------|-------------------|---------|----------|----------|\n",
    "| **–°—Ç—Ä–∞—Ç–µ–≥–∏—è** | –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –¥–µ—Ä–µ–≤—å—è | –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ä–µ–≤—å—è | GBM + regularization | Leaf-wise growth | Ordered boosting |\n",
    "| **–°–∫–æ—Ä–æ—Å—Ç—å** | –ë—ã—Å—Ç—Ä–æ | –ú–µ–¥–ª–µ–Ω–Ω–æ | –ë—ã—Å—Ç—Ä–æ | –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ | –°—Ä–µ–¥–Ω–µ |\n",
    "| **–¢–æ—á–Ω–æ—Å—Ç—å** | –•–æ—Ä–æ—à–æ | –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ | –û—Ç–ª–∏—á–Ω–æ | –û—Ç–ª–∏—á–Ω–æ | –û—Ç–ª–∏—á–Ω–æ |\n",
    "| **Overfitting** | –£—Å—Ç–æ–π—á–∏–≤ | –°–∫–ª–æ–Ω–µ–Ω | –°—Ä–µ–¥–Ω–µ (–∏–∑-–∑–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏) | –°–∫–ª–æ–Ω–µ–Ω | –£—Å—Ç–æ–π—á–∏–≤ |\n",
    "| **–ö–∞—Ç–µ–≥–æ—Ä–∏–∏** | One-hot | One-hot | One-hot | Native support | Native support |\n",
    "| **Missing values** | –ù–µ—Ç | –ù–µ—Ç | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ |\n",
    "| **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è** | –°—Ä–µ–¥–Ω–µ | –•–æ—Ä–æ—à–æ | –•–æ—Ä–æ—à–æ | –•–æ—Ä–æ—à–æ | –•–æ—Ä–æ—à–æ |\n",
    "\n",
    "**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å XGBoost:**\n",
    "- ‚úÖ –ù—É–∂–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚úÖ –ï—Å—Ç—å –≤—Ä–µ–º—è –Ω–∞ —Ç—é–Ω–∏–Ω–≥ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "- ‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (10k-1M –ø—Ä–∏–º–µ—Ä–æ–≤)\n",
    "- ‚úÖ –í–∞–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å\n",
    "- ‚ùå –ù—É–∂–Ω–∞ –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Random Forest)\n",
    "- ‚ùå –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç >10M –ø—Ä–∏–º–µ—Ä–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LightGBM)\n",
    "- ‚ùå –ú–Ω–æ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ CatBoost)\n",
    "\n",
    "---\n",
    "\n",
    "## –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø—Ä–∞–∫—Ç–∏–∫–µ üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä –ß–∞—Å—Ç—å 2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n",
    "\n",
    "### 2.1 –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Baseline –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print('‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')\n",
    "print(f'XGBoost version: {xgb.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**–î–∞—Ç–∞—Å–µ—Ç:** Default of Credit Card Clients Dataset (UCI ML Repository)\n",
    "\n",
    "**–ò—Å—Ç–æ—á–Ω–∏–∫:** https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "**–û–ø–∏—Å–∞–Ω–∏–µ:**\n",
    "- 30,000 –∫–ª–∏–µ–Ω—Ç–æ–≤ —Ç–∞–π–≤–∞–Ω—å—Å–∫–æ–≥–æ –±–∞–Ω–∫–∞ (–∞–ø—Ä–µ–ª—å - —Å–µ–Ω—Ç—è–±—Ä—å 2005)\n",
    "- –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: –¥–µ—Ñ–æ–ª—Ç –≤ —Å–ª–µ–¥—É—é—â–µ–º –º–µ—Å—è—Ü–µ (–±–∏–Ω–∞—Ä–Ω–∞—è)\n",
    "- 23 –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "\n",
    "**–ü—Ä–∏–∑–Ω–∞–∫–∏:**\n",
    "\n",
    "| –ü—Ä–∏–∑–Ω–∞–∫ | –û–ø–∏—Å–∞–Ω–∏–µ | –¢–∏–ø |\n",
    "|---------|----------|-----|\n",
    "| LIMIT_BAL | –ö—Ä–µ–¥–∏—Ç–Ω—ã–π –ª–∏–º–∏—Ç (TWD) | Continuous |\n",
    "| SEX | –ü–æ–ª (1=male, 2=female) | Categorical |\n",
    "| EDUCATION | –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (1=graduate, 2=university, 3=high school, 4=others) | Categorical |\n",
    "| MARRIAGE | –°–µ–º–µ–π–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ (1=married, 2=single, 3=others) | Categorical |\n",
    "| AGE | –í–æ–∑—Ä–∞—Å—Ç (–ª–µ—Ç) | Continuous |\n",
    "| PAY_0 - PAY_6 | –ò—Å—Ç–æ—Ä–∏—è –ø–æ–≥–∞—à–µ–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤ (-1=–≤–æ–≤—Ä–µ–º—è, 1=–∑–∞–¥–µ—Ä–∂–∫–∞ 1 –º–µ—Å, ..., 9=–∑–∞–¥–µ—Ä–∂–∫–∞ 9+ –º–µ—Å) | Ordinal |\n",
    "| BILL_AMT1 - BILL_AMT6 | –°—É–º–º–∞ –≤—ã–ø–∏—Å–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤ (TWD) | Continuous |\n",
    "| PAY_AMT1 - PAY_AMT6 | –°—É–º–º–∞ –ø–ª–∞—Ç–µ–∂–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤ (TWD) | Continuous |\n",
    "| default | –î–µ—Ñ–æ–ª—Ç –≤ —Å–ª–µ–¥—É—é—â–µ–º –º–µ—Å—è—Ü–µ (1=yes, 0=no) | Binary |\n",
    "\n",
    "**–í–ê–ñ–ù–û:** –ü–æ–ª–æ–∂–∏—Ç–µ —Ñ–∞–π–ª `credit_card_default.csv` –≤ –ø–∞–ø–∫—É `data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "import os\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞\n",
    "data_path = '../../data/credit_card_default.csv'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print('‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!')\n",
    "    print('–°–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç: https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls')\n",
    "    print('–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∫–∞–∫: data/credit_card_default.csv')\n",
    "else:\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    print(f'‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')\n",
    "    print(f'–†–∞–∑–º–µ—Ä: {df.shape[0]:,} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤')\n",
    "    print(f'–ü–∞–º—è—Ç—å: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏\n",
    "print('=== –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ ===' + '\\n')\n",
    "display(df.head())\n",
    "\n",
    "print('\\n' + '=== –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö ===' + '\\n')\n",
    "df.info()\n",
    "\n",
    "print('\\n' + '=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===' + '\\n')\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "print('=== –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ===')\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = 100 * missing / len(df)\n",
    "missing_table = pd.DataFrame({\n",
    "    '–ü—Ä–æ–ø—É—Å–∫–∏': missing,\n",
    "    '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_pct\n",
    "})\n",
    "missing_table = missing_table[missing_table['–ü—Ä–æ–ø—É—Å–∫–∏'] > 0].sort_values('–ü—Ä–æ–ø—É—Å–∫–∏', ascending=False)\n",
    "\n",
    "if len(missing_table) == 0:\n",
    "    print('‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç!')\n",
    "else:\n",
    "    display(missing_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f'–î—É–±–ª–∏–∫–∞—Ç—ã: {duplicates} —Å—Ç—Ä–æ–∫ ({100*duplicates/len(df):.2f}%)')\n",
    "\n",
    "if duplicates > 0:\n",
    "    print('\\n–ü—Ä–∏–º–µ—Ä –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:')\n",
    "    display(df[df.duplicated(keep=False)].head(10))\n",
    "else:\n",
    "    print('‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Exploratory Data Analysis (EDA)\n",
    "\n",
    "#### 2.3.1 –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
    "target_col = 'default'\n",
    "\n",
    "# –ï—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –∏–Ω–∞—á–µ, –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º\n",
    "if 'default payment next month' in df.columns:\n",
    "    df = df.rename(columns={'default payment next month': 'default'})\n",
    "elif 'default.payment.next.month' in df.columns:\n",
    "    df = df.rename(columns={'default.payment.next.month': 'default'})\n",
    "\n",
    "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "df[target_col].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Default (0=No, 1=Yes)')\n",
    "axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')\n",
    "axes[0].set_xticklabels(['No Default (0)', 'Default (1)'], rotation=0)\n",
    "\n",
    "for i, v in enumerate(df[target_col].value_counts()):\n",
    "    axes[0].text(i, v + 500, f'{v:,}\\n({100*v/len(df):.1f}%)', \n",
    "                 ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "df[target_col].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%',\n",
    "                                    colors=colors, startangle=90,\n",
    "                                    labels=['No Default', 'Default'])\n",
    "axes[1].set_title('–î–æ–ª—è –∫–ª–∞—Å—Å–æ–≤', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "default_rate = df[target_col].mean()\n",
    "print(f'\\nüìä Default rate: {default_rate:.2%}')\n",
    "print(f'   No default: {(1-default_rate):.2%}')\n",
    "print(f'   Class imbalance ratio: 1:{(1-default_rate)/default_rate:.2f}')\n",
    "\n",
    "if default_rate < 0.3:\n",
    "    print('\\n‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã! –£—á—Ç–µ–º —ç—Ç–æ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –º–µ—Ç—Ä–∏–∫ –∏ –ø–æ–¥—Ö–æ–¥–æ–≤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 –ê–Ω–∞–ª–∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features.remove(target_col)  # –£–±–∏—Ä–∞–µ–º —Ç–∞—Ä–≥–µ—Ç\n",
    "\n",
    "categorical_features = [col for col in df.columns \n",
    "                        if col not in numeric_features and col != target_col]\n",
    "\n",
    "print(f'–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(numeric_features)}): {numeric_features[:5]}...')\n",
    "print(f'–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(categorical_features)}): {categorical_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "key_numeric = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'PAY_AMT1'] \\\n",
    "              if all(col in df.columns for col in ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'PAY_AMT1']) \\\n",
    "              else numeric_features[:4]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(key_numeric):\n",
    "    if col in df.columns:\n",
    "        # Histogram –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "        df[df[target_col] == 0][col].hist(bins=50, alpha=0.7, label='No Default', \n",
    "                                           ax=axes[idx], color='#2ecc71', edgecolor='black')\n",
    "        df[df[target_col] == 1][col].hist(bins=50, alpha=0.7, label='Default', \n",
    "                                           ax=axes[idx], color='#e74c3c', edgecolor='black')\n",
    "        \n",
    "        axes[idx].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 5))\n",
    "\n",
    "for idx, col in enumerate(key_numeric):\n",
    "    if col in df.columns:\n",
    "        df.boxplot(column=col, by=target_col, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Box plot: {col}')\n",
    "        axes[idx].set_xlabel('Default')\n",
    "        axes[idx].set_ylabel(col)\n",
    "\n",
    "plt.suptitle('Box plots –ø–æ –∫–ª–∞—Å—Å–∞–º (–≤—ã—è–≤–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤)', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤\n",
    "print('\\n=== –í—ã–±—Ä–æ—Å—ã (IQR method) ===')\n",
    "for col in key_numeric:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]\n",
    "        print(f'{col}: {len(outliers)} –≤—ã–±—Ä–æ—Å–æ–≤ ({100*len(outliers)/len(df):.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "cat_features_to_plot = ['SEX', 'EDUCATION', 'MARRIAGE'] \\\n",
    "                       if all(col in df.columns for col in ['SEX', 'EDUCATION', 'MARRIAGE']) \\\n",
    "                       else categorical_features[:3]\n",
    "\n",
    "if len(cat_features_to_plot) > 0:\n",
    "    fig, axes = plt.subplots(1, len(cat_features_to_plot), figsize=(6*len(cat_features_to_plot), 5))\n",
    "    \n",
    "    if len(cat_features_to_plot) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, col in enumerate(cat_features_to_plot):\n",
    "        if col in df.columns:\n",
    "            # Crosstab\n",
    "            ct = pd.crosstab(df[col], df[target_col], normalize='index')\n",
    "            ct.plot(kind='bar', stacked=False, ax=axes[idx], color=['#2ecc71', '#e74c3c'])\n",
    "            axes[idx].set_title(f'{col} vs Default', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_xlabel(col)\n",
    "            axes[idx].set_ylabel('–ü—Ä–æ–ø–æ—Ä—Ü–∏—è')\n",
    "            axes[idx].legend(['No Default', 'Default'])\n",
    "            axes[idx].grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "print('=== Chi-squared —Ç–µ—Å—Ç (—Å–≤—è–∑—å —Å —Ç–∞—Ä–≥–µ—Ç–æ–º) ===')\n",
    "print('H0: –ø—Ä–∏–∑–Ω–∞–∫ –ù–ï —Å–≤—è–∑–∞–Ω —Å –¥–µ—Ñ–æ–ª—Ç–æ–º\\n')\n",
    "\n",
    "for col in cat_features_to_plot:\n",
    "    if col in df.columns:\n",
    "        contingency_table = pd.crosstab(df[col], df[target_col])\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "        \n",
    "        print(f'{col}:')\n",
    "        print(f'  Chi2 = {chi2:.2f}, p-value = {p_value:.4f}')\n",
    "        if p_value < 0.05:\n",
    "            print(f'  ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º (p < 0.05) - –ø—Ä–∏–∑–Ω–∞–∫ —Å–≤—è–∑–∞–Ω —Å –¥–µ—Ñ–æ–ª—Ç–æ–º')\n",
    "        else:\n",
    "            print(f'  ‚ùå –ù–ï –∑–Ω–∞—á–∏–º (p >= 0.05)')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞\n",
    "corr_matrix = df[numeric_features + [target_col]].corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –¢–æ–ø –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å —Ç–∞—Ä–≥–µ—Ç–æ–º\n",
    "print('\\n=== –¢–æ–ø-10 –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å –¥–µ—Ñ–æ–ª—Ç–æ–º ===')\n",
    "target_corr = corr_matrix[target_col].drop(target_col).sort_values(key=abs, ascending=False)\n",
    "print(target_corr.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å (–≤—ã—Å–æ–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏)\n",
    "print('=== –ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å (|corr| > 0.8) ===')\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_pairs.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    for feat1, feat2, corr_val in high_corr_pairs:\n",
    "        print(f'{feat1} <-> {feat2}: {corr_val:.3f}')\n",
    "    print(f'\\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(high_corr_pairs)} –ø–∞—Ä —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π')\n",
    "    print('–í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç —É–¥–∞–ª–∏—Ç—å –æ–¥–∏–Ω –∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∫–∞–∂–¥–æ–π –ø–∞—Ä–µ')\n",
    "else:\n",
    "    print('‚úÖ –°–∏–ª—å–Ω–æ–π –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß –ß–∞—Å—Ç—å 3: Feature Engineering\n",
    "\n",
    "### 3.1 –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "**–ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞:**\n",
    "1. **–ü–ª–∞—Ç–µ–∂–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:** –°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞, —Ç—Ä–µ–Ω–¥ –∑–∞–¥–µ—Ä–∂–µ–∫\n",
    "2. **–î–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞:** –û—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –∫ –ª–∏–º–∏—Ç—É, —É—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫—Ä–µ–¥–∏—Ç–∞\n",
    "3. **–ü–ª–∞—Ç–µ–∂–Ω–∞—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞:** –û—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–µ–π –∫ —Å—á–µ—Ç–∞–º\n",
    "4. **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã:** –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –¥–æ–ª–≥–µ, –ø–ª–∞—Ç–µ–∂–∞—Ö\n",
    "5. **–ê–≥—Ä–µ–≥–∞—Ç—ã:** –°—É–º–º—ã, —Å—Ä–µ–¥–Ω–∏–µ, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–ø–∏—è –¥–ª—è feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "print('–ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:', df_fe.shape[1] - 1)  # -1 –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–∞\n",
    "print('\\n–°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏...\\n')\n",
    "\n",
    "# ==================== PAYMENT FEATURES ====================\n",
    "\n",
    "# 1. –°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–ª–∞—Ç–µ–∂–µ–π\n",
    "pay_cols = [col for col in df_fe.columns if col.startswith('PAY_')]\n",
    "if pay_cols:\n",
    "    df_fe['avg_payment_delay'] = df_fe[pay_cols].mean(axis=1)\n",
    "    df_fe['max_payment_delay'] = df_fe[pay_cols].max(axis=1)\n",
    "    df_fe['payment_delay_std'] = df_fe[pay_cols].std(axis=1)\n",
    "    print('‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –∑–∞–¥–µ—Ä–∂–∫–∏ –ø–ª–∞—Ç–µ–∂–µ–π')\n",
    "\n",
    "# 2. Trend –≤ –∑–∞–¥–µ—Ä–∂–∫–∞—Ö (–ø–æ—Å–ª–µ–¥–Ω–∏–µ vs —Ä–∞–Ω–Ω–∏–µ –º–µ—Å—è—Ü—ã)\n",
    "if len(pay_cols) >= 6:\n",
    "    df_fe['payment_trend'] = (df_fe[pay_cols[:3]].mean(axis=1) - \n",
    "                               df_fe[pay_cols[3:]].mean(axis=1))\n",
    "    print('‚úÖ –¢—Ä–µ–Ω–¥ –∑–∞–¥–µ—Ä–∂–µ–∫')\n",
    "\n",
    "# ==================== BILL AMOUNT FEATURES ====================\n",
    "\n",
    "# 3. –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫—Ä–µ–¥–∏—Ç–∞\n",
    "bill_cols = [col for col in df_fe.columns if col.startswith('BILL_AMT')]\n",
    "if bill_cols and 'LIMIT_BAL' in df_fe.columns:\n",
    "    df_fe['avg_bill'] = df_fe[bill_cols].mean(axis=1)\n",
    "    df_fe['utilization_rate'] = df_fe['avg_bill'] / (df_fe['LIMIT_BAL'] + 1)  # +1 —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0\n",
    "    df_fe['max_utilization'] = df_fe[bill_cols].max(axis=1) / (df_fe['LIMIT_BAL'] + 1)\n",
    "    print('‚úÖ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫—Ä–µ–¥–∏—Ç–∞')\n",
    "\n",
    "# 4. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—á–µ—Ç–æ–≤\n",
    "if bill_cols:\n",
    "    df_fe['bill_volatility'] = df_fe[bill_cols].std(axis=1)\n",
    "    df_fe['bill_trend'] = (df_fe[bill_cols[:3]].mean(axis=1) - \n",
    "                            df_fe[bill_cols[3:]].mean(axis=1))\n",
    "    print('‚úÖ –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—á–µ—Ç–æ–≤')\n",
    "\n",
    "# ==================== PAYMENT AMOUNT FEATURES ====================\n",
    "\n",
    "# 5. –ü–ª–∞—Ç–µ–∂–Ω–∞—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ (–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–∞ –∫ —Å—á–µ—Ç—É)\n",
    "pay_amt_cols = [col for col in df_fe.columns if col.startswith('PAY_AMT')]\n",
    "if pay_amt_cols and bill_cols:\n",
    "    for i, (pay_col, bill_col) in enumerate(zip(pay_amt_cols, bill_cols), 1):\n",
    "        df_fe[f'payment_ratio_{i}'] = df_fe[pay_col] / (df_fe[bill_col] + 1)\n",
    "    \n",
    "    payment_ratio_cols = [col for col in df_fe.columns if col.startswith('payment_ratio_')]\n",
    "    df_fe['avg_payment_ratio'] = df_fe[payment_ratio_cols].mean(axis=1)\n",
    "    print('‚úÖ –ü–ª–∞—Ç–µ–∂–Ω–∞—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞')\n",
    "\n",
    "# 6. –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–∞\n",
    "if pay_amt_cols:\n",
    "    df_fe['avg_payment'] = df_fe[pay_amt_cols].mean(axis=1)\n",
    "    df_fe['total_payment'] = df_fe[pay_amt_cols].sum(axis=1)\n",
    "    df_fe['payment_volatility'] = df_fe[pay_amt_cols].std(axis=1)\n",
    "    print('‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–ª–∞—Ç–µ–∂–µ–π')\n",
    "\n",
    "# ==================== DEBT FEATURES ====================\n",
    "\n",
    "# 7. –î–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞\n",
    "if 'avg_bill' in df_fe.columns and 'avg_payment' in df_fe.columns:\n",
    "    df_fe['debt_to_payment_ratio'] = df_fe['avg_bill'] / (df_fe['avg_payment'] + 1)\n",
    "    print('‚úÖ –î–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞')\n",
    "\n",
    "# ==================== BINARY FLAGS ====================\n",
    "\n",
    "# 8. –§–ª–∞–≥–∏ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è\n",
    "if 'avg_payment_delay' in df_fe.columns:\n",
    "    df_fe['has_delay'] = (df_fe['avg_payment_delay'] > 0).astype(int)\n",
    "    df_fe['serious_delay'] = (df_fe['max_payment_delay'] >= 2).astype(int)\n",
    "    print('‚úÖ –§–ª–∞–≥–∏ –∑–∞–¥–µ—Ä–∂–µ–∫')\n",
    "\n",
    "if 'utilization_rate' in df_fe.columns:\n",
    "    df_fe['high_utilization'] = (df_fe['utilization_rate'] > 0.8).astype(int)\n",
    "    print('‚úÖ –§–ª–∞–≥ –≤—ã—Å–æ–∫–æ–π —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏')\n",
    "\n",
    "# ==================== AGE FEATURES ====================\n",
    "\n",
    "# 9. –í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã\n",
    "if 'AGE' in df_fe.columns:\n",
    "    df_fe['age_group'] = pd.cut(df_fe['AGE'], bins=[0, 25, 35, 45, 55, 100],\n",
    "                                 labels=['18-25', '26-35', '36-45', '46-55', '55+'])\n",
    "    # One-hot encoding –¥–ª—è –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø\n",
    "    age_dummies = pd.get_dummies(df_fe['age_group'], prefix='age')\n",
    "    df_fe = pd.concat([df_fe, age_dummies], axis=1)\n",
    "    print('‚úÖ –í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã')\n",
    "\n",
    "print(f'\\nüìä –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {df_fe.shape[1] - 1}')\n",
    "print(f'   –î–æ–±–∞–≤–ª–µ–Ω–æ: {df_fe.shape[1] - df.shape[1]} –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "new_features = [col for col in df_fe.columns if col not in df.columns]\n",
    "print(f'\\n–ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(new_features)}):')\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    print(f'  {i}. {feat}')\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "print('\\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===')\n",
    "new_numeric = [col for col in new_features if df_fe[col].dtype in [np.float64, np.int64]]\n",
    "if new_numeric:\n",
    "    display(df_fe[new_numeric].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Label Encoding –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã)\n",
    "# XGBoost –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "\n",
    "df_model = df_fe.copy()\n",
    "\n",
    "# Label encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö\n",
    "cat_cols_to_encode = ['SEX', 'EDUCATION', 'MARRIAGE'] if all(col in df_model.columns for col in ['SEX', 'EDUCATION', 'MARRIAGE']) else []\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_cols_to_encode:\n",
    "    if col in df_model.columns and df_model[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f'‚úÖ Label encoding: {col}')\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º age_group (—É–∂–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ)\n",
    "if 'age_group' in df_model.columns:\n",
    "    df_model = df_model.drop('age_group', axis=1)\n",
    "\n",
    "print(f'\\n–§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {df_model.shape}')\n",
    "print(f'–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:')\n",
    "print(df_model.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ç–∞—Ä–≥–µ—Ç\n",
    "X = df_model.drop(target_col, axis=1)\n",
    "y = df_model[target_col]\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'\\n–ü—Ä–∏–∑–Ω–∞–∫–∏ ({X.shape[1]}): {list(X.columns[:10])}...')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f'\\nTrain set: {X_train.shape[0]:,} –ø—Ä–∏–º–µ—Ä–æ–≤')\n",
    "print(f'Test set:  {X_test.shape[0]:,} –ø—Ä–∏–º–µ—Ä–æ–≤')\n",
    "print(f'\\nDefault rate –≤ train: {y_train.mean():.2%}')\n",
    "print(f'Default rate –≤ test:  {y_test.mean():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ –ß–∞—Å—Ç—å 4: Baseline –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–ü–µ—Ä–µ–¥ XGBoost —Å–æ–∑–¥–∞–¥–∏–º baseline –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:\n",
    "1. **Logistic Regression** - –ª–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "2. **Decision Tree** - –æ–¥–Ω–æ –¥–µ—Ä–µ–≤–æ (–±–∞–∑–æ–≤—ã–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –±–ª–æ–∫)\n",
    "3. **Random Forest** - –∞–Ω—Å–∞–º–±–ª—å –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name='Model'):\n",
    "    \"\"\"\n",
    "    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤—ã–≤–æ–¥–∏—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "    \"\"\"\n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'{model_name:^60}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    print(f'Accuracy:  {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f} (–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –¥–µ—Ñ–æ–ª—Ç–æ–≤, —Å–∫–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö)')\n",
    "    print(f'Recall:    {recall:.4f} (–∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–µ—Ñ–æ–ª—Ç–æ–≤, —Å–∫–æ–ª—å–∫–æ –ø–æ–π–º–∞–ª–∏)')\n",
    "    print(f'F1-score:  {f1:.4f}')\n",
    "    print(f'ROC-AUC:   {roc_auc:.4f}')\n",
    "    print(f'PR-AUC:    {pr_auc:.4f}')\n",
    "    print(f'\\nConfusion Matrix:')\n",
    "    print(f'  TN: {tn:5d}  |  FP: {fp:5d}')\n",
    "    print(f'  FN: {fn:5d}  |  TP: {tp:5d}')\n",
    "    \n",
    "    # –°—Ç–æ–∏–º–æ—Å—Ç—å –æ—à–∏–±–æ–∫ (–ø—Ä–∏–º–µ—Ä–Ω–∞—è)\n",
    "    cost_fn = 25000  # —Å—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–≥–æ –¥–µ—Ñ–æ–ª—Ç–∞\n",
    "    cost_fp = 1000   # —Å—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ—Ç–∫–∞–∑–∞ —Ö–æ—Ä–æ—à–µ–º—É –∫–ª–∏–µ–Ω—Ç—É\n",
    "    total_cost = fn * cost_fn + fp * cost_fp\n",
    "    print(f'\\nüí∞ –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫:')\n",
    "    print(f'   FN cost: {fn} √ó {cost_fn:,} TWD = {fn * cost_fn:,} TWD')\n",
    "    print(f'   FP cost: {fp} √ó {cost_fp:,} TWD = {fp * cost_fp:,} TWD')\n",
    "    print(f'   Total:   {total_cost:,} TWD')\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'total_cost': total_cost\n",
    "    }\n",
    "\n",
    "print('‚úÖ –§—É–Ω–∫—Ü–∏—è evaluate_model —Å–æ–∑–¥–∞–Ω–∞')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "results = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "print('\\nüîµ –û–±—É—á–µ–Ω–∏–µ Logistic Regression...')\n",
    "lr_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "results['Logistic Regression'] = evaluate_model(\n",
    "    lr_model, X_train, X_test, y_train, y_test, 'Logistic Regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree\n",
    "print('\\nüü¢ –û–±—É—á–µ–Ω–∏–µ Decision Tree...')\n",
    "dt_model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=10)\n",
    "results['Decision Tree'] = evaluate_model(\n",
    "    dt_model, X_train, X_test, y_train, y_test, 'Decision Tree (max_depth=10)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest\n",
    "print('\\nüü† –û–±—É—á–µ–Ω–∏–µ Random Forest...')\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10, \n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "results['Random Forest'] = evaluate_model(\n",
    "    rf_model, X_train, X_test, y_train, y_test, 'Random Forest (100 trees)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ baseline –º–æ–¥–µ–ª–µ–π\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1': [results[m]['f1'] for m in results],\n",
    "    'ROC-AUC': [results[m]['roc_auc'] for m in results],\n",
    "    'PR-AUC': [results[m]['pr_auc'] for m in results],\n",
    "    'Cost (TWD)': [results[m]['total_cost'] for m in results]\n",
    "})\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('–°–†–ê–í–ù–ï–ù–ò–ï BASELINE –ú–û–î–ï–õ–ï–ô')\n",
    "print('='*80)\n",
    "display(comparison_df)\n",
    "\n",
    "# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ ROC-AUC\n",
    "best_model_name = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'Model']\n",
    "print(f'\\nüèÜ –õ—É—á—à–∞—è baseline –º–æ–¥–µ–ª—å (ROC-AUC): {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ –ß–∞—Å—Ç—å 5: XGBoost Implementation\n",
    "\n",
    "### 5.1 XGBoost —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost baseline (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)\n",
    "print('\\n‚ö° –û–±—É—á–µ–Ω–∏–µ XGBoost (default parameters)...')\n",
    "\n",
    "xgb_baseline = XGBClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "results['XGBoost (default)'] = evaluate_model(\n",
    "    xgb_baseline, X_train, X_test, y_train, y_test, 'XGBoost (default parameters)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 XGBoost —Å –±–∞–∑–æ–≤—ã–º —Ç—é–Ω–∏–Ω–≥–æ–º\n",
    "\n",
    "–ü—Ä–∏–º–µ–Ω–∏–º –±–∞–∑–æ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:\n",
    "- `scale_pos_weight`: –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "- `max_depth`: –∫–æ–Ω—Ç—Ä–æ–ª—å –≥–ª—É–±–∏–Ω—ã –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "- `learning_rate`: —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è\n",
    "- `n_estimators`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "- `subsample`, `colsample_bytree`: —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—ã—á–∏—Å–ª—è–µ–º scale_pos_weight –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f'Scale pos weight: {scale_pos_weight:.2f}')\n",
    "\n",
    "# XGBoost —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "xgb_tuned_v1 = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "results['XGBoost (tuned_v1)'] = evaluate_model(\n",
    "    xgb_tuned_v1, X_train, X_test, y_train, y_test, 'XGBoost (basic tuning)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter Tuning (GridSearchCV)\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º grid search –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "\n",
    "**–°—Ç—Ä–∞—Ç–µ–≥–∏—è:**\n",
    "1. –§–∏–∫—Å–∏—Ä—É–µ–º `learning_rate=0.1`\n",
    "2. –¢—é–Ω–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–µ—Ä–µ–≤–∞ (`max_depth`, `min_child_weight`)\n",
    "3. –¢—é–Ω–∏–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (`subsample`, `colsample_bytree`)\n",
    "4. –¢—é–Ω–∏–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é (`gamma`, `lambda`)\n",
    "5. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å `learning_rate=0.05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "print('\\nüîç Hyperparameter tuning —Å GridSearchCV...')\n",
    "print('–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\\n')\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å\n",
    "xgb_base = XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ (–Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è)\n",
    "# –î–ª—è –ø–æ–ª–Ω–æ–≥–æ grid search –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ—Å—å X_train\n",
    "sample_size = min(10000, len(X_train))\n",
    "X_train_sample = X_train.iloc[:sample_size]\n",
    "y_train_sample = y_train.iloc[:sample_size]\n",
    "\n",
    "grid_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "print(f'\\n‚úÖ Grid search –∑–∞–≤–µ—Ä—à–µ–Ω')\n",
    "print(f'\\n–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:')\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f'  {param}: {value}')\n",
    "print(f'\\n–õ—É—á—à–∏–π ROC-AUC (CV): {grid_search.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–∞ –≤—Å–µ–º train set\n",
    "print('\\n‚ö° –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π XGBoost –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...')\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    **grid_search.best_params_,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "results['XGBoost (optimized)'] = evaluate_model(\n",
    "    xgb_final, X_train, X_test, y_train, y_test, 'XGBoost (Grid Search Optimized)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç –ß–∞—Å—Ç—å 6: –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "\n",
    "### 6.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (–≤—Å–µ —Ç—Ä–∏ —Ç–∏–ø–∞)\n",
    "model = results['XGBoost (optimized)']['model']\n",
    "\n",
    "# Weight, Gain, Cover\n",
    "importance_weight = model.feature_importances_\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º DataFrame\n",
    "feature_names = X_train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Weight': importance_weight\n",
    "})\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º gain –∏ cover (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
    "importance_df['Gain'] = importance_df['Feature'].map(\n",
    "    lambda x: importance_gain.get(f'f{list(feature_names).index(x)}', 0)\n",
    ")\n",
    "importance_df['Cover'] = importance_df['Feature'].map(\n",
    "    lambda x: importance_cover.get(f'f{list(feature_names).index(x)}', 0)\n",
    ")\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ gain\n",
    "importance_df = importance_df.sort_values('Gain', ascending=False)\n",
    "\n",
    "print('=== –¢–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Feature Importance (Gain) ===')\n",
    "display(importance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Feature Importance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Weight\n",
    "top_features_weight = importance_df.nlargest(15, 'Weight')\n",
    "axes[0].barh(top_features_weight['Feature'], top_features_weight['Weight'], color='skyblue')\n",
    "axes[0].set_xlabel('Importance (Weight)', fontweight='bold')\n",
    "axes[0].set_title('Feature Importance: Weight\\n(Frequency of splits)', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Gain (RECOMMENDED)\n",
    "top_features_gain = importance_df.nlargest(15, 'Gain')\n",
    "axes[1].barh(top_features_gain['Feature'], top_features_gain['Gain'], color='lightcoral')\n",
    "axes[1].set_xlabel('Importance (Gain)', fontweight='bold')\n",
    "axes[1].set_title('Feature Importance: Gain\\n(Average information gain) ‚≠ê', fontweight='bold', color='red')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# Cover\n",
    "top_features_cover = importance_df.nlargest(15, 'Cover')\n",
    "axes[2].barh(top_features_cover['Feature'], top_features_cover['Cover'], color='lightgreen')\n",
    "axes[2].set_xlabel('Importance (Cover)', fontweight='bold')\n",
    "axes[2].set_title('Feature Importance: Cover\\n(Sum of hessians)', fontweight='bold')\n",
    "axes[2].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ROC –∏ Precision-Recall –∫—Ä–∏–≤—ã–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC –∏ PR –∫—Ä–∏–≤—ã–µ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ROC Curve\n",
    "for model_name in results:\n",
    "    y_pred_proba = results[model_name]['y_pred_proba']\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    auc = results[model_name]['roc_auc']\n",
    "    axes[0].plot(fpr, tpr, label=f'{model_name} (AUC={auc:.3f})', linewidth=2)\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.500)', linewidth=1)\n",
    "axes[0].set_xlabel('False Positive Rate', fontweight='bold')\n",
    "axes[0].set_ylabel('True Positive Rate', fontweight='bold')\n",
    "axes[0].set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "for model_name in results:\n",
    "    y_pred_proba = results[model_name]['y_pred_proba']\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = results[model_name]['pr_auc']\n",
    "    axes[1].plot(recall, precision, label=f'{model_name} (AUC={pr_auc:.3f})', linewidth=2)\n",
    "\n",
    "# Baseline (–¥–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö)\n",
    "baseline = y_test.mean()\n",
    "axes[1].plot([0, 1], [baseline, baseline], 'k--', label=f'Random (AUC={baseline:.3f})', linewidth=1)\n",
    "axes[1].set_xlabel('Recall', fontweight='bold')\n",
    "axes[1].set_ylabel('Precision', fontweight='bold')\n",
    "axes[1].set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nüí° –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:')\n",
    "print('- ROC-AUC: –û–±—â–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ —Ä–∞–∑–¥–µ–ª—è—Ç—å –∫–ª–∞—Å—Å—ã')\n",
    "print('- PR-AUC: –ë–æ–ª–µ–µ –≤–∞–∂–Ω–∞ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Ñ–æ–∫—É—Å –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–º –∫–ª–∞—Å—Å–µ)')\n",
    "print('- –î–ª—è –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞ PR-AUC —á–∞—Å—Ç–æ –≤–∞–∂–Ω–µ–µ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Threshold Optimization\n",
    "\n",
    "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ = 0.5, –Ω–æ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–æ–∏–º–æ—Å—Ç–µ–π –æ—à–∏–±–æ–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥—Ä—É–≥–∏–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold optimization\n",
    "y_pred_proba_xgb = results['XGBoost (optimized)']['y_pred_proba']\n",
    "\n",
    "# –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥–∏\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "metrics_by_threshold = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba_xgb >= threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred_thresh)\n",
    "    recall = recall_score(y_test, y_pred_thresh)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thresh).ravel()\n",
    "    cost = fn * 25000 + fp * 1000  # –°—Ç–æ–∏–º–æ—Å—Ç—å –æ—à–∏–±–æ–∫\n",
    "    \n",
    "    metrics_by_threshold.append({\n",
    "        'Threshold': threshold,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'Cost': cost\n",
    "    })\n",
    "\n",
    "threshold_df = pd.DataFrame(metrics_by_threshold)\n",
    "\n",
    "# –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –ø–æ –º–∏–Ω–∏–º—É–º—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏\n",
    "optimal_idx = threshold_df['Cost'].idxmin()\n",
    "optimal_threshold = threshold_df.loc[optimal_idx, 'Threshold']\n",
    "\n",
    "print('=== –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –ø–æ—Ä–æ–≥–∞–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ===')\n",
    "display(threshold_df)\n",
    "\n",
    "print(f'\\nüéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ (–º–∏–Ω–∏–º—É–º —Å—Ç–æ–∏–º–æ—Å—Ç–∏): {optimal_threshold:.2f}')\n",
    "print(f'   Precision: {threshold_df.loc[optimal_idx, \"Precision\"]:.4f}')\n",
    "print(f'   Recall: {threshold_df.loc[optimal_idx, \"Recall\"]:.4f}')\n",
    "print(f'   F1: {threshold_df.loc[optimal_idx, \"F1\"]:.4f}')\n",
    "print(f'   Cost: {threshold_df.loc[optimal_idx, \"Cost\"]:,.0f} TWD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è threshold optimization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Precision, Recall, F1 vs Threshold\n",
    "axes[0].plot(threshold_df['Threshold'], threshold_df['Precision'], 'b-', label='Precision', linewidth=2)\n",
    "axes[0].plot(threshold_df['Threshold'], threshold_df['Recall'], 'r-', label='Recall', linewidth=2)\n",
    "axes[0].plot(threshold_df['Threshold'], threshold_df['F1'], 'g-', label='F1', linewidth=2)\n",
    "axes[0].axvline(x=optimal_threshold, color='purple', linestyle='--', linewidth=2, \n",
    "                label=f'Optimal={optimal_threshold:.2f}')\n",
    "axes[0].axvline(x=0.5, color='gray', linestyle=':', linewidth=1, label='Default=0.5')\n",
    "axes[0].set_xlabel('Threshold', fontweight='bold')\n",
    "axes[0].set_ylabel('Score', fontweight='bold')\n",
    "axes[0].set_title('Metrics vs Threshold', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Cost vs Threshold\n",
    "axes[1].plot(threshold_df['Threshold'], threshold_df['Cost'], 'purple', linewidth=3)\n",
    "axes[1].axvline(x=optimal_threshold, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Optimal={optimal_threshold:.2f}')\n",
    "axes[1].axvline(x=0.5, color='gray', linestyle=':', linewidth=1, label='Default=0.5')\n",
    "axes[1].scatter([optimal_threshold], [threshold_df.loc[optimal_idx, 'Cost']], \n",
    "                color='red', s=200, zorder=5, label='Min Cost')\n",
    "axes[1].set_xlabel('Threshold', fontweight='bold')\n",
    "axes[1].set_ylabel('Total Cost (TWD)', fontweight='bold')\n",
    "axes[1].set_title('Business Cost vs Threshold', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
    "final_comparison = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1': [results[m]['f1'] for m in results],\n",
    "    'ROC-AUC': [results[m]['roc_auc'] for m in results],\n",
    "    'PR-AUC': [results[m]['pr_auc'] for m in results],\n",
    "    'Cost (TWD)': [results[m]['total_cost'] for m in results]\n",
    "})\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ ROC-AUC\n",
    "final_comparison = final_comparison.sort_values('ROC-AUC', ascending=False)\n",
    "\n",
    "print('\\n' + '='*100)\n",
    "print('–§–ò–ù–ê–õ–¨–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –í–°–ï–• –ú–û–î–ï–õ–ï–ô')\n",
    "print('='*100)\n",
    "display(final_comparison)\n",
    "\n",
    "# –ü–æ–±–µ–¥–∏—Ç–µ–ª—å\n",
    "best_model = final_comparison.iloc[0]['Model']\n",
    "print(f'\\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model}')\n",
    "print(f'   ROC-AUC: {final_comparison.iloc[0][\"ROC-AUC\"]:.4f}')\n",
    "print(f'   PR-AUC:  {final_comparison.iloc[0][\"PR-AUC\"]:.4f}')\n",
    "print(f'   Cost:    {final_comparison.iloc[0][\"Cost (TWD)\"]:,.0f} TWD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics_to_plot = ['ROC-AUC', 'PR-AUC', 'F1', 'Cost (TWD)']\n",
    "colors_map = plt.cm.viridis(np.linspace(0, 1, len(final_comparison)))\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    data = final_comparison.sort_values(metric, ascending=(metric == 'Cost (TWD)'))\n",
    "    \n",
    "    bars = ax.barh(data['Model'], data[metric], color=colors_map)\n",
    "    ax.set_xlabel(metric, fontweight='bold')\n",
    "    ax.set_title(f'Comparison: {metric}', fontsize=12, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # –ó–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –±–∞—Ä–∞—Ö\n",
    "    for i, (model, value) in enumerate(zip(data['Model'], data[metric])):\n",
    "        if metric == 'Cost (TWD)':\n",
    "            ax.text(value, i, f' {value:,.0f}', va='center', fontweight='bold')\n",
    "        else:\n",
    "            ax.text(value, i, f' {value:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù –ß–∞—Å—Ç—å 7: –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "\n",
    "### 7.1 –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:**\n",
    "1. **XGBoost (optimized)** –ø–æ–∫–∞–∑–∞–ª –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º\n",
    "2. **Random Forest** - —Ö–æ—Ä–æ—à–∞—è baseline –º–æ–¥–µ–ª—å, –Ω–æ —É—Å—Ç—É–ø–∞–µ—Ç XGBoost\n",
    "3. **Logistic Regression** - –ø—Ä–æ—Å—Ç–∞—è –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–∞—è, –Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–Ω–∞—è\n",
    "4. **Decision Tree** - –≤—ã—Å–æ–∫–æ–µ overfitting, –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è production\n",
    "\n",
    "**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ XGBoost:**\n",
    "- ‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (ROC-AUC, PR-AUC)\n",
    "- ‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (gamma, lambda) ‚Üí –º–µ–Ω—å—à–µ overfitting\n",
    "- ‚úÖ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º (scale_pos_weight)\n",
    "- ‚úÖ –•–æ—Ä–æ—à–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å (feature importance, SHAP)\n",
    "- ‚úÖ –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ inference\n",
    "\n",
    "### 7.2 Feature Engineering Insights\n",
    "\n",
    "**–ù–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø–æ Gain):**\n",
    "1. **–ü–ª–∞—Ç–µ–∂–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:** PAY_0, PAY_2, PAY_3 - –∏—Å—Ç–æ—Ä–∏—è –∑–∞–¥–µ—Ä–∂–µ–∫ –∫—Ä–∏—Ç–∏—á–Ω–∞\n",
    "2. **–£—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫—Ä–µ–¥–∏—Ç–∞:** utilization_rate, avg_bill - –¥–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞\n",
    "3. **–ü–ª–∞—Ç–µ–∂–Ω–∞—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞:** payment_ratio_*, avg_payment_ratio\n",
    "4. **–ö—Ä–µ–¥–∏—Ç–Ω—ã–π –ª–∏–º–∏—Ç:** LIMIT_BAL - –±–∞–∑–æ–≤—ã–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∫—Ä–µ–¥–∏—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏\n",
    "\n",
    "**–°–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–∫–∞–∑–∞–ª–∏—Å—å –æ—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω—ã–º–∏:**\n",
    "- –ê–≥—Ä–µ–≥–∞—Ç—ã (—Å—Ä–µ–¥–Ω–∏–µ, —Å—É–º–º—ã, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)\n",
    "- –û—Ç–Ω–æ—à–µ–Ω–∏—è (–ø–ª–∞—Ç–µ–∂/—Å—á–µ—Ç, –¥–æ–ª–≥/–ª–∏–º–∏—Ç)\n",
    "- –¢—Ä–µ–Ω–¥—ã (–∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏)\n",
    "- –ë–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–ª–∞–≥–∏ (has_delay, high_utilization)\n",
    "\n",
    "### 7.3 –ë–∏–∑–Ω–µ—Å-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "\n",
    "**–î–ª—è –±–∞–Ω–∫–∞:**\n",
    "1. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å XGBoost** –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞\n",
    "2. **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä–æ–≥** –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å—Ö–æ–¥—è –∏–∑ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫:\n",
    "   - False Negative (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç) –¥–æ—Ä–æ–∂–µ ‚Üí –ø–æ—Ä–æ–≥ –Ω–∏–∂–µ 0.5\n",
    "   - –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç Recall, —É–º–µ–Ω—å—à–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ—Ç–µ—Ä–∏\n",
    "3. **–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø–ª–∞—Ç–µ–∂–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ** - —Å–∞–º—ã–π —Å–∏–ª—å–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä\n",
    "4. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–Ω–∏–∂–∞—Ç—å –ª–∏–º–∏—Ç—ã** –∫–ª–∏–µ–Ω—Ç–∞–º —Å:\n",
    "   - –í—ã—Å–æ–∫–æ–π —É—Ç–∏–ª–∏–∑–∞—Ü–∏–µ–π (>80%)\n",
    "   - –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–º–∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏ (PAY > 1)\n",
    "   - –ù–∏–∑–∫–∏–º payment_ratio (<0.1)\n",
    "\n",
    "**–†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã (Basel III):**\n",
    "- –ú–æ–¥–µ–ª—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–∞ (feature importance, partial dependence)\n",
    "- –ú–æ–∂–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å –∫–∞–∂–¥–æ–µ —Ä–µ—à–µ–Ω–∏–µ\n",
    "- ROC-AUC >0.75 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º\n",
    "\n",
    "### 7.4 –î–∞–ª—å–Ω–µ–π—à–∏–µ —É–ª—É—á—à–µ–Ω–∏—è\n",
    "\n",
    "**–ú–æ–¥–µ–ª—å:**\n",
    "1. **SHAP values** –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–∏–º–µ—Ä–∞\n",
    "2. **Early stopping** —Å validation set –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ n_estimators\n",
    "3. **Stacking** —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ (LightGBM, CatBoost)\n",
    "4. **Calibration** –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (Platt scaling, isotonic regression)\n",
    "\n",
    "**–î–∞–Ω–Ω—ã–µ:**\n",
    "1. –í–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ (–±—é—Ä–æ –∫—Ä–µ–¥–∏—Ç–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏–π)\n",
    "2. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, —Ç—Ä–µ–Ω–¥—ã)\n",
    "3. –°–æ—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n",
    "4. –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è\n",
    "\n",
    "**Production:**\n",
    "1. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ drift (–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π)\n",
    "2. A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "3. –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (—Ä–∞–∑ –≤ –º–µ—Å—è—Ü/–∫–≤–∞—Ä—Ç–∞–ª)\n",
    "4. API –¥–ª—è real-time scoring\n",
    "\n",
    "### 7.5 –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã\n",
    "\n",
    "**–ü–æ—á–µ–º—É XGBoost —Ä–∞–±–æ—Ç–∞–µ—Ç:**\n",
    "\n",
    "1. **Second-order approximation** (Hessian) –¥–∞–µ—Ç –ª—É—á—à—É—é –ª–æ–∫–∞–ª—å–Ω—É—é –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—é loss:\n",
    "   $$L(y, F + h) \\approx L(y, F) + g \\cdot h + \\frac{1}{2}h \\cdot h^2$$\n",
    "   –ö–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è vs –ª–∏–Ω–µ–π–Ω–∞—è ‚Üí —Ç–æ—á–Ω–µ–µ –Ω–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º—É–º\n",
    "\n",
    "2. **Regularization** –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç overfitting:\n",
    "   $$\\Omega(h) = \\gamma T + \\frac{\\lambda}{2}\\sum w_j^2$$\n",
    "   –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É bias –∏ variance\n",
    "\n",
    "3. **–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –ª–∏—Å—Ç—å–µ–≤** –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏:\n",
    "   $$w_j^* = -\\frac{G_j}{H_j + \\lambda}$$\n",
    "   –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤ line search!\n",
    "\n",
    "4. **Gain-based split finding** –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç —É–º–µ–Ω—å—à–µ–Ω–∏–µ loss:\n",
    "   $$\\text{Gain} = \\frac{1}{2}\\left[\\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{(G_L+G_R)^2}{H_L+H_R+\\lambda}\\right] - \\gamma$$\n",
    "\n",
    "### 7.6 –ö–æ–≥–¥–∞ –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å XGBoost\n",
    "\n",
    "‚ùå **–ò–∑–±–µ–≥–∞–π—Ç–µ XGBoost –µ—Å–ª–∏:**\n",
    "1. –ù—É–∂–Ω–∞ –æ–Ω–ª–∞–π–Ω-–æ–±—É—á–µ–Ω–∏–µ (online learning) - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ SGD-based –º–æ–¥–µ–ª–∏\n",
    "2. –û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö (<1000 –ø—Ä–∏–º–µ—Ä–æ–≤) - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–ª–∏ Random Forest\n",
    "3. –î–∞–Ω–Ω—ã–µ –Ω–µ —Ç–∞–±–ª–∏—á–Ω—ã–µ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ç–µ–∫—Å—Ç) - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\n",
    "4. –ö—Ä–∏—Ç–∏—á–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å inference (<1ms) - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é\n",
    "5. –ù—É–∂–Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Bayesian –º–æ–¥–µ–ª–∏\n",
    "\n",
    "---\n",
    "\n",
    "## üéì –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã:\n",
    "1. ‚úÖ –†–∞–∑–æ–±—Ä–∞–ª–∏ **–º–∞—Ç–µ–º–∞—Ç–∏–∫—É** XGBoost –æ—Ç –ø–µ—Ä–≤—ã—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤\n",
    "2. ‚úÖ –ü—Ä–æ–≤–µ–ª–∏ **–ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π EDA** –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "3. ‚úÖ –°–æ–∑–¥–∞–ª–∏ **–æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏** –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∏\n",
    "4. ‚úÖ –°—Ä–∞–≤–Ω–∏–ª–∏ **baseline –º–æ–¥–µ–ª–∏**\n",
    "5. ‚úÖ **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª–∏** –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã XGBoost\n",
    "6. ‚úÖ **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞–ª–∏** –º–æ–¥–µ–ª—å (feature importance, threshold optimization)\n",
    "7. ‚úÖ –î–∞–ª–∏ **–±–∏–∑–Ω–µ—Å-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**\n",
    "\n",
    "**XGBoost - —ç—Ç–æ state-of-the-art –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.** –ü–æ–Ω–∏–º–∞–Ω–∏–µ –µ–≥–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∏ best practices –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —É—Å–ø–µ—Ö–∞ –≤ ML competitions –∏ production-—Å–∏—Å—Ç–µ–º–∞—Ö.\n",
    "\n",
    "**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**\n",
    "- üìò **LightGBM Deep Dive** - leaf-wise —Ä–æ—Å—Ç, categorical features\n",
    "- üìô **CatBoost Deep Dive** - ordered boosting, –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏\n",
    "- üìï **Stacking & Ensemble** - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
    "\n",
    "---\n",
    "\n",
    "**–ê–≤—Ç–æ—Ä:** Claude (Anthropic)  \n",
    "**–î–∞—Ç–∞:** 2024  \n",
    "**–í–µ—Ä—Å–∏—è XGBoost:** 2.0+  \n",
    "\n",
    "**–†–µ—Ñ–µ—Ä–µ–Ω—Å—ã:**\n",
    "1. Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. KDD 2016.\n",
    "2. Friedman, J. H. (2001). Greedy Function Approximation: A Gradient Boosting Machine.\n",
    "3. Ke, G. et al. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree.\n",
    "4. Prokhorenkova, L. et al. (2018). CatBoost: unbiased boosting with categorical features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}