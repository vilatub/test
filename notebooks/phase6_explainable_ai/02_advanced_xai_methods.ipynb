{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9383f16d",
   "metadata": {},
   "source": [
    "# Phase 6.2: Advanced Explainable AI Methods\n",
    "\n",
    "## Deep Learning Interpretability & Counterfactual Analysis\n",
    "\n",
    "This notebook covers advanced XAI techniques:\n",
    "\n",
    "1. **DeepSHAP** - SHAP values for deep neural networks\n",
    "2. **Attention Visualization** - Interpreting attention weights\n",
    "3. **Counterfactual Explanations** - \"What-if\" scenarios\n",
    "4. **Model Distillation** - Extracting interpretable rules from black-box models\n",
    "\n",
    "### Dataset\n",
    "Credit card fraud detection with class imbalance - ideal for demonstrating\n",
    "explainability in high-stakes decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04574550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, MultiHeadAttention, LayerNormalization, Flatten\n",
    "\n",
    "# SHAP\n",
    "import shap\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully\")\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"SHAP: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fraud_dataset(n_samples=10000, fraud_rate=0.05):\n",
    "    \"\"\"\n",
    "    Create synthetic credit card fraud dataset.\n",
    "\n",
    "    Features represent transaction characteristics that\n",
    "    are meaningful for explainability demonstrations.\n",
    "    \"\"\"\n",
    "    n_fraud = int(n_samples * fraud_rate)\n",
    "    n_normal = n_samples - n_fraud\n",
    "\n",
    "    # Normal transactions\n",
    "    normal = {\n",
    "        'amount': np.random.lognormal(4, 1, n_normal),  # $50-100 typical\n",
    "        'hour': np.random.choice(range(8, 22), n_normal),  # Daytime\n",
    "        'day_of_week': np.random.choice(range(7), n_normal),\n",
    "        'merchant_category': np.random.choice(range(10), n_normal),\n",
    "        'distance_from_home': np.abs(np.random.normal(5, 3, n_normal)),\n",
    "        'time_since_last_txn': np.random.exponential(24, n_normal),  # Hours\n",
    "        'avg_txn_amount': np.random.lognormal(4, 0.5, n_normal),\n",
    "        'txn_frequency': np.random.poisson(10, n_normal),  # Per month\n",
    "        'is_online': np.random.binomial(1, 0.3, n_normal),\n",
    "        'is_international': np.random.binomial(1, 0.05, n_normal),\n",
    "    }\n",
    "\n",
    "    # Fraudulent transactions - different patterns\n",
    "    fraud = {\n",
    "        'amount': np.random.lognormal(6, 1.5, n_fraud),  # Higher amounts\n",
    "        'hour': np.random.choice(list(range(0, 6)) + list(range(22, 24)), n_fraud),  # Night\n",
    "        'day_of_week': np.random.choice(range(7), n_fraud),\n",
    "        'merchant_category': np.random.choice([0, 1, 2], n_fraud),  # Specific categories\n",
    "        'distance_from_home': np.abs(np.random.normal(50, 30, n_fraud)),  # Far from home\n",
    "        'time_since_last_txn': np.random.exponential(1, n_fraud),  # Quick succession\n",
    "        'avg_txn_amount': np.random.lognormal(4, 0.5, n_fraud),\n",
    "        'txn_frequency': np.random.poisson(10, n_fraud),\n",
    "        'is_online': np.random.binomial(1, 0.7, n_fraud),  # More online\n",
    "        'is_international': np.random.binomial(1, 0.4, n_fraud),  # More international\n",
    "    }\n",
    "\n",
    "    # Combine\n",
    "    df_normal = pd.DataFrame(normal)\n",
    "    df_normal['is_fraud'] = 0\n",
    "\n",
    "    df_fraud = pd.DataFrame(fraud)\n",
    "    df_fraud['is_fraud'] = 1\n",
    "\n",
    "    df = pd.concat([df_normal, df_fraud], ignore_index=True)\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "df = create_fraud_dataset(n_samples=10000, fraud_rate=0.05)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Fraud rate: {df['is_fraud'].mean()*100:.1f}%\")\n",
    "print(f\"\\nFeatures: {list(df.columns[:-1])}\")\n",
    "print(f\"\\nSample data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a33239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_names = ['amount', 'hour', 'day_of_week', 'merchant_category',\n",
    "                 'distance_from_home', 'time_since_last_txn', 'avg_txn_amount',\n",
    "                 'txn_frequency', 'is_online', 'is_international']\n",
    "\n",
    "X = df[feature_names].values\n",
    "y = df['is_fraud'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training fraud rate: {y_train.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b462452",
   "metadata": {},
   "source": [
    "## 1. DeepSHAP - SHAP Values for Deep Neural Networks\n",
    "\n",
    "DeepSHAP combines SHAP with DeepLIFT to efficiently compute SHAP values for deep learning models. It's faster than KernelSHAP for neural networks while maintaining theoretical guarantees.\n",
    "\n",
    "### How it works:\n",
    "- Uses backpropagation-based attribution\n",
    "- Computes contributions relative to a reference (background) distribution\n",
    "- Satisfies SHAP's consistency and local accuracy properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a50920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a neural network for fraud detection\n",
    "def build_fraud_detector(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Train model\n",
    "model = build_fraud_detector(X_train_scaled.shape[1])\n",
    "\n",
    "# Use class weights for imbalanced data\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b184896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DeepSHAP\n",
    "# Use a subset of training data as background\n",
    "background = X_train_scaled[np.random.choice(len(X_train_scaled), 100, replace=False)]\n",
    "\n",
    "# Create DeepSHAP explainer\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "\n",
    "# Calculate SHAP values for test set\n",
    "shap_values = explainer.shap_values(X_test_scaled[:500])\n",
    "\n",
    "# For binary classification, shap_values might be a list\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "print(f\"Feature importance calculated for {shap_values.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Beeswarm plot\n",
    "plt.sca(axes[0])\n",
    "shap.summary_plot(shap_values, X_test_scaled[:500],\n",
    "                  feature_names=feature_names, show=False)\n",
    "axes[0].set_title('DeepSHAP: Feature Impact on Fraud Prediction')\n",
    "\n",
    "# Bar plot for mean absolute SHAP values\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "sorted_idx = np.argsort(mean_abs_shap)\n",
    "\n",
    "axes[1].barh([feature_names[i] for i in sorted_idx], mean_abs_shap[sorted_idx])\n",
    "axes[1].set_xlabel('Mean |SHAP value|')\n",
    "axes[1].set_title('DeepSHAP: Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain individual fraud predictions\n",
    "fraud_indices = np.where(y_test[:500] == 1)[0]\n",
    "\n",
    "if len(fraud_indices) > 0:\n",
    "    # Take first fraud case\n",
    "    idx = fraud_indices[0]\n",
    "\n",
    "    print(f\"Explaining prediction for sample {idx} (True fraud)\")\n",
    "    print(f\"Predicted probability: {y_pred_proba[idx]:.3f}\")\n",
    "    print(f\"\\nFeature contributions:\")\n",
    "\n",
    "    # Show feature values and their SHAP contributions\n",
    "    contributions = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Value': X_test[idx],\n",
    "        'SHAP': shap_values[idx]\n",
    "    }).sort_values('SHAP', key=abs, ascending=False)\n",
    "\n",
    "    print(contributions.to_string(index=False))\n",
    "\n",
    "    # Waterfall plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    shap.waterfall_plot(shap.Explanation(\n",
    "        values=shap_values[idx],\n",
    "        base_values=explainer.expected_value[0] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "        data=X_test_scaled[idx],\n",
    "        feature_names=feature_names\n",
    "    ), show=False)\n",
    "    plt.title(f'DeepSHAP Waterfall: Fraud Case {idx}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895eb279",
   "metadata": {},
   "source": [
    "## 2. Attention Visualization\n",
    "\n",
    "Attention mechanisms provide built-in interpretability by showing which parts of the input the model focuses on. We'll build a simple attention-based model and visualize the attention weights.\n",
    "\n",
    "### Architecture:\n",
    "- Multi-head self-attention over features\n",
    "- Attention weights show feature interactions\n",
    "- More interpretable than standard feed-forward networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionFraudDetector(Model):\n",
    "    \"\"\"\n",
    "    Fraud detector with attention mechanism for interpretability.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_heads=2, d_model=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Project features to d_model dimensions\n",
    "        self.feature_embedding = Dense(d_model)\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=n_heads,\n",
    "            key_dim=d_model // n_heads,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        self.norm = LayerNormalization()\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = Sequential([\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def call(self, inputs, training=False, return_attention=False):\n",
    "        # Reshape to (batch, n_features, 1)\n",
    "        x = tf.expand_dims(inputs, -1)\n",
    "\n",
    "        # Embed features\n",
    "        x = self.feature_embedding(x)  # (batch, n_features, d_model)\n",
    "\n",
    "        # Self-attention with attention weights\n",
    "        attn_output, attn_weights = self.attention(\n",
    "            x, x, return_attention_scores=True, training=training\n",
    "        )\n",
    "\n",
    "        # Residual + Norm\n",
    "        x = self.norm(x + attn_output)\n",
    "\n",
    "        # Flatten and classify\n",
    "        x = self.flatten(x)\n",
    "        output = self.classifier(x, training=training)\n",
    "\n",
    "        if return_attention:\n",
    "            return output, attn_weights\n",
    "        return output\n",
    "\n",
    "# Build and train attention model\n",
    "attn_model = AttentionFraudDetector(n_features=len(feature_names))\n",
    "\n",
    "attn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "attn_history = attn_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_attn = attn_model.predict(X_test_scaled).flatten()\n",
    "y_pred_attn_class = (y_pred_attn > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nAttention Model Performance:\")\n",
    "print(classification_report(y_test, y_pred_attn_class))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_attn):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attention weights\n",
    "_, attention_weights = attn_model(X_test_scaled[:100], return_attention=True)\n",
    "\n",
    "# Average attention across heads and samples\n",
    "# attention_weights shape: (batch, n_heads, n_features, n_features)\n",
    "avg_attention = attention_weights.numpy().mean(axis=(0, 1))  # (n_features, n_features)\n",
    "\n",
    "# Visualize attention heatmap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Full attention matrix\n",
    "im = axes[0].imshow(avg_attention, cmap='Blues')\n",
    "axes[0].set_xticks(range(len(feature_names)))\n",
    "axes[0].set_yticks(range(len(feature_names)))\n",
    "axes[0].set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "axes[0].set_yticklabels(feature_names)\n",
    "axes[0].set_title('Average Attention Weights (Feature Interactions)')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "# Feature importance from attention (sum of attention received)\n",
    "feature_importance = avg_attention.sum(axis=0)\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "axes[1].barh([feature_names[i] for i in sorted_idx], feature_importance[sorted_idx])\n",
    "axes[1].set_xlabel('Total Attention Received')\n",
    "axes[1].set_title('Feature Importance from Attention')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop feature interactions (high attention):\")\n",
    "for i in range(len(feature_names)):\n",
    "    for j in range(i+1, len(feature_names)):\n",
    "        if avg_attention[i, j] > 0.1:\n",
    "            print(f\"  {feature_names[i]} <-> {feature_names[j]}: {avg_attention[i,j]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2420c72",
   "metadata": {},
   "source": [
    "## 3. Counterfactual Explanations\n",
    "\n",
    "Counterfactuals answer: \"What minimal changes would flip the prediction?\"\n",
    "\n",
    "For fraud detection: \"What would need to change for this transaction to be classified as legitimate?\"\n",
    "\n",
    "### Algorithm:\n",
    "1. Start with original instance\n",
    "2. Optimize to find nearest instance with different prediction\n",
    "3. Constraints ensure realistic changes (e.g., can't change past transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counterfactual(model, instance, target_class, feature_names,\n",
    "                                feature_ranges, immutable_features=None,\n",
    "                                learning_rate=0.1, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Generate counterfactual explanation using gradient descent.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : Keras model\n",
    "    instance : array, original instance\n",
    "    target_class : int, desired prediction (0 or 1)\n",
    "    feature_names : list of feature names\n",
    "    feature_ranges : dict of (min, max) for each feature\n",
    "    immutable_features : list of features that cannot change\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    counterfactual : array, modified instance\n",
    "    changes : dict of feature changes\n",
    "    \"\"\"\n",
    "    if immutable_features is None:\n",
    "        immutable_features = []\n",
    "\n",
    "    # Create trainable variable\n",
    "    cf = tf.Variable(instance.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = model(cf)\n",
    "\n",
    "            # Loss: prediction loss + distance loss\n",
    "            if target_class == 1:\n",
    "                pred_loss = -tf.math.log(pred + 1e-10)\n",
    "            else:\n",
    "                pred_loss = -tf.math.log(1 - pred + 1e-10)\n",
    "\n",
    "            # L1 distance for sparsity\n",
    "            distance_loss = 0.1 * tf.reduce_sum(tf.abs(cf - instance))\n",
    "\n",
    "            total_loss = pred_loss + distance_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, cf)\n",
    "        optimizer.apply_gradients([(gradients, cf)])\n",
    "\n",
    "        # Project to feasible region\n",
    "        cf_numpy = cf.numpy().flatten()\n",
    "        for i, fname in enumerate(feature_names):\n",
    "            # Immutable features\n",
    "            if fname in immutable_features:\n",
    "                cf_numpy[i] = instance[i]\n",
    "            # Clip to range\n",
    "            elif fname in feature_ranges:\n",
    "                cf_numpy[i] = np.clip(cf_numpy[i],\n",
    "                                      feature_ranges[fname][0],\n",
    "                                      feature_ranges[fname][1])\n",
    "\n",
    "        cf.assign(cf_numpy.reshape(1, -1))\n",
    "\n",
    "        # Check if target reached\n",
    "        current_pred = model(cf).numpy().flatten()[0]\n",
    "        if (target_class == 1 and current_pred > 0.5) or \\\n",
    "           (target_class == 0 and current_pred < 0.5):\n",
    "            break\n",
    "\n",
    "    # Calculate changes\n",
    "    cf_final = cf.numpy().flatten()\n",
    "    changes = {}\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        if abs(cf_final[i] - instance[i]) > 0.01:\n",
    "            changes[fname] = {\n",
    "                'original': instance[i],\n",
    "                'counterfactual': cf_final[i],\n",
    "                'change': cf_final[i] - instance[i]\n",
    "            }\n",
    "\n",
    "    return cf_final, changes\n",
    "\n",
    "# Define feature constraints\n",
    "feature_ranges = {\n",
    "    'amount': (-3, 3),  # Scaled values\n",
    "    'hour': (-3, 3),\n",
    "    'day_of_week': (-3, 3),\n",
    "    'merchant_category': (-3, 3),\n",
    "    'distance_from_home': (-3, 3),\n",
    "    'time_since_last_txn': (-3, 3),\n",
    "    'avg_txn_amount': (-3, 3),\n",
    "    'txn_frequency': (-3, 3),\n",
    "    'is_online': (-3, 3),\n",
    "    'is_international': (-3, 3)\n",
    "}\n",
    "\n",
    "# Immutable features (can't change historical data)\n",
    "immutable = ['avg_txn_amount', 'txn_frequency']\n",
    "\n",
    "print(\"Counterfactual generator defined\")\n",
    "print(f\"Immutable features: {immutable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a fraud prediction to explain\n",
    "fraud_preds = np.where((y_pred > 0.5) & (y_test == 1))[0]\n",
    "\n",
    "if len(fraud_preds) > 0:\n",
    "    idx = fraud_preds[0]\n",
    "    original = X_test_scaled[idx]\n",
    "    original_pred = y_pred_proba[idx]\n",
    "\n",
    "    print(f\"Original transaction (predicted fraud with p={original_pred:.3f})\")\n",
    "    print(\"\\nGenerating counterfactual (what would make it legitimate?)...\")\n",
    "\n",
    "    # Generate counterfactual\n",
    "    cf, changes = generate_counterfactual(\n",
    "        model, original, target_class=0,\n",
    "        feature_names=feature_names,\n",
    "        feature_ranges=feature_ranges,\n",
    "        immutable_features=immutable\n",
    "    )\n",
    "\n",
    "    cf_pred = model.predict(cf.reshape(1, -1), verbose=0).flatten()[0]\n",
    "\n",
    "    print(f\"\\nCounterfactual prediction: {cf_pred:.3f}\")\n",
    "    print(f\"\\nRequired changes to flip prediction:\")\n",
    "\n",
    "    if changes:\n",
    "        for fname, vals in changes.items():\n",
    "            # Convert back from scaled values for interpretability\n",
    "            orig_unscaled = scaler.inverse_transform(original.reshape(1, -1))[0]\n",
    "            cf_unscaled = scaler.inverse_transform(cf.reshape(1, -1))[0]\n",
    "\n",
    "            fidx = feature_names.index(fname)\n",
    "            print(f\"  {fname}:\")\n",
    "            print(f\"    Original: {orig_unscaled[fidx]:.2f}\")\n",
    "            print(f\"    Counterfactual: {cf_unscaled[fidx]:.2f}\")\n",
    "    else:\n",
    "        print(\"  No significant changes needed\")\n",
    "\n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    x = np.arange(len(feature_names))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(x - width/2, original, width, label='Original (Fraud)')\n",
    "    ax.bar(x + width/2, cf, width, label='Counterfactual (Legitimate)')\n",
    "\n",
    "    ax.set_ylabel('Scaled Feature Value')\n",
    "    ax.set_title('Original vs Counterfactual Feature Values')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74c7a8",
   "metadata": {},
   "source": [
    "## 4. Model Distillation\n",
    "\n",
    "Model distillation transfers knowledge from a complex \"teacher\" model to a simpler, more interpretable \"student\" model.\n",
    "\n",
    "### Benefits:\n",
    "- Interpretable approximation of black-box model\n",
    "- Preserves most of the teacher's accuracy\n",
    "- Can extract decision rules\n",
    "\n",
    "### Our approach:\n",
    "Train a decision tree to mimic the neural network's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get soft labels from neural network\n",
    "soft_labels = model.predict(X_train_scaled, verbose=0).flatten()\n",
    "\n",
    "# Train decision tree on soft labels\n",
    "# Use probability as regression target for soft distillation\n",
    "dt_student = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to hard labels for decision tree\n",
    "hard_labels = (soft_labels > 0.5).astype(int)\n",
    "dt_student.fit(X_train_scaled, hard_labels)\n",
    "\n",
    "# Evaluate student\n",
    "y_pred_student = dt_student.predict(X_test_scaled)\n",
    "y_pred_student_proba = dt_student.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Model Distillation Results:\")\n",
    "print(\"\\nTeacher (Neural Network):\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "print(f\"  Accuracy: {(y_pred == y_test).mean():.3f}\")\n",
    "\n",
    "print(\"\\nStudent (Decision Tree):\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, y_pred_student_proba):.3f}\")\n",
    "print(f\"  Accuracy: {(y_pred_student == y_test).mean():.3f}\")\n",
    "\n",
    "# Agreement between teacher and student\n",
    "agreement = (y_pred == y_pred_student).mean()\n",
    "print(f\"\\nTeacher-Student Agreement: {agreement*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distilled decision tree\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "plot_tree(\n",
    "    dt_student,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['Legitimate', 'Fraud'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    ax=ax,\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "ax.set_title('Distilled Decision Tree (Approximating Neural Network)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract and print rules\n",
    "def get_rules(tree, feature_names, class_names):\n",
    "    \"\"\"Extract rules from decision tree.\"\"\"\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != -2 else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    rules = []\n",
    "\n",
    "    def recurse(node, depth, rule):\n",
    "        if tree_.feature[node] != -2:  # Not a leaf\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "\n",
    "            # Left branch\n",
    "            recurse(tree_.children_left[node], depth + 1,\n",
    "                   rule + [f\"{name} <= {threshold:.2f}\"])\n",
    "            # Right branch\n",
    "            recurse(tree_.children_right[node], depth + 1,\n",
    "                   rule + [f\"{name} > {threshold:.2f}\"])\n",
    "        else:  # Leaf\n",
    "            class_idx = np.argmax(tree_.value[node])\n",
    "            class_name = class_names[class_idx]\n",
    "            samples = tree_.n_node_samples[node]\n",
    "            if class_name == 'Fraud' and samples > 10:\n",
    "                rules.append((rule, class_name, samples))\n",
    "\n",
    "    recurse(0, 0, [])\n",
    "    return rules\n",
    "\n",
    "rules = get_rules(dt_student, feature_names, ['Legitimate', 'Fraud'])\n",
    "\n",
    "print(\"\\nExtracted Fraud Detection Rules:\")\n",
    "print(\"=\" * 60)\n",
    "for i, (conditions, cls, samples) in enumerate(rules[:5], 1):\n",
    "    print(f\"\\nRule {i} ({samples} samples):\")\n",
    "    for cond in conditions:\n",
    "        print(f\"  - {cond}\")\n",
    "    print(f\"  => {cls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all XAI methods\n",
    "print(\"=\" * 70)\n",
    "print(\"ADVANCED XAI METHODS - COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. DeepSHAP\")\n",
    "print(\"   - Provides feature attributions for neural networks\")\n",
    "print(\"   - Fast computation using backpropagation\")\n",
    "print(\"   - Best for: Understanding individual predictions\")\n",
    "\n",
    "print(\"\\n2. Attention Visualization\")\n",
    "print(\"   - Built-in interpretability from attention weights\")\n",
    "print(\"   - Shows feature interactions\")\n",
    "print(\"   - Best for: Understanding which features interact\")\n",
    "\n",
    "print(\"\\n3. Counterfactual Explanations\")\n",
    "print(\"   - Actionable 'what-if' scenarios\")\n",
    "print(\"   - Minimal changes to flip prediction\")\n",
    "print(\"   - Best for: User-facing explanations, recourse\")\n",
    "\n",
    "print(\"\\n4. Model Distillation\")\n",
    "print(\"   - Interpretable approximation of complex model\")\n",
    "print(\"   - Extracts decision rules\")\n",
    "print(\"   - Best for: Global model understanding, compliance\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDATIONS FOR FRAUD DETECTION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"- Use DeepSHAP for individual transaction review\")\n",
    "print(\"- Use attention to identify important feature interactions\")\n",
    "print(\"- Use counterfactuals for customer explanations\")\n",
    "print(\"- Use distillation for regulatory compliance and audits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210c414",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **DeepSHAP** efficiently computes SHAP values for neural networks, revealing which features drive individual predictions.\n",
    "\n",
    "2. **Attention mechanisms** provide built-in interpretability by showing feature interactions and importance directly from model architecture.\n",
    "\n",
    "3. **Counterfactual explanations** offer actionable insights by showing minimal changes needed to flip a prediction - crucial for customer communication.\n",
    "\n",
    "4. **Model distillation** creates interpretable approximations of complex models, enabling rule extraction for compliance and auditing.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- Combine multiple XAI methods for comprehensive understanding\n",
    "- Consider the audience: technical (SHAP) vs. non-technical (counterfactuals)\n",
    "- Validate explanations against domain knowledge\n",
    "- Document and version explanations for regulatory purposes\n",
    "\n",
    "### Next Steps\n",
    "- Integrate XAI into production pipelines\n",
    "- Build interactive dashboards for model monitoring\n",
    "- Establish explanation baselines for drift detection"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
