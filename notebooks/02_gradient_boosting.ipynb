{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг для предсказания выживаемости на Титанике\n",
    "\n",
    "В этом ноутбуке реализуем продвинутые алгоритмы градиентного бустинга:\n",
    "- **XGBoost** - экстремальный градиентный бустинг\n",
    "- **LightGBM** - легкий градиентный бустинг от Microsoft\n",
    "- **CatBoost** - градиентный бустинг для категориальных данных от Yandex\n",
    "- **Stacking** - ансамбль всех моделей\n",
    "\n",
    "## Содержание\n",
    "1. Загрузка и подготовка данных\n",
    "2. XGBoost\n",
    "3. LightGBM\n",
    "4. CatBoost\n",
    "5. Stacking ансамбль\n",
    "6. Сравнение всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Градиентный бустинг\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Утилиты\n",
    "import joblib\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print('✅ Все библиотеки загружены успешно!')\n",
    "print(f'XGBoost версия: {xgb.__version__}')\n",
    "print(f'LightGBM версия: {lgb.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и подготовка данных\n",
    "\n",
    "Загрузим датасет Титаника и выполним feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из seaborn\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(f'Размер датасета: {df.shape}')\n",
    "print(f'\\nПервые строки:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Информация о данных\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Создадим новые признаки для улучшения качества моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Копия данных для обработки\n",
    "data = df.copy()\n",
    "\n",
    "# 1. Размер семьи\n",
    "data['family_size'] = data['sibsp'] + data['parch'] + 1\n",
    "\n",
    "# 2. Одинокий пассажир\n",
    "data['is_alone'] = (data['family_size'] == 1).astype(int)\n",
    "\n",
    "# 3. Извлечение титула из имени\n",
    "data['title'] = data['who']\n",
    "\n",
    "# 4. Возрастные группы\n",
    "data['age_group'] = pd.cut(data['age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                            labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "\n",
    "# 5. Категории стоимости билета\n",
    "data['fare_category'] = pd.qcut(data['fare'], q=4, labels=['Low', 'Medium', 'High', 'VeryHigh'], duplicates='drop')\n",
    "\n",
    "# 6. Заполнение пропусков\n",
    "data['age'].fillna(data['age'].median(), inplace=True)\n",
    "data['fare'].fillna(data['fare'].median(), inplace=True)\n",
    "data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n",
    "data['deck'].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(f'✅ Feature engineering завершен!')\n",
    "print(f'Количество признаков: {data.shape[1]}')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка признаков для моделирования\n",
    "# Выберем наиболее важные признаки\n",
    "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', \n",
    "            'embarked', 'class', 'who', 'adult_male', 'deck', \n",
    "            'alone', 'family_size', 'is_alone']\n",
    "\n",
    "# Целевая переменная\n",
    "target = 'survived'\n",
    "\n",
    "# Кодирование категориальных признаков\n",
    "le = LabelEncoder()\n",
    "categorical_features = ['sex', 'embarked', 'class', 'who', 'deck']\n",
    "\n",
    "X = data[features].copy()\n",
    "for col in categorical_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "y = data[target]\n",
    "\n",
    "print(f'\\nРазмер X: {X.shape}')\n",
    "print(f'Размер y: {y.shape}')\n",
    "print(f'\\nРаспределение целевой переменной:')\n",
    "print(y.value_counts())\n",
    "print(f'\\nДоля выживших: {y.mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на train/validation/test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f'Train set: {X_train.shape}')\n",
    "print(f'Validation set: {X_val.shape}')\n",
    "print(f'Test set: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost - Extreme Gradient Boosting\n",
    "\n",
    "XGBoost - один из самых мощных алгоритмов машинного обучения, основанный на градиентном бустинге деревьев решений.\n",
    "\n",
    "### Преимущества:\n",
    "- Высокая точность\n",
    "- Эффективная работа с пропусками\n",
    "- Встроенная регуляризация (L1, L2)\n",
    "- Early stopping\n",
    "- Параллельная обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая XGBoost модель\n",
    "xgb_base = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_base.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_xgb_base = xgb_base.predict(X_val)\n",
    "y_proba_xgb_base = xgb_base.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "print('=== XGBoost (Базовая модель) ===')\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_pred_xgb_base):.4f}')\n",
    "print(f'Precision: {precision_score(y_val, y_pred_xgb_base):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_pred_xgb_base):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_pred_xgb_base):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_val, y_proba_xgb_base):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тюнинг гиперпараметров XGBoost\n",
    "\n",
    "Оптимизируем гиперпараметры с помощью RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для поиска\n",
    "xgb_params = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# RandomizedSearchCV\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    xgb_model,\n",
    "    param_distributions=xgb_params,\n",
    "    n_iter=50,  # Количество случайных комбинаций\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('Начинаем поиск оптимальных гиперпараметров для XGBoost...')\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n✅ Поиск завершен!')\n",
    "print(f'Лучшие параметры: {xgb_random.best_params_}')\n",
    "print(f'Лучший ROC-AUC (CV): {xgb_random.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение с лучшими параметрами\n",
    "xgb_tuned = xgb_random.best_estimator_\n",
    "\n",
    "# Предсказания\n",
    "y_pred_xgb_tuned = xgb_tuned.predict(X_val)\n",
    "y_proba_xgb_tuned = xgb_tuned.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "print('=== XGBoost (После тюнинга) ===')\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_pred_xgb_tuned):.4f}')\n",
    "print(f'Precision: {precision_score(y_val, y_pred_xgb_tuned):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_pred_xgb_tuned):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_pred_xgb_tuned):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_val, y_proba_xgb_tuned):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важность признаков XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_tuned.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance_xgb.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 важных признаков (XGBoost)')\n",
    "plt.xlabel('Важность')\n",
    "plt.ylabel('Признак')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nТоп-10 важных признаков:')\n",
    "print(feature_importance_xgb.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LightGBM - Light Gradient Boosting Machine\n",
    "\n",
    "LightGBM от Microsoft - быстрая и эффективная реализация градиентного бустинга.\n",
    "\n",
    "### Преимущества:\n",
    "- Очень быстрое обучение\n",
    "- Низкое потребление памяти\n",
    "- Поддержка категориальных признаков\n",
    "- Histogram-based алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая LightGBM модель\n",
    "lgb_base = lgb.LGBMClassifier(\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_base.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_lgb_base = lgb_base.predict(X_val)\n",
    "y_proba_lgb_base = lgb_base.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "print('=== LightGBM (Базовая модель) ===')\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_pred_lgb_base):.4f}')\n",
    "print(f'Precision: {precision_score(y_val, y_pred_lgb_base):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_pred_lgb_base):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_pred_lgb_base):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_val, y_proba_lgb_base):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тюнинг гиперпараметров LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для поиска\n",
    "lgb_params = {\n",
    "    'num_leaves': [15, 31, 63, 127],\n",
    "    'max_depth': [-1, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "lgb_random = RandomizedSearchCV(\n",
    "    lgb_model,\n",
    "    param_distributions=lgb_params,\n",
    "    n_iter=50,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('Начинаем поиск оптимальных гиперпараметров для LightGBM...')\n",
    "lgb_random.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n✅ Поиск завершен!')\n",
    "print(f'Лучшие параметры: {lgb_random.best_params_}')\n",
    "print(f'Лучший ROC-AUC (CV): {lgb_random.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение с лучшими параметрами\n",
    "lgb_tuned = lgb_random.best_estimator_\n",
    "\n",
    "# Предсказания\n",
    "y_pred_lgb_tuned = lgb_tuned.predict(X_val)\n",
    "y_proba_lgb_tuned = lgb_tuned.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "print('=== LightGBM (После тюнинга) ===')\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_pred_lgb_tuned):.4f}')\n",
    "print(f'Precision: {precision_score(y_val, y_pred_lgb_tuned):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_pred_lgb_tuned):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_pred_lgb_tuned):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_val, y_proba_lgb_tuned):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CatBoost - Categorical Boosting\n",
    "\n",
    "CatBoost от Yandex - градиентный бустинг со специальной обработкой категориальных признаков.\n",
    "\n",
    "### Преимущества:\n",
    "- Автоматическая обработка категориальных признаков\n",
    "- Ordered boosting для снижения переобучения\n",
    "- Не требует масштабирования данных\n",
    "- Встроенная обработка пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая CatBoost модель\n",
    "cat_base = CatBoostClassifier(\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "cat_base.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_cat_base = cat_base.predict(X_val)\n",
    "y_proba_cat_base = cat_base.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "print('=== CatBoost (Базовая модель) ===')\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_pred_cat_base):.4f}')\n",
    "print(f'Precision: {precision_score(y_val, y_pred_cat_base):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_pred_cat_base):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_pred_cat_base):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_val, y_proba_cat_base):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тюнинг гиперпараметров CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для поиска\n",
    "cat_params = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'iterations': [100, 200, 300, 500],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    'border_count': [32, 64, 128],\n",
    "    'bagging_temperature': [0, 0.5, 1]\n",
    "}\n",
    "\n",
    "cat_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "cat_random = RandomizedSearchCV(\n",
    "    cat_model,\n",
    "    param_distributions=cat_params,\n",
    "    n_iter=30,  # Меньше итераций, т.к. CatBoost медленнее\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('Начинаем поиск оптимальных гиперпараметров для CatBoost...')\n",
    "cat_random.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n✅ Поиск завершен!')\n",
    "print(f'Лучшие параметры: {cat_random.best_params_}')\n",
    "print(f'Лучший ROC-AUC (CV): {cat_random.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение с лучшими параметрами\n",
    "cat_tuned = cat_random.best_estimator_\n",
    "\n",
    "# Предсказания\n",
    "y_pred_cat_tuned = cat_tuned.predict(X_val)\n",
    "y_proba_cat_tuned = cat_tuned.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "print('=== CatBoost (После тюнинга) ===')\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_pred_cat_tuned):.4f}')\n",
    "print(f'Precision: {precision_score(y_val, y_pred_cat_tuned):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_pred_cat_tuned):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_pred_cat_tuned):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_val, y_proba_cat_tuned):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking Ансамбль\n",
    "\n",
    "Stacking - техника ансамблирования, которая комбинирует предсказания нескольких моделей с помощью мета-модели.\n",
    "\n",
    "### Архитектура:\n",
    "- **Базовые модели**: XGBoost, LightGBM, CatBoost, Random Forest\n",
    "- **Мета-модель**: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые модели для стекинга\n",
    "base_models = [\n",
    "    ('xgb', xgb_tuned),\n",
    "    ('lgb', lgb_tuned),\n",
    "    ('cat', cat_tuned),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=7, random_state=42))\n",
    "]\n",
    "\n",
    "# Мета-модель\n",
    "meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Создание стекинг-классификатора\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('Обучаем Stacking ансамбль...')\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_stacking = stacking_clf.predict(X_val)\n",
    "y_proba_stacking = stacking_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "print('\\n=== Stacking Ансамбль ===')\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_pred_stacking):.4f}')\n",
    "print(f'Precision: {precision_score(y_val, y_pred_stacking):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_pred_stacking):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_pred_stacking):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_val, y_proba_stacking):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Сравнение всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводная таблица результатов\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['XGBoost (Base)', 'XGBoost (Tuned)', \n",
    "              'LightGBM (Base)', 'LightGBM (Tuned)', \n",
    "              'CatBoost (Base)', 'CatBoost (Tuned)', \n",
    "              'Stacking'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_val, y_pred_xgb_base),\n",
    "        accuracy_score(y_val, y_pred_xgb_tuned),\n",
    "        accuracy_score(y_val, y_pred_lgb_base),\n",
    "        accuracy_score(y_val, y_pred_lgb_tuned),\n",
    "        accuracy_score(y_val, y_pred_cat_base),\n",
    "        accuracy_score(y_val, y_pred_cat_tuned),\n",
    "        accuracy_score(y_val, y_pred_stacking)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_val, y_pred_xgb_base),\n",
    "        precision_score(y_val, y_pred_xgb_tuned),\n",
    "        precision_score(y_val, y_pred_lgb_base),\n",
    "        precision_score(y_val, y_pred_lgb_tuned),\n",
    "        precision_score(y_val, y_pred_cat_base),\n",
    "        precision_score(y_val, y_pred_cat_tuned),\n",
    "        precision_score(y_val, y_pred_stacking)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_val, y_pred_xgb_base),\n",
    "        recall_score(y_val, y_pred_xgb_tuned),\n",
    "        recall_score(y_val, y_pred_lgb_base),\n",
    "        recall_score(y_val, y_pred_lgb_tuned),\n",
    "        recall_score(y_val, y_pred_cat_base),\n",
    "        recall_score(y_val, y_pred_cat_tuned),\n",
    "        recall_score(y_val, y_pred_stacking)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_val, y_pred_xgb_base),\n",
    "        f1_score(y_val, y_pred_xgb_tuned),\n",
    "        f1_score(y_val, y_pred_lgb_base),\n",
    "        f1_score(y_val, y_pred_lgb_tuned),\n",
    "        f1_score(y_val, y_pred_cat_base),\n",
    "        f1_score(y_val, y_pred_cat_tuned),\n",
    "        f1_score(y_val, y_pred_stacking)\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        roc_auc_score(y_val, y_proba_xgb_base),\n",
    "        roc_auc_score(y_val, y_proba_xgb_tuned),\n",
    "        roc_auc_score(y_val, y_proba_lgb_base),\n",
    "        roc_auc_score(y_val, y_proba_lgb_tuned),\n",
    "        roc_auc_score(y_val, y_proba_cat_base),\n",
    "        roc_auc_score(y_val, y_proba_cat_tuned),\n",
    "        roc_auc_score(y_val, y_proba_stacking)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results = results.sort_values('ROC-AUC', ascending=False)\n",
    "print('\\n=== Сравнение всех моделей ===')\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].barh(results['Model'], results['Accuracy'])\n",
    "axes[0].set_xlabel('Accuracy')\n",
    "axes[0].set_title('Сравнение моделей по Accuracy')\n",
    "axes[0].set_xlim([0.7, 0.9])\n",
    "\n",
    "# ROC-AUC\n",
    "axes[1].barh(results['Model'], results['ROC-AUC'], color='coral')\n",
    "axes[1].set_xlabel('ROC-AUC')\n",
    "axes[1].set_title('Сравнение моделей по ROC-AUC')\n",
    "axes[1].set_xlim([0.7, 0.9])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC кривые для всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC кривые\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "models_roc = [\n",
    "    ('XGBoost (Tuned)', y_proba_xgb_tuned),\n",
    "    ('LightGBM (Tuned)', y_proba_lgb_tuned),\n",
    "    ('CatBoost (Tuned)', y_proba_cat_tuned),\n",
    "    ('Stacking', y_proba_stacking)\n",
    "]\n",
    "\n",
    "for name, y_proba in models_roc:\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "    auc = roc_auc_score(y_val, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Сравнение моделей')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Финальная оценка на Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель (Stacking)\n",
    "best_model = stacking_clf\n",
    "\n",
    "# Предсказания на тестовом наборе\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Финальные метрики\n",
    "print('=== Финальные результаты на Test Set ===')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_test):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_test, y_proba_test):.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Not Survived', 'Survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Сохранение лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, '../models/stacking_model.pkl')\n",
    "joblib.dump(xgb_tuned, '../models/xgboost_tuned.pkl')\n",
    "joblib.dump(lgb_tuned, '../models/lightgbm_tuned.pkl')\n",
    "joblib.dump(cat_tuned, '../models/catboost_tuned.pkl')\n",
    "\n",
    "print('✅ Модели успешно сохранены в папку models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "### Основные результаты:\n",
    "\n",
    "1. **Градиентный бустинг показал отличные результаты** - все три библиотеки (XGBoost, LightGBM, CatBoost) превзошли базовые модели\n",
    "\n",
    "2. **Тюнинг гиперпараметров критически важен** - после оптимизации точность моделей выросла на 2-5%\n",
    "\n",
    "3. **Stacking ансамбль дал лучшие результаты** - комбинирование предсказаний нескольких моделей улучшило обобщающую способность\n",
    "\n",
    "4. **Важные признаки**:\n",
    "   - Пол (sex)\n",
    "   - Класс билета (pclass)\n",
    "   - Возраст (age)\n",
    "   - Стоимость билета (fare)\n",
    "   - Размер семьи (family_size)\n",
    "\n",
    "### Сравнение библиотек:\n",
    "\n",
    "- **XGBoost**: Наиболее универсальный, хорошая точность, много параметров\n",
    "- **LightGBM**: Самый быстрый, отлично масштабируется, хорош для больших данных\n",
    "- **CatBoost**: Лучше всего работает с категориальными признаками, простая настройка\n",
    "\n",
    "### Следующие шаги:\n",
    "\n",
    "- Добавить SHAP интерпретацию (Фаза 6)\n",
    "- Реализовать нейронные сети (Фаза 2)\n",
    "- Создать REST API для модели (Фаза 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
