"""
Titanic Analysis - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º –¢–∏—Ç–∞–Ω–∏–∫.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
import joblib
import os

# ============================================================================
# 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• (Kaggle –¥–∞—Ç–∞—Å–µ—Ç —Å fallback –Ω–∞ seaborn)
# ============================================================================

def load_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ Kaggle –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å fallback –Ω–∞ seaborn"""

    train_path = '../../datasets/titanic/train.csv'
    test_path = '../../datasets/titanic/test.csv'

    try:
        if os.path.exists(train_path):
            # Kaggle –¥–∞—Ç–∞—Å–µ—Ç
            df_train = pd.read_csv(train_path)
            df_test = pd.read_csv(test_path) if os.path.exists(test_path) else None

            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω Kaggle –¥–∞—Ç–∞—Å–µ—Ç")
            print(f"  Train: {df_train.shape}")
            if df_test is not None:
                print(f"  Test: {df_test.shape}")

            return df_train, df_test
        else:
            raise FileNotFoundError

    except FileNotFoundError:
        # Fallback –Ω–∞ seaborn
        import seaborn as sns
        print("‚ö† Kaggle –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º seaborn")
        print("  –î–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å Kaggle:")
        print("  https://www.kaggle.com/c/titanic/data")

        df = sns.load_dataset('titanic')

        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
        df.rename(columns={
            'survived': 'Survived',
            'pclass': 'Pclass',
            'sex': 'Sex',
            'age': 'Age',
            'sibsp': 'SibSp',
            'parch': 'Parch',
            'fare': 'Fare',
            'embarked': 'Embarked'
        }, inplace=True)

        return df, None


# ============================================================================
# 2. –ü–†–ê–í–ò–õ–¨–ù–û–ï –†–ê–ó–î–ï–õ–ï–ù–ò–ï: Train / Validation / Test
# ============================================================================

def split_data(X, y, test_size=0.15, val_size=0.15, random_state=42):
    """
    –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ Train/Validation/Test

    Train: –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏
    Validation: –ø–æ–¥–±–∏—Ä–∞–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –≤—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
    Test: —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –†–ê–ó!)
    """

    # –®–∞–≥ 1: –û—Ç–¥–µ–ª—è–µ–º test set (15%)
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )

    # –®–∞–≥ 2: –î–µ–ª–∏–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –Ω–∞ Train –∏ Validation
    val_size_adjusted = val_size / (1 - test_size)
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=val_size_adjusted,
        random_state=random_state, stratify=y_temp
    )

    print("=" * 60)
    print("–†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•")
    print("=" * 60)
    print(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {len(X)} —Å—Ç—Ä–æ–∫")
    print(f"\nüìö Train:      {len(X_train):4d} ({len(X_train)/len(X)*100:.1f}%)")
    print(f"üéØ Validation: {len(X_val):4d} ({len(X_val)/len(X)*100:.1f}%)")
    print(f"üîí Test:       {len(X_test):4d} ({len(X_test)/len(X)*100:.1f}%)")
    print("=" * 60)

    return X_train, X_val, X_test, y_train, y_val, y_test


# ============================================================================
# 3. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° JOBLIB (–Ω–µ pickle!)
# ============================================================================

def save_model(model, scaler, model_dir='../../models'):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å joblib"""

    os.makedirs(model_dir, exist_ok=True)

    model_path = os.path.join(model_dir, 'titanic_model.joblib')
    scaler_path = os.path.join(model_dir, 'titanic_scaler.joblib')

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —Å–∂–∞—Ç–∏–µ–º
    joblib.dump(model, model_path, compress=3)
    joblib.dump(scaler, scaler_path, compress=3)

    print(f"\n‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    print(f"‚úì Scaler —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {scaler_path}")

    return model_path, scaler_path


def load_model(model_dir='../../models'):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""

    model_path = os.path.join(model_dir, 'titanic_model.joblib')
    scaler_path = os.path.join(model_dir, 'titanic_scaler.joblib')

    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)

    print(f"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
    print(f"‚úì Scaler –∑–∞–≥—Ä—É–∂–µ–Ω: {scaler_path}")

    return model, scaler


# ============================================================================
# –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
# ============================================================================

if __name__ == "__main__":

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_train, df_test = load_data()

    # 2. –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (–¥–ª—è –ø—Ä–∏–º–µ—Ä–∞)
    X = df_train[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].fillna(0)
    y = df_train['Survived']

    # 3. –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)

    # 4. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)

    # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_scaled, y_train)

    # 6. –û—Ü–µ–Ω–∫–∞ –Ω–∞ validation (–ø–æ–¥–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
    val_score = model.score(X_val_scaled, y_val)
    print(f"\nüìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ Validation: {val_score:.4f}")

    # 7. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ test (–¢–û–õ–¨–ö–û –†–ê–ó!)
    test_score = model.score(X_test_scaled, y_test)
    print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ Test: {test_score:.4f}")

    # 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å joblib
    save_model(model, scaler)

    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
