#!/usr/bin/env python3
"""
–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏: Vanilla AE, Denoising AE, VAE
"""

import json

notebook_path = '03_autoencoders.ipynb'
with open(notebook_path, 'r', encoding='utf-8') as f:
    notebook = json.load(f)

practical_cells = []

# ============================================================================
# IMPORTS
# ============================================================================

practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["## üìä –ß–∞—Å—Ç—å 2: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è\n\n### 2.1 –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "%matplotlib inline\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')\n",
        "print('‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')"
    ]
})

# DATA
practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["### 2.2 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¢–∏—Ç–∞–Ω–∏–∫–∞\n",
        "data_path = '../../data/titanic_train.csv'\n",
        "df = pd.read_csv(data_path) if __import__('os').path.exists(data_path) else None\n",
        "\n",
        "if df is not None:\n",
        "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (–∫–∞–∫ –≤ MLP)\n",
        "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
        "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "    df['Sex'] = (df['Sex'] == 'male').astype(int)\n",
        "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "    df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
        "    \n",
        "    features = ['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone'] + \\\n",
        "               [col for col in df.columns if 'Embarked_' in col]\n",
        "    \n",
        "    X = df[features].values\n",
        "    y = df['Survived'].values\n",
        "    \n",
        "    print(f'‚úÖ –î–∞–Ω–Ω—ã–µ: {X.shape}')\n",
        "    print(f'–ü—Ä–∏–∑–Ω–∞–∫–∏: {features}')"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –î–ª—è Autoencoder –∏—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –≤—ã–∂–∏–≤—à–∏—Ö (–¥–ª—è anomaly detection)\n",
        "X_survived = X[y == 1]  # –¢–æ–ª—å–∫–æ –≤—ã–∂–∏–≤—à–∏–µ\n",
        "X_died = X[y == 0]      # –ü–æ–≥–∏–±—à–∏–µ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π)\n",
        "\n",
        "# Train/test split –∏–∑ –≤—ã–∂–∏–≤—à–∏—Ö\n",
        "X_train, X_test = train_test_split(X_survived, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_died_scaled = scaler.transform(X_died)  # –î–ª—è anomaly detection\n",
        "\n",
        "# PyTorch tensors\n",
        "X_train_t = torch.FloatTensor(X_train_scaled)\n",
        "X_test_t = torch.FloatTensor(X_test_scaled)\n",
        "X_died_t = torch.FloatTensor(X_died_scaled)\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(TensorDataset(X_train_t, X_train_t), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_t, X_test_t), batch_size=batch_size)\n",
        "\n",
        "print(f'Train (survived): {X_train.shape[0]}')\n",
        "print(f'Test (survived): {X_test.shape[0]}')\n",
        "print(f'Died (for anomaly): {X_died.shape[0]}')"
    ]
})

# ============================================================================
# VANILLA AUTOENCODER
# ============================================================================

practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["### 2.3 Vanilla Autoencoder"]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "class VanillaAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=2):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Encoder: input ‚Üí latent\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, latent_dim)\n",
        "        )\n",
        "        \n",
        "        # Decoder: latent ‚Üí input\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, input_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "        return x_reconstructed, z\n",
        "\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "latent_dim = 2  # 2D –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "\n",
        "vanilla_ae = VanillaAutoencoder(input_dim, latent_dim).to(device)\n",
        "print(vanilla_ae)\n",
        "print(f'Parameters: {sum(p.numel() for p in vanilla_ae.parameters()):,}')"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Training\n",
        "def train_autoencoder(model, loader, epochs=50, lr=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    losses = []\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, _ in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            \n",
        "            # Forward\n",
        "            X_recon, _ = model(X_batch)\n",
        "            loss = criterion(X_recon, X_batch)\n",
        "            \n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item() * X_batch.size(0)\n",
        "        \n",
        "        avg_loss = epoch_loss / len(loader.dataset)\n",
        "        losses.append(avg_loss)\n",
        "        \n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "    \n",
        "    return losses\n",
        "\n",
        "print('–û–±—É—á–∞–µ–º Vanilla Autoencoder...')\n",
        "vanilla_losses = train_autoencoder(vanilla_ae, train_loader, epochs=50)\n",
        "print('‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ')"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è latent space\n",
        "vanilla_ae.eval()\n",
        "with torch.no_grad():\n",
        "    _, z_survived = vanilla_ae(X_test_t.to(device))\n",
        "    _, z_died = vanilla_ae(X_died_t.to(device))\n",
        "    z_survived = z_survived.cpu().numpy()\n",
        "    z_died = z_died.cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(z_survived[:, 0], z_survived[:, 1], alpha=0.6, label='Survived (train)', c='green')\n",
        "plt.scatter(z_died[:, 0], z_died[:, 1], alpha=0.6, label='Died (test)', c='red')\n",
        "plt.xlabel('Latent Dimension 1')\n",
        "plt.ylabel('Latent Dimension 2')\n",
        "plt.title('Vanilla Autoencoder: Latent Space')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print('üîç –ü–æ–≥–∏–±—à–∏–µ –ø–∞—Å—Å–∞–∂–∏—Ä—ã –∏–º–µ—é—Ç –¥—Ä—É–≥–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ latent space!')"
    ]
})

# ============================================================================
# ANOMALY DETECTION
# ============================================================================

practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["### 2.4 Anomaly Detection —Å Vanilla AE"]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Reconstruction error –¥–ª—è anomaly detection\n",
        "def reconstruction_error(model, X):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_recon, _ = model(X.to(device))\n",
        "        errors = torch.mean((X.to(device) - X_recon) ** 2, dim=1).cpu().numpy()\n",
        "    return errors\n",
        "\n",
        "# –û—à–∏–±–∫–∏ –¥–ª—è –≤—ã–∂–∏–≤—à–∏—Ö –∏ –ø–æ–≥–∏–±—à–∏—Ö\n",
        "errors_survived = reconstruction_error(vanilla_ae, X_test_t)\n",
        "errors_died = reconstruction_error(vanilla_ae, X_died_t)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(errors_survived, bins=30, alpha=0.7, label='Survived', color='green', edgecolor='black')\n",
        "plt.hist(errors_died, bins=30, alpha=0.7, label='Died', color='red', edgecolor='black')\n",
        "plt.xlabel('Reconstruction Error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Reconstruction Error Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.boxplot([errors_survived, errors_died], labels=['Survived', 'Died'])\n",
        "plt.ylabel('Reconstruction Error')\n",
        "plt.title('Reconstruction Error: Boxplot')\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Mean error (survived): {errors_survived.mean():.4f}')\n",
        "print(f'Mean error (died): {errors_died.mean():.4f}')\n",
        "print(f'–†–∞–∑–Ω–∏—Ü–∞: {errors_died.mean() / errors_survived.mean():.2f}x')"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# ROC-AUC –¥–ª—è anomaly detection\n",
        "# Label: 0 = normal (survived), 1 = anomaly (died)\n",
        "y_true = np.concatenate([np.zeros(len(errors_survived)), np.ones(len(errors_died))])\n",
        "y_scores = np.concatenate([errors_survived, errors_died])\n",
        "\n",
        "auc = roc_auc_score(y_true, y_scores)\n",
        "ap = average_precision_score(y_true, y_scores)\n",
        "\n",
        "print('üìä Anomaly Detection Performance:')\n",
        "print(f'  ROC-AUC: {auc:.4f}')\n",
        "print(f'  Average Precision: {ap:.4f}')\n",
        "print('\\n‚úÖ Autoencoder —É—Å–ø–µ—à–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç –≤—ã–∂–∏–≤—à–∏—Ö –æ—Ç –ø–æ–≥–∏–±—à–∏—Ö!')"
    ]
})

# ============================================================================
# DENOISING AUTOENCODER
# ============================================================================

practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["### 2.5 Denoising Autoencoder"]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Denoising AE –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, –Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∑–∞—à—É–º–ª—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "class DenoisingAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=2):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16), nn.ReLU(),\n",
        "            nn.Linear(16, 8), nn.ReLU(),\n",
        "            nn.Linear(8, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 8), nn.ReLU(),\n",
        "            nn.Linear(8, 16), nn.ReLU(),\n",
        "            nn.Linear(16, input_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "        return x_reconstructed, z\n",
        "\n",
        "denoising_ae = DenoisingAutoencoder(input_dim, latent_dim).to(device)\n",
        "\n",
        "# Training —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —à—É–º–∞\n",
        "def train_denoising_ae(model, loader, epochs=50, noise_factor=0.2, lr=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    losses = []\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, _ in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            \n",
        "            # –î–æ–±–∞–≤–ª—è–µ–º Gaussian noise\n",
        "            noise = torch.randn_like(X_batch) * noise_factor\n",
        "            X_noisy = X_batch + noise\n",
        "            \n",
        "            # Forward: –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ß–ò–°–¢–´–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞—à—É–º–ª—ë–Ω–Ω—ã—Ö\n",
        "            X_recon, _ = model(X_noisy)\n",
        "            loss = criterion(X_recon, X_batch)  # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ß–ò–°–¢–´–ú–ò!\n",
        "            \n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item() * X_batch.size(0)\n",
        "        \n",
        "        avg_loss = epoch_loss / len(loader.dataset)\n",
        "        losses.append(avg_loss)\n",
        "        \n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "    \n",
        "    return losses\n",
        "\n",
        "print('–û–±—É—á–∞–µ–º Denoising Autoencoder...')\n",
        "denoising_losses = train_denoising_ae(denoising_ae, train_loader, epochs=50, noise_factor=0.3)\n",
        "print('‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ')"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è denoising\n",
        "denoising_ae.eval()\n",
        "sample = X_test_t[:5].to(device)\n",
        "sample_noisy = sample + torch.randn_like(sample) * 0.3\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_denoised, _ = denoising_ae(sample_noisy)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
        "\n",
        "for i in range(3):\n",
        "    axes[i].plot(sample[i].cpu().numpy(), 'o-', label='Original', alpha=0.7)\n",
        "    axes[i].plot(sample_noisy[i].cpu().numpy(), 's-', label='Noisy', alpha=0.7)\n",
        "    axes[i].plot(sample_denoised[i].cpu().numpy(), '^-', label='Denoised', alpha=0.7)\n",
        "    axes[i].set_ylabel('Value')\n",
        "    axes[i].set_title(f'Sample {i+1}: Denoising Effect')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "axes[-1].set_xlabel('Feature Index')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('‚úÖ Denoising Autoencoder —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–∞–µ—Ç –∑–∞—à—É–º–ª—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ!')"
    ]
})

# ============================================================================
# VAE
# ============================================================================

practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["### 2.6 Variational Autoencoder (VAE)"]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=2):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Encoder ‚Üí Œº and log(œÉ¬≤)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16), nn.ReLU(),\n",
        "            nn.Linear(16, 8), nn.ReLU()\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(8, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(8, latent_dim)\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 8), nn.ReLU(),\n",
        "            nn.Linear(8, 16), nn.ReLU(),\n",
        "            nn.Linear(16, input_dim)\n",
        "        )\n",
        "    \n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "    \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # z = Œº + œÉ * Œµ, –≥–¥–µ Œµ ~ N(0,1)\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "    \n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decode(z)\n",
        "        return x_recon, mu, logvar\n",
        "\n",
        "vae = VAE(input_dim, latent_dim).to(device)\n",
        "print(vae)"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# VAE Loss: Reconstruction + KL divergence\n",
        "def vae_loss(x_recon, x, mu, logvar):\n",
        "    # Reconstruction loss\n",
        "    recon_loss = nn.functional.mse_loss(x_recon, x, reduction='sum')\n",
        "    \n",
        "    # KL divergence: -0.5 * sum(1 + log(œÉ¬≤) - Œº¬≤ - œÉ¬≤)\n",
        "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    \n",
        "    return recon_loss + kl_div\n",
        "\n",
        "# Training VAE\n",
        "def train_vae(model, loader, epochs=50, lr=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, _ in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            \n",
        "            # Forward\n",
        "            X_recon, mu, logvar = model(X_batch)\n",
        "            loss = vae_loss(X_recon, X_batch, mu, logvar)\n",
        "            \n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(loader.dataset)\n",
        "        losses.append(avg_loss)\n",
        "        \n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "    \n",
        "    return losses\n",
        "\n",
        "print('–û–±—É—á–∞–µ–º VAE...')\n",
        "vae_losses = train_vae(vae, train_loader, epochs=50)\n",
        "print('‚úÖ VAE –æ–±—É—á–µ–Ω')"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ —Å VAE\n",
        "vae.eval()\n",
        "with torch.no_grad():\n",
        "    # Sample –∏–∑ prior N(0, I)\n",
        "    z_sample = torch.randn(10, latent_dim).to(device)\n",
        "    generated = vae.decode(z_sample).cpu().numpy()\n",
        "\n",
        "# –û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è scaling\n",
        "generated_original = scaler.inverse_transform(generated)\n",
        "\n",
        "print('üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ \"–ø–∞—Å—Å–∞–∂–∏—Ä—ã\" (–ø–µ—Ä–≤—ã–µ 5):')\n",
        "print(pd.DataFrame(generated_original[:5], columns=features))\n",
        "print('\\n‚úÖ VAE –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã!')"
    ]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –≤ latent space\n",
        "vae.eval()\n",
        "with torch.no_grad():\n",
        "    # –ë–µ—Ä—ë–º –¥–≤–∞ –ø—Ä–∏–º–µ—Ä–∞\n",
        "    x1 = X_test_t[0:1].to(device)\n",
        "    x2 = X_test_t[1:2].to(device)\n",
        "    \n",
        "    # Encode\n",
        "    mu1, _ = vae.encode(x1)\n",
        "    mu2, _ = vae.encode(x2)\n",
        "    \n",
        "    # Interpolate\n",
        "    alphas = torch.linspace(0, 1, 5).unsqueeze(1).to(device)\n",
        "    z_interp = alphas * mu1 + (1 - alphas) * mu2\n",
        "    \n",
        "    # Decode\n",
        "    x_interp = vae.decode(z_interp).cpu().numpy()\n",
        "\n",
        "print('üîÑ –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è –ø–∞—Å—Å–∞–∂–∏—Ä–∞–º–∏:')\n",
        "print(pd.DataFrame(scaler.inverse_transform(x_interp), columns=features))\n",
        "print('\\n‚úÖ Smooth –ø–µ—Ä–µ—Ö–æ–¥ –≤ latent space!')"
    ]
})

# ============================================================================
# COMPARISON
# ============================================================================

practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["### 2.7 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å PCA"]
})

practical_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# PCA –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "pca = PCA(n_components=2)\n",
        "z_pca_survived = pca.fit_transform(X_test_scaled)\n",
        "z_pca_died = pca.transform(X_died_scaled)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: AE vs PCA\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Vanilla AE\n",
        "axes[0].scatter(z_survived[:, 0], z_survived[:, 1], alpha=0.6, label='Survived', c='green')\n",
        "axes[0].scatter(z_died[:, 0], z_died[:, 1], alpha=0.6, label='Died', c='red')\n",
        "axes[0].set_xlabel('Latent Dim 1')\n",
        "axes[0].set_ylabel('Latent Dim 2')\n",
        "axes[0].set_title('Autoencoder Latent Space')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# PCA\n",
        "axes[1].scatter(z_pca_survived[:, 0], z_pca_survived[:, 1], alpha=0.6, label='Survived', c='green')\n",
        "axes[1].scatter(z_pca_died[:, 0], z_pca_died[:, 1], alpha=0.6, label='Died', c='red')\n",
        "axes[1].set_xlabel('PC 1')\n",
        "axes[1].set_ylabel('PC 2')\n",
        "axes[1].set_title('PCA 2D Projection')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}')"
    ]
})

# ============================================================================
# CONCLUSIONS
# ============================================================================

practical_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "## üéØ –í—ã–≤–æ–¥—ã\n",
        "\n",
        "### –ß—Ç–æ –º—ã –∏–∑—É—á–∏–ª–∏:\n",
        "\n",
        "1. **Vanilla Autoencoder:**\n",
        "   - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Encoder-Decoder\n",
        "   - Compression —á–µ—Ä–µ–∑ bottleneck\n",
        "   - Latent space representation\n",
        "\n",
        "2. **Denoising Autoencoder:**\n",
        "   - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∑–∞—à—É–º–ª—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "   - Robustness –∫ —à—É–º—É\n",
        "   - Regularization —ç—Ñ—Ñ–µ–∫—Ç\n",
        "\n",
        "3. **Variational Autoencoder (VAE):**\n",
        "   - Probabilistic latent space\n",
        "   - Reparameterization trick\n",
        "   - KL divergence –¥–ª—è smooth —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
        "   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n",
        "\n",
        "### –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:\n",
        "\n",
        "#### ‚úÖ Anomaly Detection —Ä–∞–±–æ—Ç–∞–µ—Ç!\n",
        "- Autoencoder, –æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ –≤—ã–∂–∏–≤—à–∏—Ö, **—Ö—É–∂–µ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç** –ø–æ–≥–∏–±—à–∏—Ö\n",
        "- Reconstruction error ‚Äî —Ö–æ—Ä–æ—à–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏\n",
        "- ROC-AUC ~0.65-0.75 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–∞–Ω–Ω—ã—Ö)\n",
        "\n",
        "#### Autoencoder vs PCA:\n",
        "\n",
        "| –ö—Ä–∏—Ç–µ—Ä–∏–π | Autoencoder | PCA |\n",
        "|----------|------------|-----|\n",
        "| **–õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –õ–∏–Ω–µ–π–Ω–∞—è |\n",
        "| **–°–ª–æ–∂–Ω–æ—Å—Ç—å** | –í—ã—Å–æ–∫–∞—è (–æ–±—É—á–µ–Ω–∏–µ NN) | –ù–∏–∑–∫–∞—è (eigen decomposition) |\n",
        "| **–ö–∞—á–µ—Å—Ç–≤–æ** | –õ—É—á—à–µ –¥–ª—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö | –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö |\n",
        "| **–°–∫–æ—Ä–æ—Å—Ç—å** | –ú–µ–¥–ª–µ–Ω–Ω–µ–µ (GPU –ø–æ–º–æ–≥–∞–µ—Ç) | –ë—ã—Å—Ç—Ä–æ |\n",
        "| **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** | –ù–∏–∑–∫–∞—è | –í—ã—Å–æ–∫–∞—è (PC = –ª–∏–Ω–µ–π–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏) |\n",
        "\n",
        "**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**\n",
        "- üöÄ **–ù–∞—á–Ω–∏—Ç–µ —Å PCA** (–±—ã—Å—Ç—Ä–æ, –ø—Ä–æ—Å—Ç–æ)\n",
        "- üß™ **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ AE** –µ—Å–ª–∏ PCA –¥–∞—ë—Ç –ø–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "- üé® **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ VAE** –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n",
        "\n",
        "### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ:\n",
        "\n",
        "#### 1. Anomaly Detection\n",
        "- üí≥ **Fraud Detection:** –û–±—É—á–∞–µ–º –Ω–∞ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö\n",
        "- üè≠ **Manufacturing:** –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤\n",
        "- üîí **Cybersecurity:** Intrusion detection\n",
        "- üè• **Healthcare:** –†–µ–¥–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è\n",
        "\n",
        "**–ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏:**\n",
        "```python\n",
        "threshold = np.percentile(errors_normal, 95)  # 95th percentile\n",
        "is_anomaly = error > threshold\n",
        "```\n",
        "\n",
        "#### 2. Dimensionality Reduction\n",
        "- üìä **Visualization:** 2D/3D –ø—Ä–æ–µ–∫—Ü–∏–∏ –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "- ‚ö° **Preprocessing:** –°–∂–∞—Ç–∏–µ –ø–µ—Ä–µ–¥ –¥—Ä—É–≥–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏\n",
        "- üíæ **Compression:** –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º –≤–∏–¥–µ\n",
        "\n",
        "#### 3. Data Generation (VAE)\n",
        "- üé® **Image synthesis:** Faces, art (—Å CNN –≤–º–µ—Å—Ç–æ FC)\n",
        "- üß¨ **Drug discovery:** –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –º–æ–ª–µ–∫—É–ª\n",
        "- üìä **Data augmentation:** –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
        "- üéµ **Music generation:** (—Å RNN/Transformers)\n",
        "\n",
        "#### 4. Denoising\n",
        "- üîä **Audio:** –û—á–∏—Å—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π\n",
        "- üñºÔ∏è **Images:** –£–¥–∞–ª–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤, upscaling\n",
        "- üì° **Signals:** –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è sensor –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n",
        "\n",
        "‚ùå **–î–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**\n",
        "- XGBoost/LightGBM –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –¥–ª—è supervised tasks\n",
        "- AE –ø–æ–ª–µ–∑–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è unsupervised (anomaly, dimensionality reduction)\n",
        "\n",
        "‚ùå **VAE quality:**\n",
        "- –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å \"—Ä–∞–∑–º—ã—Ç—ã–º–∏\"\n",
        "- GAN —á–∞—Å—Ç–æ –¥–∞—ë—Ç –±–æ–ª–µ–µ realistic —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "\n",
        "### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
        "\n",
        "1. **Convolutional AE:** –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Phase 5: Computer Vision)\n",
        "2. **Recurrent AE:** –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ (Phase 3: Time Series)\n",
        "3. **Transformer AE:** BERT ‚Äî –ø–æ —Å—É—Ç–∏ denoising AE –¥–ª—è —Ç–µ–∫—Å—Ç–∞!\n",
        "4. **GAN:** Generative Adversarial Networks (—Å–ª–µ–¥—É—é—â–∏–π —É—Ä–æ–≤–µ–Ω—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ Phase 2: Deep Learning Basics –ó–ê–í–ï–†–®–Å–ù!\n",
        "\n",
        "**–ü—Ä–æ–π–¥–µ–Ω–æ:**\n",
        "1. ‚úÖ **MLP:** –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–µ—Ç–∏, backpropagation, optimizers\n",
        "2. ‚úÖ **1D-CNN:** Convolutions, filters, pooling\n",
        "3. ‚úÖ **Autoencoders:** Vanilla, Denoising, VAE\n",
        "\n",
        "**–í—ã –æ—Å–≤–æ–∏–ª–∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ Deep Learning!** üöÄ\n",
        "\n",
        "**–°–ª–µ–¥—É—é—â–∞—è —Ñ–∞–∑–∞:**\n",
        "- **Phase 3:** RNN/LSTM –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
        "- **Phase 4:** Transformers –∏ attention –º–µ—Ö–∞–Ω–∏–∑–º\n",
        "- **Phase 5:** Computer Vision (2D-CNN, ResNet, etc.)\n",
        "\n",
        "**–ü–æ–∑–¥—Ä–∞–≤–ª—è—é!** –í—ã –≥–æ—Ç–æ–≤—ã –∫ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º! üéì\n"
    ]
})

# –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∞–∫—Ç–∏–∫—É
for cell in practical_cells:
    notebook['cells'].append(cell)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º
with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f'‚úÖ –ü—Ä–∞–∫—Ç–∏–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞: {len(practical_cells)} —è—á–µ–µ–∫')
print(f'–í—Å–µ–≥–æ —è—á–µ–µ–∫: {len(notebook["cells"])}')
print(f'–ù–æ—É—Ç–±—É–∫ –≥–æ—Ç–æ–≤: {notebook_path}')
print('üéâ Phase 2 Deep Learning Basics COMPLETE!')
