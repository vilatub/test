{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ” Advanced Clustering: DBSCAN, Hierarchical & UMAP\n",
    "\n",
    "**Phase 5 Expansion: ÐœÐµÑ‚Ð¾Ð´Ñ‹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€ Ð´Ð°Ð½Ð½Ñ‹Ñ…**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Ð—Ð°Ñ‡ÐµÐ¼ Ð½ÑƒÐ¶Ð½Ñ‹ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñ‹ K-Means?\n",
    "\n",
    "**K-Means limitations:**\n",
    "- âŒ Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ Ð·Ð°Ð´Ð°Ñ‚ÑŒ Ñ‡Ð¸ÑÐ»Ð¾ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð² K\n",
    "- âŒ ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÑ„ÐµÑ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñ‹\n",
    "- âŒ Ð§ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÐµÐ½ Ðº Ð²Ñ‹Ð±Ñ€Ð¾ÑÐ°Ð¼\n",
    "- âŒ ÐÐµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð°Ð¼Ð¸ Ñ€Ð°Ð·Ð½Ð¾Ð¹ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸\n",
    "\n",
    "**ÐšÐ¾Ð³Ð´Ð° K-Means Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚:**\n",
    "\n",
    "```\n",
    "K-Means:          DBSCAN:\n",
    "   â—â—â—               â—â—â—\n",
    "  â—â—â—â—â—             â—â—â—â—â—\n",
    "   â—â—â—               â—â—â—\n",
    "                          â—\n",
    "      â—â—â—â—â—â—â—â—â—â—         â—â—â—â—â—â—â—â—â—â—\n",
    "      (1 ÐºÐ»Ð°ÑÑ‚ÐµÑ€)        (2 ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° + Ð²Ñ‹Ð±Ñ€Ð¾Ñ)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š ÐœÐµÑ‚Ð¾Ð´Ñ‹ Ð² ÑÑ‚Ð¾Ð¼ notebook\n",
    "\n",
    "### 1. **DBSCAN (Density-Based Spatial Clustering)**\n",
    "- ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð»ÑŒÐ½Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ñ‹\n",
    "- ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ñ‡Ð¸ÑÐ»Ð¾ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð²\n",
    "- Ð’Ñ‹Ð´ÐµÐ»ÑÐµÑ‚ Ð²Ñ‹Ð±Ñ€Ð¾ÑÑ‹ (noise points)\n",
    "- ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹: eps (Ñ€Ð°Ð´Ð¸ÑƒÑ), min_samples\n",
    "\n",
    "### 2. **Hierarchical Clustering**\n",
    "- Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ Ð¸ÐµÑ€Ð°Ñ€Ñ…Ð¸ÑŽ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð² (Ð´ÐµÐ½Ð´Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°)\n",
    "- Agglomerative (ÑÐ½Ð¸Ð·Ñƒ Ð²Ð²ÐµÑ€Ñ…) Ð¸Ð»Ð¸ Divisive (ÑÐ²ÐµÑ€Ñ…Ñƒ Ð²Ð½Ð¸Ð·)\n",
    "- Ð Ð°Ð·Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑÐ²ÑÐ·Ð¸: single, complete, average, ward\n",
    "- ÐœÐ¾Ð¶Ð½Ð¾ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ñ‡Ð¸ÑÐ»Ð¾ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð² Ð¿Ð¾ÑÐ»Ðµ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ\n",
    "\n",
    "### 3. **UMAP (Uniform Manifold Approximation)**\n",
    "- Dimensionality reduction Ð´Ð»Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸\n",
    "- Ð›ÑƒÑ‡ÑˆÐµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ñ‡ÐµÐ¼ t-SNE\n",
    "- Ð‘Ñ‹ÑÑ‚Ñ€ÐµÐµ t-SNE Ð½Ð° Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Hierarchical clustering visualization\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"âš ï¸ UMAP not installed. Install with: pip install umap-learn\")\n",
    "\n",
    "# Datasets\n",
    "from sklearn.datasets import make_moons, make_circles, make_blobs\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Libraries loaded\")\n",
    "if UMAP_AVAILABLE:\n",
    "    print(f\"UMAP version: {umap.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Ð§Ð°ÑÑ‚ÑŒ 1: Synthetic Datasets\n",
    "\n",
    "Ð¡Ð¾Ð·Ð´Ð°Ð´Ð¸Ð¼ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð¾Ð² Ñ Ñ€Ð°Ð·Ð½Ñ‹Ð¼Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°Ð¼Ð¸ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸:\n",
    "1. **Moons** - Ð´Ð²Ð° Ð¿Ð¾Ð»ÑƒÐ¼ÐµÑÑÑ†Ð° (non-convex)\n",
    "2. **Circles** - ÐºÐ¾Ð½Ñ†ÐµÐ½Ñ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÐºÑ€ÑƒÐ³Ð¸\n",
    "3. **Blobs with varying density** - ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñ‹ Ñ€Ð°Ð·Ð½Ð¾Ð¹ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸\n",
    "4. **Complex real-world** - ÑÐ¼ÐµÑÑŒ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic datasets\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Moons - Ð´Ð²Ð° Ð¿Ð¾Ð»ÑƒÐ¼ÐµÑÑÑ†Ð°\n",
    "X_moons, y_moons = make_moons(n_samples=1000, noise=0.05, random_state=42)\n",
    "\n",
    "# 2. Circles - ÐºÐ¾Ð½Ñ†ÐµÐ½Ñ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÐºÑ€ÑƒÐ³Ð¸\n",
    "X_circles, y_circles = make_circles(n_samples=1000, noise=0.05, factor=0.5, random_state=42)\n",
    "\n",
    "# 3. Blobs with varying density\n",
    "# Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñ‹ Ñ€Ð°Ð·Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°\n",
    "X_blob1 = np.random.randn(300, 2) * 0.5 + np.array([0, 0])\n",
    "X_blob2 = np.random.randn(100, 2) * 0.2 + np.array([3, 3])\n",
    "X_blob3 = np.random.randn(500, 2) * 1.0 + np.array([-3, 3])\n",
    "X_blobs_varied = np.vstack([X_blob1, X_blob2, X_blob3])\n",
    "y_blobs_varied = np.array([0]*300 + [1]*100 + [2]*500)\n",
    "\n",
    "# 4. Complex dataset with noise\n",
    "X_complex, y_complex = make_blobs(n_samples=800, centers=4, cluster_std=[1.0, 1.5, 0.5, 1.2], random_state=42)\n",
    "# Add noise points\n",
    "noise = np.random.uniform(-10, 10, (50, 2))\n",
    "X_complex = np.vstack([X_complex, noise])\n",
    "y_complex = np.hstack([y_complex, [-1]*50])  # -1 for noise\n",
    "\n",
    "datasets = {\n",
    "    'Moons': (X_moons, y_moons),\n",
    "    'Circles': (X_circles, y_circles),\n",
    "    'Varied Density': (X_blobs_varied, y_blobs_varied),\n",
    "    'Complex + Noise': (X_complex, y_complex)\n",
    "}\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, (X, y)) in enumerate(datasets.items()):\n",
    "    scatter = axes[idx].scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.6, s=20)\n",
    "    axes[idx].set_title(f'{name} (n={len(X)})', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Feature 1')\n",
    "    axes[idx].set_ylabel('Feature 2')\n",
    "\n",
    "plt.suptitle('Synthetic Datasets for Clustering', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Datasets created:\")\n",
    "for name, (X, y) in datasets.items():\n",
    "    n_clusters = len(np.unique(y[y >= 0]))\n",
    "    print(f\"  {name}: {len(X)} samples, {n_clusters} true clusters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”¬ Ð§Ð°ÑÑ‚ÑŒ 2: DBSCAN\n",
    "\n",
    "### ÐšÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ DBSCAN?\n",
    "\n",
    "**ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ð¸:**\n",
    "\n",
    "1. **Core point:** Ñ‚Ð¾Ñ‡ÐºÐ° Ñ â‰¥ min_samples ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ð² Ñ€Ð°Ð´Ð¸ÑƒÑÐµ eps\n",
    "2. **Border point:** Ð½Ðµ core, Ð½Ð¾ Ð² eps-Ð¾ÐºÑ€ÐµÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ core point\n",
    "3. **Noise point:** Ð½Ð¸ core, Ð½Ð¸ border\n",
    "\n",
    "**ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼:**\n",
    "1. Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð½Ð°Ð¹Ñ‚Ð¸ ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ð² Ñ€Ð°Ð´Ð¸ÑƒÑÐµ eps\n",
    "2. Ð•ÑÐ»Ð¸ ÑÐ¾ÑÐµÐ´ÐµÐ¹ â‰¥ min_samples â†’ core point, ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÐºÐ»Ð°ÑÑ‚ÐµÑ€\n",
    "3. Ð Ð°ÑÑˆÐ¸Ñ€ÑÑ‚ÑŒ ÐºÐ»Ð°ÑÑ‚ÐµÑ€, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ density-reachable Ñ‚Ð¾Ñ‡ÐºÐ¸\n",
    "4. Ð¢Ð¾Ñ‡ÐºÐ¸, Ð½Ðµ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð½ÑƒÑ‚Ñ‹Ðµ Ð½Ð¸ Ð¾Ð´Ð½Ð¸Ð¼ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð¼ â†’ noise\n",
    "\n",
    "**ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:**\n",
    "- `eps`: Ñ€Ð°Ð´Ð¸ÑƒÑ Ð¾ÐºÑ€ÐµÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ (Ð²Ð°Ð¶Ð½ÐµÐ¹ÑˆÐ¸Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€)\n",
    "- `min_samples`: Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ Ñ‚Ð¾Ñ‡ÐµÐº Ð´Ð»Ñ core point\n",
    "\n",
    "**ÐšÐ°Ðº Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ eps?**\n",
    "- k-distance plot (elbow method)\n",
    "- Ð”Ð¾Ð¼ÐµÐ¹Ð½ knowledge\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DBSCAN: DENSITY-BASED CLUSTERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def find_optimal_eps(X, k=5):\n",
    "    \"\"\"\n",
    "    Find optimal eps using k-distance plot.\n",
    "    Look for 'elbow' in the sorted k-distances.\n",
    "    \"\"\"\n",
    "    neighbors = NearestNeighbors(n_neighbors=k)\n",
    "    neighbors.fit(X)\n",
    "    distances, _ = neighbors.kneighbors(X)\n",
    "    \n",
    "    # k-th nearest neighbor distance\n",
    "    k_distances = distances[:, k-1]\n",
    "    k_distances = np.sort(k_distances)\n",
    "    \n",
    "    return k_distances\n",
    "\n",
    "# Demonstrate on Moons dataset\n",
    "print(\"\\nðŸ“Š Finding optimal eps for Moons dataset...\")\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_moons_scaled = scaler.fit_transform(X_moons)\n",
    "\n",
    "# K-distance plot\n",
    "k_distances = find_optimal_eps(X_moons_scaled, k=5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# K-distance plot\n",
    "axes[0].plot(k_distances, linewidth=2)\n",
    "axes[0].set_xlabel('Points (sorted)', fontsize=12)\n",
    "axes[0].set_ylabel('5-th Nearest Neighbor Distance', fontsize=12)\n",
    "axes[0].set_title('K-Distance Plot for eps Selection', fontsize=14, fontweight='bold')\n",
    "axes[0].axhline(y=0.15, color='r', linestyle='--', label='Suggested eps=0.15')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Find elbow (approximate)\n",
    "eps_suggested = 0.15\n",
    "print(f\"Suggested eps: {eps_suggested}\")\n",
    "\n",
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=eps_suggested, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_moons_scaled)\n",
    "\n",
    "# Results\n",
    "n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"\\nDBSCAN Results:\")\n",
    "print(f\"  Clusters found: {n_clusters}\")\n",
    "print(f\"  Noise points: {n_noise} ({n_noise/len(X_moons)*100:.1f}%)\")\n",
    "\n",
    "# Plot results\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "for label in set(dbscan_labels):\n",
    "    mask = dbscan_labels == label\n",
    "    if label == -1:\n",
    "        axes[1].scatter(X_moons_scaled[mask, 0], X_moons_scaled[mask, 1], \n",
    "                       c='gray', marker='x', s=30, label='Noise', alpha=0.5)\n",
    "    else:\n",
    "        axes[1].scatter(X_moons_scaled[mask, 0], X_moons_scaled[mask, 1], \n",
    "                       c=colors[label % len(colors)], s=30, \n",
    "                       label=f'Cluster {label}', alpha=0.6)\n",
    "\n",
    "axes[1].set_title(f'DBSCAN: {n_clusters} clusters, {n_noise} noise', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Feature 1 (scaled)')\n",
    "axes[1].set_ylabel('Feature 2 (scaled)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… DBSCAN successfully separated the moons!\")\n",
    "print(\"   K-Means would fail here (non-convex clusters)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare DBSCAN vs K-Means on all datasets\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DBSCAN vs K-MEANS COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 16))\n",
    "\n",
    "for idx, (name, (X, y_true)) in enumerate(datasets.items()):\n",
    "    # Scale\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # True labels\n",
    "    axes[idx, 0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_true, cmap='viridis', s=20, alpha=0.6)\n",
    "    axes[idx, 0].set_title(f'{name}: True Labels', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # K-Means\n",
    "    n_true = len(set(y_true[y_true >= 0]))\n",
    "    kmeans = KMeans(n_clusters=n_true, random_state=42, n_init=10)\n",
    "    kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "    axes[idx, 1].scatter(X_scaled[:, 0], X_scaled[:, 1], c=kmeans_labels, cmap='viridis', s=20, alpha=0.6)\n",
    "    axes[idx, 1].set_title(f'K-Means (K={n_true})', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # DBSCAN\n",
    "    # Find good eps for this dataset\n",
    "    k_dist = find_optimal_eps(X_scaled, k=5)\n",
    "    eps = np.percentile(k_dist, 90) * 0.5  # heuristic\n",
    "    \n",
    "    dbscan = DBSCAN(eps=eps, min_samples=5)\n",
    "    dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "    \n",
    "    n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "    n_noise = list(dbscan_labels).count(-1)\n",
    "    \n",
    "    scatter = axes[idx, 2].scatter(X_scaled[:, 0], X_scaled[:, 1], c=dbscan_labels, cmap='viridis', s=20, alpha=0.6)\n",
    "    # Mark noise\n",
    "    noise_mask = dbscan_labels == -1\n",
    "    if noise_mask.any():\n",
    "        axes[idx, 2].scatter(X_scaled[noise_mask, 0], X_scaled[noise_mask, 1], \n",
    "                           c='red', marker='x', s=30, alpha=0.7)\n",
    "    axes[idx, 2].set_title(f'DBSCAN ({n_clusters} clusters, {n_noise} noise)', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('DBSCAN vs K-Means on Different Data Structures', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Key observations:\")\n",
    "print(\"- Moons/Circles: DBSCAN >> K-Means (non-convex shapes)\")\n",
    "print(\"- Varied Density: DBSCAN handles different densities better\")\n",
    "print(\"- Complex + Noise: DBSCAN identifies noise points (red X)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŒ³ Ð§Ð°ÑÑ‚ÑŒ 3: Hierarchical Clustering\n",
    "\n",
    "### ÐšÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚?\n",
    "\n",
    "**Agglomerative (bottom-up):**\n",
    "1. ÐšÐ°Ð¶Ð´Ð°Ñ Ñ‚Ð¾Ñ‡ÐºÐ° - Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€\n",
    "2. ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð´Ð²Ð° Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÐ¸Ñ… ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð°\n",
    "3. ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€ÑÐµÐ¼ Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð¾ÑÑ‚Ð°Ð½ÐµÑ‚ÑÑ Ð¾Ð´Ð¸Ð½ ÐºÐ»Ð°ÑÑ‚ÐµÑ€\n",
    "4. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ - Ð´ÐµÐ½Ð´Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° (Ð´ÐµÑ€ÐµÐ²Ð¾)\n",
    "\n",
    "**Linkage methods:**\n",
    "- **Single:** min distance between clusters (chain effect)\n",
    "- **Complete:** max distance (compact clusters)\n",
    "- **Average:** average distance\n",
    "- **Ward:** minimize variance increase (spherical clusters)\n",
    "\n",
    "**ÐŸÑ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°:**\n",
    "- âœ… ÐÐµ Ð½ÑƒÐ¶Ð½Ð¾ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ Ð·Ð°Ð´Ð°Ð²Ð°Ñ‚ÑŒ K\n",
    "- âœ… Ð”ÐµÐ½Ð´Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð¸ÐµÑ€Ð°Ñ€Ñ…Ð¸ÑŽ\n",
    "- âœ… ÐœÐ¾Ð¶Ð½Ð¾ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ K Ð¿Ð¾ÑÐ»Ðµ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ\n",
    "\n",
    "**ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸:**\n",
    "- âŒ O(nÂ²) Ð¿Ð°Ð¼ÑÑ‚ÑŒ, O(nÂ³) Ð²Ñ€ÐµÐ¼Ñ\n",
    "- âŒ ÐÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use Varied Density dataset\n",
    "X_hier = X_blobs_varied.copy()\n",
    "X_hier_scaled = StandardScaler().fit_transform(X_hier)\n",
    "\n",
    "# Compute linkage matrix\n",
    "print(\"\\nComputing linkage matrices...\")\n",
    "linkage_methods = ['single', 'complete', 'average', 'ward']\n",
    "linkages = {}\n",
    "\n",
    "for method in linkage_methods:\n",
    "    linkages[method] = linkage(X_hier_scaled, method=method)\n",
    "\n",
    "print(\"âœ… Linkage matrices computed\")\n",
    "\n",
    "# Plot dendrograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, method in enumerate(linkage_methods):\n",
    "    dendrogram(\n",
    "        linkages[method],\n",
    "        ax=axes[idx],\n",
    "        truncate_mode='lastp',\n",
    "        p=30,  # show last 30 merges\n",
    "        leaf_rotation=90,\n",
    "        leaf_font_size=8,\n",
    "        show_contracted=True\n",
    "    )\n",
    "    axes[idx].set_title(f'{method.capitalize()} Linkage', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Sample index')\n",
    "    axes[idx].set_ylabel('Distance')\n",
    "    \n",
    "    # Draw cut line for 3 clusters\n",
    "    if method == 'ward':\n",
    "        axes[idx].axhline(y=15, color='r', linestyle='--', label='Cut for 3 clusters')\n",
    "        axes[idx].legend()\n",
    "\n",
    "plt.suptitle('Dendrograms: Different Linkage Methods', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Linkage comparison:\")\n",
    "print(\"- Single: chain-like clusters, sensitive to noise\")\n",
    "print(\"- Complete: compact clusters, sensitive to outliers\")\n",
    "print(\"- Average: balanced, robust\")\n",
    "print(\"- Ward: spherical clusters, minimizes variance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Agglomerative Clustering with different linkages\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"AGGLOMERATIVE CLUSTERING COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "n_clusters = 3  # True number\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# True labels\n",
    "axes[0, 0].scatter(X_hier_scaled[:, 0], X_hier_scaled[:, 1], c=y_blobs_varied, cmap='viridis', s=30, alpha=0.6)\n",
    "axes[0, 0].set_title('True Labels', fontsize=12, fontweight='bold')\n",
    "\n",
    "# K-Means for comparison\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X_hier_scaled)\n",
    "axes[0, 1].scatter(X_hier_scaled[:, 0], X_hier_scaled[:, 1], c=kmeans_labels, cmap='viridis', s=30, alpha=0.6)\n",
    "axes[0, 1].set_title('K-Means', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Different linkages\n",
    "plot_positions = [(0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "results = {}\n",
    "\n",
    "for idx, method in enumerate(linkage_methods):\n",
    "    agg = AgglomerativeClustering(n_clusters=n_clusters, linkage=method)\n",
    "    labels = agg.fit_predict(X_hier_scaled)\n",
    "    results[method] = labels\n",
    "    \n",
    "    pos = plot_positions[idx]\n",
    "    axes[pos].scatter(X_hier_scaled[:, 0], X_hier_scaled[:, 1], c=labels, cmap='viridis', s=30, alpha=0.6)\n",
    "    \n",
    "    # Compute silhouette\n",
    "    sil = silhouette_score(X_hier_scaled, labels)\n",
    "    axes[pos].set_title(f'{method.capitalize()} (Silhouette: {sil:.3f})', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Agglomerative Clustering: Linkage Comparison', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Silhouette Scores:\")\n",
    "for method, labels in results.items():\n",
    "    sil = silhouette_score(X_hier_scaled, labels)\n",
    "    print(f\"  {method.capitalize():10s}: {sil:.4f}\")\n",
    "print(f\"  {'K-Means':10s}: {silhouette_score(X_hier_scaled, kmeans_labels):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ—ºï¸ Ð§Ð°ÑÑ‚ÑŒ 4: UMAP Visualization\n",
    "\n",
    "### UMAP vs t-SNE\n",
    "\n",
    "**UMAP (Uniform Manifold Approximation and Projection):**\n",
    "- âœ… Ð‘Ñ‹ÑÑ‚Ñ€ÐµÐµ t-SNE Ð½Ð° Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "- âœ… Ð›ÑƒÑ‡ÑˆÐµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ\n",
    "- âœ… ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð±Ð¾Ð»ÐµÐµ Ð¸Ð½Ñ‚ÑƒÐ¸Ñ‚Ð¸Ð²Ð½Ñ‹\n",
    "- âœ… ÐœÐ¾Ð¶ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð´Ð»Ñ transform Ð½Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "\n",
    "**ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:**\n",
    "- `n_neighbors`: Ð±Ð°Ð»Ð°Ð½Ñ local vs global structure\n",
    "- `min_dist`: Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ñ‚Ð¾Ñ‡ÐµÐº Ð² projection\n",
    "- `metric`: Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ (euclidean, cosine, etc.)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"UMAP vs t-SNE VISUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create higher-dimensional dataset for dimensionality reduction demo\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load digits dataset (8x8 images = 64 dimensions)\n",
    "digits = load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "print(f\"\\nDigits dataset: {X_digits.shape[0]} samples, {X_digits.shape[1]} dimensions\")\n",
    "print(f\"Classes: {len(np.unique(y_digits))} digits (0-9)\")\n",
    "\n",
    "# Scale\n",
    "X_digits_scaled = StandardScaler().fit_transform(X_digits)\n",
    "\n",
    "# t-SNE\n",
    "print(\"\\nRunning t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_digits_scaled)\n",
    "print(\"âœ… t-SNE done\")\n",
    "\n",
    "# UMAP\n",
    "if UMAP_AVAILABLE:\n",
    "    print(\"Running UMAP...\")\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    X_umap = reducer.fit_transform(X_digits_scaled)\n",
    "    print(\"âœ… UMAP done\")\n",
    "else:\n",
    "    X_umap = X_tsne  # fallback\n",
    "    print(\"âš ï¸ UMAP not available, showing t-SNE twice\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# t-SNE\n",
    "scatter1 = axes[0].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_digits, cmap='tab10', s=5, alpha=0.7)\n",
    "axes[0].set_title('t-SNE (perplexity=30)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Dimension 1')\n",
    "axes[0].set_ylabel('Dimension 2')\n",
    "\n",
    "# UMAP\n",
    "scatter2 = axes[1].scatter(X_umap[:, 0], X_umap[:, 1], c=y_digits, cmap='tab10', s=5, alpha=0.7)\n",
    "axes[1].set_title('UMAP (n_neighbors=15)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Dimension 1')\n",
    "axes[1].set_ylabel('Dimension 2')\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(scatter2, ax=axes[1])\n",
    "cbar.set_label('Digit')\n",
    "\n",
    "plt.suptitle('Dimensionality Reduction: 64D â†’ 2D', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Observations:\")\n",
    "print(\"- Both methods separate digit clusters well\")\n",
    "print(\"- UMAP typically preserves global structure better\")\n",
    "print(\"- UMAP is faster on larger datasets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“‹ Summary & Recommendations\n",
    "\n",
    "### When to use each method:\n",
    "\n",
    "| Method | Best for | Avoid when |\n",
    "|--------|----------|------------|\n",
    "| **K-Means** | Spherical clusters, known K | Non-convex shapes, outliers |\n",
    "| **DBSCAN** | Arbitrary shapes, unknown K, noise | Varying densities, high dimensions |\n",
    "| **Hierarchical** | Small data, need hierarchy, interpretability | Large datasets (>10k) |\n",
    "| **UMAP** | Visualization, preserving structure | Need exact distances |\n",
    "\n",
    "### Practical tips:\n",
    "\n",
    "1. **Always scale data** before clustering\n",
    "2. **DBSCAN eps:** Use k-distance plot or domain knowledge\n",
    "3. **Hierarchical linkage:** Ward for spherical, average for general\n",
    "4. **Evaluation:** Use silhouette, but also visual inspection\n",
    "5. **High dimensions:** Reduce with PCA/UMAP first\n",
    "\n",
    "### Key takeaways:\n",
    "\n",
    "- âœ… **DBSCAN** excels at non-convex clusters and noise detection\n",
    "- âœ… **Hierarchical** gives interpretable dendrograms\n",
    "- âœ… **UMAP** is the go-to for visualization\n",
    "- âœ… **No single best method** - depends on data structure\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}