{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cc8729",
   "metadata": {},
   "source": [
    "# –§–∞–∑–∞ 7.3: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è MLOps –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞\n",
    "\n",
    "## Kubernetes, Feature Store –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞\n",
    "\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ MLOps:\n",
    "\n",
    "### –¢–µ–º—ã\n",
    "\n",
    "1. **Kubernetes Deployment** - –º–∞–Ω–∏—Ñ–µ—Å—Ç—ã –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è ML-–º–æ–¥–µ–ª–µ–π –≤ K8s\n",
    "2. **Feature Store** - –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "3. **Data Drift Detection** - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö (—Å—Ç–∏–ª—å Evidently)\n",
    "\n",
    "### –ó–∞–¥–∞—á–∞\n",
    "\n",
    "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É —Å –º–æ–¥–µ–ª—å—é –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ (Customer Churn) –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫:\n",
    "- –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –º–æ–¥–µ–ª—å –≤ Kubernetes\n",
    "- –û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "- –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –¥—Ä–∏—Ñ—Ç–∞\n",
    "\n",
    "### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å\n",
    "\n",
    "–≠—Ç–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è production-ready ML —Å–∏—Å—Ç–µ–º, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å, –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898578c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)\n",
    "def create_churn_data(n_samples=10000, drift=False, drift_magnitude=0.3):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ—Ç—Ç–æ–∫–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞.\n",
    "\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤\n",
    "    drift : bool\n",
    "        –î–æ–±–∞–≤–∏—Ç—å –ª–∏ –¥—Ä–∏—Ñ—Ç –≤ –¥–∞–Ω–Ω—ã–µ\n",
    "    drift_magnitude : float\n",
    "        –°–∏–ª–∞ –¥—Ä–∏—Ñ—Ç–∞\n",
    "\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    data = {\n",
    "        'customer_id': range(1, n_samples + 1),\n",
    "        'tenure_months': np.random.randint(1, 72, n_samples),\n",
    "        'monthly_charges': np.random.uniform(20, 100, n_samples),\n",
    "        'total_charges': np.zeros(n_samples),\n",
    "        'num_support_tickets': np.random.poisson(2, n_samples),\n",
    "        'num_referrals': np.random.poisson(1, n_samples),\n",
    "        'contract_type': np.random.choice(['Month-to-month', 'One year', 'Two year'],\n",
    "                                          n_samples, p=[0.5, 0.3, 0.2]),\n",
    "        'payment_method': np.random.choice(['Electronic', 'Mailed', 'Bank', 'Credit'],\n",
    "                                           n_samples),\n",
    "        'internet_service': np.random.choice(['DSL', 'Fiber', 'No'],\n",
    "                                             n_samples, p=[0.35, 0.45, 0.2]),\n",
    "    }\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä–∏—Ñ—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "    if drift:\n",
    "        # –î—Ä–∏—Ñ—Ç: —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ü–µ–Ω –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–∏–∫–µ—Ç–æ–≤\n",
    "        data['monthly_charges'] *= (1 + drift_magnitude)\n",
    "        data['num_support_tickets'] = np.random.poisson(3.5, n_samples)\n",
    "        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤\n",
    "        data['contract_type'] = np.random.choice(\n",
    "            ['Month-to-month', 'One year', 'Two year'],\n",
    "            n_samples, p=[0.65, 0.25, 0.10]\n",
    "        )\n",
    "\n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º total_charges\n",
    "    data['total_charges'] = data['tenure_months'] * data['monthly_charges'] * \\\n",
    "                            np.random.uniform(0.9, 1.1, n_samples)\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—Ç–æ–∫\n",
    "    churn_prob = 0.1 + \\\n",
    "        0.3 * (np.array([1 if c == 'Month-to-month' else 0 for c in data['contract_type']])) + \\\n",
    "        0.1 * (data['tenure_months'] < 12) / 12 + \\\n",
    "        0.1 * (data['num_support_tickets'] > 3) + \\\n",
    "        0.1 * (data['monthly_charges'] > 70)\n",
    "\n",
    "    churn_prob = np.clip(churn_prob, 0, 1)\n",
    "    data['churned'] = np.random.binomial(1, churn_prob)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –¥–∞–Ω–Ω—ã–µ —Å –¥—Ä–∏—Ñ—Ç–æ–º\n",
    "df_train = create_churn_data(n_samples=10000, drift=False)\n",
    "df_production = create_churn_data(n_samples=3000, drift=True, drift_magnitude=0.3)\n",
    "\n",
    "print(f\"–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ: {df_train.shape}\")\n",
    "print(f\"Production –¥–∞–Ω–Ω—ã–µ (—Å –¥—Ä–∏—Ñ—Ç–æ–º): {df_production.shape}\")\n",
    "print(f\"\\n–û—Ç—Ç–æ–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏: {df_train['churned'].mean()*100:.1f}%\")\n",
    "print(f\"–û—Ç—Ç–æ–∫ –≤ production: {df_production['churned'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1d0bd",
   "metadata": {},
   "source": [
    "## 1. Kubernetes Deployment\n",
    "\n",
    "### –ß—Ç–æ —Ç–∞–∫–æ–µ Kubernetes?\n",
    "\n",
    "Kubernetes (K8s) - —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä–∞—è:\n",
    "- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
    "- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å\n",
    "- –£–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ–º –∏ –æ—Ç–∫–∞—Ç–æ–º\n",
    "\n",
    "### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è ML\n",
    "\n",
    "1. **Deployment** - –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∂–µ–ª–∞–µ–º–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
    "2. **Service** - –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–µ—Ç–µ–≤–æ–π –¥–æ—Å—Ç—É–ø\n",
    "3. **ConfigMap** - —Ö—Ä–∞–Ω–∏—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é\n",
    "4. **Secret** - —Ö—Ä–∞–Ω–∏—Ç sensitive –¥–∞–Ω–Ω—ã–µ\n",
    "5. **HorizontalPodAutoscaler** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n",
    "### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –¥–ª—è ML\n",
    "\n",
    "- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–ø–ª–∏–∫–∏ –ø—Ä–∏ –Ω–∞–≥—Ä—É–∑–∫–µ\n",
    "- **–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å** - –æ–∫—Ä—É–∂–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–æ –≤ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞—Ö\n",
    "- **–ò–∑–æ–ª—è—Ü–∏—è** - –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –≤ —Å–≤–æ—ë–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ\n",
    "- **Rolling updates** - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑ –ø—Ä–æ—Å—Ç–æ—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Kubernetes –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏\n",
    "\n",
    "def generate_k8s_manifests(model_name, image, replicas=3, cpu_limit='500m', memory_limit='512Mi'):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Kubernetes –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è ML –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    model_name : str\n",
    "        –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "    image : str\n",
    "        Docker –æ–±—Ä–∞–∑\n",
    "    replicas : int\n",
    "        –ß–∏—Å–ª–æ —Ä–µ–ø–ª–∏–∫\n",
    "    cpu_limit : str\n",
    "        –õ–∏–º–∏—Ç CPU\n",
    "    memory_limit : str\n",
    "        –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏\n",
    "\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    dict —Å –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞–º–∏\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Deployment\n",
    "    deployment = {\n",
    "        'apiVersion': 'apps/v1',\n",
    "        'kind': 'Deployment',\n",
    "        'metadata': {\n",
    "            'name': f'{model_name}-deployment',\n",
    "            'labels': {\n",
    "                'app': model_name,\n",
    "                'version': 'v1'\n",
    "            }\n",
    "        },\n",
    "        'spec': {\n",
    "            'replicas': replicas,\n",
    "            'selector': {\n",
    "                'matchLabels': {\n",
    "                    'app': model_name\n",
    "                }\n",
    "            },\n",
    "            'template': {\n",
    "                'metadata': {\n",
    "                    'labels': {\n",
    "                        'app': model_name,\n",
    "                        'version': 'v1'\n",
    "                    },\n",
    "                    'annotations': {\n",
    "                        'prometheus.io/scrape': 'true',\n",
    "                        'prometheus.io/port': '8000'\n",
    "                    }\n",
    "                },\n",
    "                'spec': {\n",
    "                    'containers': [{\n",
    "                        'name': model_name,\n",
    "                        'image': image,\n",
    "                        'ports': [{'containerPort': 8000}],\n",
    "                        'resources': {\n",
    "                            'requests': {\n",
    "                                'cpu': '100m',\n",
    "                                'memory': '256Mi'\n",
    "                            },\n",
    "                            'limits': {\n",
    "                                'cpu': cpu_limit,\n",
    "                                'memory': memory_limit\n",
    "                            }\n",
    "                        },\n",
    "                        'env': [\n",
    "                            {'name': 'MODEL_NAME', 'value': model_name},\n",
    "                            {'name': 'LOG_LEVEL', 'value': 'INFO'}\n",
    "                        ],\n",
    "                        'livenessProbe': {\n",
    "                            'httpGet': {\n",
    "                                'path': '/health',\n",
    "                                'port': 8000\n",
    "                            },\n",
    "                            'initialDelaySeconds': 30,\n",
    "                            'periodSeconds': 10\n",
    "                        },\n",
    "                        'readinessProbe': {\n",
    "                            'httpGet': {\n",
    "                                'path': '/ready',\n",
    "                                'port': 8000\n",
    "                            },\n",
    "                            'initialDelaySeconds': 5,\n",
    "                            'periodSeconds': 5\n",
    "                        }\n",
    "                    }]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 2. Service\n",
    "    service = {\n",
    "        'apiVersion': 'v1',\n",
    "        'kind': 'Service',\n",
    "        'metadata': {\n",
    "            'name': f'{model_name}-service'\n",
    "        },\n",
    "        'spec': {\n",
    "            'selector': {\n",
    "                'app': model_name\n",
    "            },\n",
    "            'ports': [{\n",
    "                'protocol': 'TCP',\n",
    "                'port': 80,\n",
    "                'targetPort': 8000\n",
    "            }],\n",
    "            'type': 'ClusterIP'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 3. HorizontalPodAutoscaler\n",
    "    hpa = {\n",
    "        'apiVersion': 'autoscaling/v2',\n",
    "        'kind': 'HorizontalPodAutoscaler',\n",
    "        'metadata': {\n",
    "            'name': f'{model_name}-hpa'\n",
    "        },\n",
    "        'spec': {\n",
    "            'scaleTargetRef': {\n",
    "                'apiVersion': 'apps/v1',\n",
    "                'kind': 'Deployment',\n",
    "                'name': f'{model_name}-deployment'\n",
    "            },\n",
    "            'minReplicas': 2,\n",
    "            'maxReplicas': 10,\n",
    "            'metrics': [{\n",
    "                'type': 'Resource',\n",
    "                'resource': {\n",
    "                    'name': 'cpu',\n",
    "                    'target': {\n",
    "                        'type': 'Utilization',\n",
    "                        'averageUtilization': 70\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 4. ConfigMap –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "    configmap = {\n",
    "        'apiVersion': 'v1',\n",
    "        'kind': 'ConfigMap',\n",
    "        'metadata': {\n",
    "            'name': f'{model_name}-config'\n",
    "        },\n",
    "        'data': {\n",
    "            'model_config.yaml': yaml.dump({\n",
    "                'model_name': model_name,\n",
    "                'version': 'v1',\n",
    "                'threshold': 0.5,\n",
    "                'features': ['tenure_months', 'monthly_charges', 'total_charges',\n",
    "                            'num_support_tickets', 'contract_type']\n",
    "            })\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'deployment': deployment,\n",
    "        'service': service,\n",
    "        'hpa': hpa,\n",
    "        'configmap': configmap\n",
    "    }\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç—ã\n",
    "manifests = generate_k8s_manifests(\n",
    "    model_name='churn-predictor',\n",
    "    image='ml-registry/churn-model:v1.0',\n",
    "    replicas=3\n",
    ")\n",
    "\n",
    "print(\"Kubernetes Deployment –º–∞–Ω–∏—Ñ–µ—Å—Ç:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(manifests['deployment'], default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aebbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service –º–∞–Ω–∏—Ñ–µ—Å—Ç\n",
    "print(\"Kubernetes Service –º–∞–Ω–∏—Ñ–µ—Å—Ç:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(manifests['service'], default_flow_style=False))\n",
    "\n",
    "print(\"\\nHorizontalPodAutoscaler –º–∞–Ω–∏—Ñ–µ—Å—Ç:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(manifests['hpa'], default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –≤ —Ñ–∞–π–ª—ã\n",
    "import os\n",
    "\n",
    "k8s_dir = '/home/user/test/notebooks/phase7_production_mlops/k8s'\n",
    "os.makedirs(k8s_dir, exist_ok=True)\n",
    "\n",
    "for name, manifest in manifests.items():\n",
    "    filepath = os.path.join(k8s_dir, f'{name}.yaml')\n",
    "    with open(filepath, 'w') as f:\n",
    "        yaml.dump(manifest, f, default_flow_style=False)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}\")\n",
    "\n",
    "print(\"\\n–ö–æ–º–∞–Ω–¥—ã –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è:\")\n",
    "print(\"kubectl apply -f k8s/\")\n",
    "print(\"kubectl get pods -l app=churn-predictor\")\n",
    "print(\"kubectl get hpa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d8075",
   "metadata": {},
   "source": [
    "## 2. Feature Store\n",
    "\n",
    "### –ß—Ç–æ —Ç–∞–∫–æ–µ Feature Store?\n",
    "\n",
    "Feature Store - —ç—Ç–æ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML, –∫–æ—Ç–æ—Ä–æ–µ:\n",
    "- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏\n",
    "- –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –æ–±—É—á–µ–Ω–∏–µ–º –∏ inference\n",
    "- –í–µ—Ä—Å–∏–æ–Ω–∏—Ä—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç point-in-time –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å\n",
    "\n",
    "### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n",
    "\n",
    "1. **Feature Registry** - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\n",
    "2. **Offline Store** - –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "3. **Online Store** - –Ω–∏–∑–∫–æ–ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è inference\n",
    "4. **Feature Transformation** - –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞\n",
    "\n",
    "- **–ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ** - –æ–¥–Ω–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–Ω–æ–≥–∏—Ö –º–æ–¥–µ–ª–µ–π\n",
    "- **–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å** - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ train –∏ serve\n",
    "- **–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "\n",
    "–ú—ã —Ä–µ–∞–ª–∏–∑—É–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFeatureStore:\n",
    "    \"\"\"\n",
    "    –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Feature Store.\n",
    "\n",
    "    –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:\n",
    "    - –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    - –•—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "    - –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è inference\n",
    "    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_registry = {}  # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\n",
    "        self.offline_store = {}     # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n",
    "        self.online_store = {}      # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "        self.statistics = {}        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "\n",
    "    def register_feature(self, name, dtype, description, transformation=None):\n",
    "        \"\"\"\n",
    "        –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞.\n",
    "\n",
    "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "        ----------\n",
    "        name : str\n",
    "            –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "        dtype : str\n",
    "            –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö\n",
    "        description : str\n",
    "            –û–ø–∏—Å–∞–Ω–∏–µ\n",
    "        transformation : callable\n",
    "            –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "        \"\"\"\n",
    "        self.feature_registry[name] = {\n",
    "            'name': name,\n",
    "            'dtype': dtype,\n",
    "            'description': description,\n",
    "            'transformation': transformation,\n",
    "            'created_at': datetime.now().isoformat(),\n",
    "            'version': 1\n",
    "        }\n",
    "\n",
    "        self.offline_store[name] = []\n",
    "        self.online_store[name] = {}\n",
    "        self.statistics[name] = {\n",
    "            'count': 0,\n",
    "            'mean': 0,\n",
    "            'std': 0,\n",
    "            'min': float('inf'),\n",
    "            'max': float('-inf')\n",
    "        }\n",
    "\n",
    "        print(f\"–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: {name}\")\n",
    "\n",
    "    def ingest(self, entity_id, features, timestamp=None):\n",
    "        \"\"\"\n",
    "        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "\n",
    "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "        ----------\n",
    "        entity_id : str/int\n",
    "            ID —Å—É—â–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, customer_id)\n",
    "        features : dict\n",
    "            –°–ª–æ–≤–∞—Ä—å {–Ω–∞–∑–≤–∞–Ω–∏–µ: –∑–Ω–∞—á–µ–Ω–∏–µ}\n",
    "        timestamp : datetime\n",
    "            –í—Ä–µ–º—è –∑–∞–ø–∏—Å–∏\n",
    "        \"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now()\n",
    "\n",
    "        for name, value in features.items():\n",
    "            if name not in self.feature_registry:\n",
    "                raise ValueError(f\"–ü—Ä–∏–∑–Ω–∞–∫ {name} –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω\")\n",
    "\n",
    "            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å\n",
    "            transform = self.feature_registry[name].get('transformation')\n",
    "            if transform:\n",
    "                value = transform(value)\n",
    "\n",
    "            # Offline store (–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ)\n",
    "            self.offline_store[name].append({\n",
    "                'entity_id': entity_id,\n",
    "                'value': value,\n",
    "                'timestamp': timestamp\n",
    "            })\n",
    "\n",
    "            # Online store (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)\n",
    "            self.online_store[name][entity_id] = value\n",
    "\n",
    "            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "            self._update_statistics(name, value)\n",
    "\n",
    "    def _update_statistics(self, name, value):\n",
    "        \"\"\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞.\"\"\"\n",
    "        stats = self.statistics[name]\n",
    "\n",
    "        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ\n",
    "        n = stats['count']\n",
    "        old_mean = stats['mean']\n",
    "\n",
    "        stats['count'] = n + 1\n",
    "        stats['mean'] = old_mean + (value - old_mean) / (n + 1)\n",
    "\n",
    "        if n > 0:\n",
    "            stats['std'] = np.sqrt(\n",
    "                ((n - 1) * stats['std']**2 + (value - old_mean) * (value - stats['mean'])) / n\n",
    "            )\n",
    "\n",
    "        stats['min'] = min(stats['min'], value)\n",
    "        stats['max'] = max(stats['max'], value)\n",
    "\n",
    "    def get_online_features(self, entity_id, feature_names):\n",
    "        \"\"\"\n",
    "        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è inference (–Ω–∏–∑–∫–∞—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å).\n",
    "\n",
    "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "        ----------\n",
    "        entity_id : str/int\n",
    "            ID —Å—É—â–Ω–æ—Å—Ç–∏\n",
    "        feature_names : list\n",
    "            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "        -----------\n",
    "        dict —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for name in feature_names:\n",
    "            if name in self.online_store:\n",
    "                result[name] = self.online_store[name].get(entity_id)\n",
    "            else:\n",
    "                result[name] = None\n",
    "        return result\n",
    "\n",
    "    def get_historical_features(self, entity_ids, feature_names, start_time=None, end_time=None):\n",
    "        \"\"\"\n",
    "        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "        ----------\n",
    "        entity_ids : list\n",
    "            –°–ø–∏—Å–æ–∫ ID —Å—É—â–Ω–æ—Å—Ç–µ–π\n",
    "        feature_names : list\n",
    "            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        start_time : datetime\n",
    "            –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞\n",
    "        end_time : datetime\n",
    "            –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞\n",
    "\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "        -----------\n",
    "        DataFrame —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "        \"\"\"\n",
    "        records = []\n",
    "\n",
    "        for entity_id in entity_ids:\n",
    "            record = {'entity_id': entity_id}\n",
    "\n",
    "            for name in feature_names:\n",
    "                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è entity_id\n",
    "                values = [\n",
    "                    r for r in self.offline_store.get(name, [])\n",
    "                    if r['entity_id'] == entity_id\n",
    "                ]\n",
    "\n",
    "                if start_time:\n",
    "                    values = [v for v in values if v['timestamp'] >= start_time]\n",
    "                if end_time:\n",
    "                    values = [v for v in values if v['timestamp'] <= end_time]\n",
    "\n",
    "                if values:\n",
    "                    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "                    record[name] = sorted(values, key=lambda x: x['timestamp'])[-1]['value']\n",
    "                else:\n",
    "                    record[name] = None\n",
    "\n",
    "            records.append(record)\n",
    "\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "    def get_feature_statistics(self, name):\n",
    "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É.\"\"\"\n",
    "        return self.statistics.get(name, {})\n",
    "\n",
    "    def list_features(self):\n",
    "        \"\"\"–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\"\"\"\n",
    "        return list(self.feature_registry.keys())\n",
    "\n",
    "print(\"–ö–ª–∞—Å—Å SimpleFeatureStore –æ–ø—Ä–µ–¥–µ–ª—ë–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞—ë–º –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Feature Store\n",
    "fs = SimpleFeatureStore()\n",
    "\n",
    "# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "fs.register_feature(\n",
    "    name='tenure_months',\n",
    "    dtype='int',\n",
    "    description='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—è—Ü–µ–≤ —Å –∫–æ–º–ø–∞–Ω–∏–µ–π'\n",
    ")\n",
    "\n",
    "fs.register_feature(\n",
    "    name='monthly_charges',\n",
    "    dtype='float',\n",
    "    description='–ï–∂–µ–º–µ—Å—è—á–Ω—ã–π –ø–ª–∞—Ç—ë–∂'\n",
    ")\n",
    "\n",
    "fs.register_feature(\n",
    "    name='total_charges',\n",
    "    dtype='float',\n",
    "    description='–û–±—â–∞—è —Å—É–º–º–∞ –ø–ª–∞—Ç–µ–∂–µ–π'\n",
    ")\n",
    "\n",
    "fs.register_feature(\n",
    "    name='support_tickets_normalized',\n",
    "    dtype='float',\n",
    "    description='–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ —Ç–∏–∫–µ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏',\n",
    "    transformation=lambda x: np.log1p(x)  # log-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    ")\n",
    "\n",
    "fs.register_feature(\n",
    "    name='avg_monthly_charge',\n",
    "    dtype='float',\n",
    "    description='–°—Ä–µ–¥–Ω–∏–π –º–µ—Å—è—á–Ω—ã–π –ø–ª–∞—Ç—ë–∂ (total/tenure)'\n",
    ")\n",
    "\n",
    "print(\"\\n–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\")\n",
    "for name in fs.list_features():\n",
    "    info = fs.feature_registry[name]\n",
    "    print(f\"  {name}: {info['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdc218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Feature Store\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Feature Store...\")\n",
    "\n",
    "# –ë–µ—Ä—ë–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "sample_data = df_train.head(1000)\n",
    "\n",
    "for _, row in sample_data.iterrows():\n",
    "    customer_id = row['customer_id']\n",
    "\n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    features = {\n",
    "        'tenure_months': row['tenure_months'],\n",
    "        'monthly_charges': row['monthly_charges'],\n",
    "        'total_charges': row['total_charges'],\n",
    "        'support_tickets_normalized': row['num_support_tickets'],\n",
    "        'avg_monthly_charge': row['total_charges'] / max(row['tenure_months'], 1)\n",
    "    }\n",
    "\n",
    "    fs.ingest(customer_id, features)\n",
    "\n",
    "print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sample_data)} –∑–∞–ø–∏—Å–µ–π\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "print(\"\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
    "for name in fs.list_features():\n",
    "    stats = fs.get_feature_statistics(name)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Count: {stats['count']}\")\n",
    "    print(f\"  Mean: {stats['mean']:.2f}\")\n",
    "    print(f\"  Std: {stats['std']:.2f}\")\n",
    "    print(f\"  Min: {stats['min']:.2f}\")\n",
    "    print(f\"  Max: {stats['max']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee75916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "# 1. Online features (–¥–ª—è inference)\n",
    "customer_id = 42\n",
    "online_features = fs.get_online_features(\n",
    "    customer_id,\n",
    "    ['tenure_months', 'monthly_charges', 'support_tickets_normalized']\n",
    ")\n",
    "\n",
    "print(\"Online Features –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞\", customer_id)\n",
    "print(json.dumps(online_features, indent=2, default=str))\n",
    "\n",
    "# 2. Historical features (–¥–ª—è –æ–±—É—á–µ–Ω–∏—è)\n",
    "entity_ids = [1, 2, 3, 4, 5]\n",
    "historical_df = fs.get_historical_features(\n",
    "    entity_ids,\n",
    "    ['tenure_months', 'monthly_charges', 'total_charges', 'avg_monthly_charge']\n",
    ")\n",
    "\n",
    "print(\"\\nHistorical Features:\")\n",
    "print(historical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533feb7",
   "metadata": {},
   "source": [
    "## 3. Data Drift Detection\n",
    "\n",
    "### –ß—Ç–æ —Ç–∞–∫–æ–µ Data Drift?\n",
    "\n",
    "Data Drift - —ç—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤—Ä–µ–º–µ–Ω–∏. –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è ML, –ø–æ—Ç–æ–º—É —á—Ç–æ:\n",
    "- –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏\n",
    "- –ï—Å–ª–∏ production –¥–∞–Ω–Ω—ã–µ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è, –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞–¥–∞–µ—Ç\n",
    "- –ù—É–∂–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è\n",
    "\n",
    "### –¢–∏–ø—ã –¥—Ä–∏—Ñ—Ç–∞\n",
    "\n",
    "1. **Feature Drift** - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "2. **Label Drift** - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "3. **Concept Drift** - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª—å—é\n",
    "\n",
    "### –ú–µ—Ç–æ–¥—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è\n",
    "\n",
    "1. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã**\n",
    "   - Kolmogorov-Smirnov (K-S test)\n",
    "   - Chi-squared test\n",
    "   - Population Stability Index (PSI)\n",
    "\n",
    "2. **–†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏**\n",
    "   - Wasserstein distance\n",
    "   - Jensen-Shannon divergence\n",
    "   - KL divergence\n",
    "\n",
    "–ú—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–∏—Ñ—Ç–∞ –≤ —Å—Ç–∏–ª–µ Evidently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e481d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriftDetector:\n",
    "    \"\"\"\n",
    "    –î–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–∏—Ñ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–∏–ª–µ Evidently.\n",
    "\n",
    "    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    –º–µ–∂–¥—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º –∏ —Ç–µ–∫—É—â–∏–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reference_data, feature_names, categorical_features=None):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.\n",
    "\n",
    "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "        ----------\n",
    "        reference_data : DataFrame\n",
    "            –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ–±—ã—á–Ω–æ –æ–±—É—á–∞—é—â–∏–µ)\n",
    "        feature_names : list\n",
    "            –°–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        categorical_features : list\n",
    "            –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        \"\"\"\n",
    "        self.reference_data = reference_data\n",
    "        self.feature_names = feature_names\n",
    "        self.categorical_features = categorical_features or []\n",
    "\n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "        self.reference_stats = self._compute_statistics(reference_data)\n",
    "\n",
    "    def _compute_statistics(self, data):\n",
    "        \"\"\"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞.\"\"\"\n",
    "        stats = {}\n",
    "        for col in self.feature_names:\n",
    "            if col in data.columns:\n",
    "                values = data[col].dropna()\n",
    "                stats[col] = {\n",
    "                    'mean': values.mean(),\n",
    "                    'std': values.std(),\n",
    "                    'median': values.median(),\n",
    "                    'min': values.min(),\n",
    "                    'max': values.max(),\n",
    "                    'percentiles': np.percentile(values, [25, 50, 75]).tolist()\n",
    "                }\n",
    "        return stats\n",
    "\n",
    "    def ks_test(self, reference, current):\n",
    "        \"\"\"\n",
    "        Kolmogorov-Smirnov —Ç–µ—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.\n",
    "\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "        -----------\n",
    "        statistic : float\n",
    "            K-S —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        p_value : float\n",
    "            p-value\n",
    "        \"\"\"\n",
    "        statistic, p_value = stats.ks_2samp(reference, current)\n",
    "        return statistic, p_value\n",
    "\n",
    "    def psi(self, reference, current, bins=10):\n",
    "        \"\"\"\n",
    "        Population Stability Index.\n",
    "\n",
    "        PSI < 0.1 - –Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "        PSI 0.1-0.2 - –Ω–µ–±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "        PSI > 0.2 - –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "        \"\"\"\n",
    "        # –°–æ–∑–¥–∞—ë–º bins –Ω–∞ –æ—Å–Ω–æ–≤–µ reference\n",
    "        _, bin_edges = np.histogram(reference, bins=bins)\n",
    "\n",
    "        # –°—á–∏—Ç–∞–µ–º –¥–æ–ª–∏ –≤ –∫–∞–∂–¥–æ–º bin\n",
    "        ref_counts, _ = np.histogram(reference, bins=bin_edges)\n",
    "        cur_counts, _ = np.histogram(current, bins=bin_edges)\n",
    "\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º\n",
    "        ref_pct = ref_counts / len(reference)\n",
    "        cur_pct = cur_counts / len(current)\n",
    "\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞–ª–æ–µ —á–∏—Å–ª–æ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è log(0)\n",
    "        ref_pct = np.clip(ref_pct, 0.0001, 1)\n",
    "        cur_pct = np.clip(cur_pct, 0.0001, 1)\n",
    "\n",
    "        # PSI\n",
    "        psi_value = np.sum((cur_pct - ref_pct) * np.log(cur_pct / ref_pct))\n",
    "\n",
    "        return psi_value\n",
    "\n",
    "    def detect_drift(self, current_data, threshold_pvalue=0.05, threshold_psi=0.1):\n",
    "        \"\"\"\n",
    "        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—Ä–∏—Ñ—Ç–∞ –≤ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "        ----------\n",
    "        current_data : DataFrame\n",
    "            –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "        threshold_pvalue : float\n",
    "            –ü–æ—Ä–æ–≥ p-value –¥–ª—è K-S —Ç–µ—Å—Ç–∞\n",
    "        threshold_psi : float\n",
    "            –ü–æ—Ä–æ–≥ PSI\n",
    "\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "        -----------\n",
    "        report : dict\n",
    "            –û—Ç—á—ë—Ç –æ –¥—Ä–∏—Ñ—Ç–µ\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'n_reference': len(self.reference_data),\n",
    "            'n_current': len(current_data),\n",
    "            'features': {},\n",
    "            'overall_drift': False,\n",
    "            'drifted_features': []\n",
    "        }\n",
    "\n",
    "        for col in self.feature_names:\n",
    "            if col not in current_data.columns:\n",
    "                continue\n",
    "\n",
    "            ref_values = self.reference_data[col].dropna().values\n",
    "            cur_values = current_data[col].dropna().values\n",
    "\n",
    "            # K-S —Ç–µ—Å—Ç\n",
    "            ks_stat, ks_pvalue = self.ks_test(ref_values, cur_values)\n",
    "\n",
    "            # PSI\n",
    "            psi_value = self.psi(ref_values, cur_values)\n",
    "\n",
    "            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
    "            ref_mean = ref_values.mean()\n",
    "            cur_mean = cur_values.mean()\n",
    "            mean_change = (cur_mean - ref_mean) / (ref_mean + 1e-10) * 100\n",
    "\n",
    "            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥—Ä–∏—Ñ—Ç–∞\n",
    "            is_drifted = (ks_pvalue < threshold_pvalue) or (psi_value > threshold_psi)\n",
    "\n",
    "            feature_report = {\n",
    "                'ks_statistic': ks_stat,\n",
    "                'ks_pvalue': ks_pvalue,\n",
    "                'psi': psi_value,\n",
    "                'reference_mean': ref_mean,\n",
    "                'current_mean': cur_mean,\n",
    "                'mean_change_pct': mean_change,\n",
    "                'is_drifted': is_drifted\n",
    "            }\n",
    "\n",
    "            report['features'][col] = feature_report\n",
    "\n",
    "            if is_drifted:\n",
    "                report['drifted_features'].append(col)\n",
    "\n",
    "        report['overall_drift'] = len(report['drifted_features']) > 0\n",
    "\n",
    "        return report\n",
    "\n",
    "    def plot_drift_report(self, report, figsize=(14, 10)):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –æ –¥—Ä–∏—Ñ—Ç–µ.\"\"\"\n",
    "        features = list(report['features'].keys())\n",
    "        n_features = len(features)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "\n",
    "        # 1. PSI –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "        ax1 = axes[0, 0]\n",
    "        psi_values = [report['features'][f]['psi'] for f in features]\n",
    "        colors = ['red' if p > 0.1 else 'orange' if p > 0.05 else 'green' for p in psi_values]\n",
    "        bars = ax1.barh(features, psi_values, color=colors)\n",
    "        ax1.axvline(x=0.1, color='red', linestyle='--', label='–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π (0.1)')\n",
    "        ax1.axvline(x=0.05, color='orange', linestyle='--', label='–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ (0.05)')\n",
    "        ax1.set_xlabel('PSI')\n",
    "        ax1.set_title('Population Stability Index')\n",
    "        ax1.legend()\n",
    "\n",
    "        # 2. K-S p-values\n",
    "        ax2 = axes[0, 1]\n",
    "        pvalues = [report['features'][f]['ks_pvalue'] for f in features]\n",
    "        colors = ['red' if p < 0.05 else 'green' for p in pvalues]\n",
    "        ax2.barh(features, pvalues, color=colors)\n",
    "        ax2.axvline(x=0.05, color='red', linestyle='--', label='Œ± = 0.05')\n",
    "        ax2.set_xlabel('p-value')\n",
    "        ax2.set_title('Kolmogorov-Smirnov Test p-values')\n",
    "        ax2.legend()\n",
    "\n",
    "        # 3. –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
    "        ax3 = axes[1, 0]\n",
    "        mean_changes = [report['features'][f]['mean_change_pct'] for f in features]\n",
    "        colors = ['red' if abs(m) > 20 else 'orange' if abs(m) > 10 else 'green' for m in mean_changes]\n",
    "        ax3.barh(features, mean_changes, color=colors)\n",
    "        ax3.axvline(x=0, color='black', linewidth=0.5)\n",
    "        ax3.set_xlabel('–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ (%)')\n",
    "        ax3.set_title('–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ')\n",
    "\n",
    "        # 4. –°–≤–æ–¥–∫–∞\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.axis('off')\n",
    "\n",
    "        summary_text = f\"\"\"\n",
    "        –°–í–û–î–ö–ê –ü–û –î–†–ò–§–¢–£\n",
    "\n",
    "        –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {report['n_reference']} –∑–∞–ø–∏—Å–µ–π\n",
    "        –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ: {report['n_current']} –∑–∞–ø–∏—Å–µ–π\n",
    "\n",
    "        –û–±—â–∏–π –¥—Ä–∏—Ñ—Ç: {'–î–ê' if report['overall_drift'] else '–ù–ï–¢'}\n",
    "\n",
    "        –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –¥—Ä–∏—Ñ—Ç–æ–º:\n",
    "        {chr(10).join(['  ‚Ä¢ ' + f for f in report['drifted_features']]) if report['drifted_features'] else '  –ù–µ—Ç'}\n",
    "\n",
    "        –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n",
    "        {'‚Ä¢ –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏' if report['overall_drift'] else '‚Ä¢ –ú–æ–¥–µ–ª—å –∞–∫—Ç—É–∞–ª—å–Ω–∞'}\n",
    "        {'‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö' if report['overall_drift'] else ''}\n",
    "        \"\"\"\n",
    "\n",
    "        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes,\n",
    "                fontsize=11, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "        plt.suptitle('–û—Ç—á—ë—Ç –æ –¥—Ä–∏—Ñ—Ç–µ –¥–∞–Ω–Ω—ã—Ö', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"–ö–ª–∞—Å—Å DriftDetector –æ–ø—Ä–µ–¥–µ–ª—ë–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º Drift Detection\n",
    "\n",
    "# –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
    "numeric_features = ['tenure_months', 'monthly_charges', 'total_charges',\n",
    "                   'num_support_tickets', 'num_referrals']\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–µ–∫—Ç–æ—Ä\n",
    "detector = DriftDetector(\n",
    "    reference_data=df_train,\n",
    "    feature_names=numeric_features\n",
    ")\n",
    "\n",
    "# –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –¥—Ä–∏—Ñ—Ç –≤ production –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"–ê–Ω–∞–ª–∏–∑ –¥—Ä–∏—Ñ—Ç–∞...\")\n",
    "drift_report = detector.detect_drift(df_production)\n",
    "\n",
    "# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "print(\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for feature, metrics in drift_report['features'].items():\n",
    "    status = \"üî¥ –î–†–ò–§–¢\" if metrics['is_drifted'] else \"üü¢ OK\"\n",
    "    print(f\"\\n{feature} {status}\")\n",
    "    print(f\"  PSI: {metrics['psi']:.4f}\")\n",
    "    print(f\"  K-S p-value: {metrics['ks_pvalue']:.4f}\")\n",
    "    print(f\"  –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: {metrics['mean_change_pct']:+.1f}%\")\n",
    "\n",
    "print(f\"\\n–û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {'–î–†–ò–§–¢ –û–ë–ù–ê–†–£–ñ–ï–ù' if drift_report['overall_drift'] else '–î—Ä–∏—Ñ—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω'}\")\n",
    "print(f\"–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –¥—Ä–∏—Ñ—Ç–æ–º: {drift_report['drifted_features']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce94d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞\n",
    "detector.plot_drift_report(drift_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32abbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_features):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    ax.hist(df_train[col], bins=30, alpha=0.5, label='Reference', density=True)\n",
    "    # Production –¥–∞–Ω–Ω—ã–µ\n",
    "    ax.hist(df_production[col], bins=30, alpha=0.5, label='Production', density=True)\n",
    "\n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    ref_mean = df_train[col].mean()\n",
    "    prod_mean = df_production[col].mean()\n",
    "\n",
    "    ax.axvline(ref_mean, color='blue', linestyle='--', linewidth=2)\n",
    "    ax.axvline(prod_mean, color='orange', linestyle='--', linewidth=2)\n",
    "\n",
    "    psi = drift_report['features'][col]['psi']\n",
    "    ax.set_title(f'{col}\\nPSI={psi:.3f}')\n",
    "    ax.legend()\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–π subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.suptitle('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π: Reference vs Production', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–∏—Ñ—Ç–∞\n",
    "\n",
    "def monitor_data_quality(detector, new_data, alert_threshold=0.15):\n",
    "    \"\"\"\n",
    "    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    detector : DriftDetector\n",
    "        –î–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–∏—Ñ—Ç–∞\n",
    "    new_data : DataFrame\n",
    "        –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    alert_threshold : float\n",
    "        –ü–æ—Ä–æ–≥ PSI –¥–ª—è –∞–ª–µ—Ä—Ç–∞\n",
    "\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    alerts : list\n",
    "        –°–ø–∏—Å–æ–∫ –∞–ª–µ—Ä—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    report = detector.detect_drift(new_data)\n",
    "\n",
    "    alerts = []\n",
    "\n",
    "    for feature, metrics in report['features'].items():\n",
    "        if metrics['psi'] > alert_threshold:\n",
    "            alert = {\n",
    "                'type': 'CRITICAL',\n",
    "                'feature': feature,\n",
    "                'message': f'–í—ã—Å–æ–∫–∏–π PSI ({metrics[\"psi\"]:.3f})',\n",
    "                'action': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ'\n",
    "            }\n",
    "            alerts.append(alert)\n",
    "        elif metrics['psi'] > alert_threshold / 2:\n",
    "            alert = {\n",
    "                'type': 'WARNING',\n",
    "                'feature': feature,\n",
    "                'message': f'–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π PSI ({metrics[\"psi\"]:.3f})',\n",
    "                'action': '–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é'\n",
    "            }\n",
    "            alerts.append(alert)\n",
    "\n",
    "    return alerts\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥\n",
    "alerts = monitor_data_quality(detector, df_production)\n",
    "\n",
    "print(\"–ê–ª–µ—Ä—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for alert in alerts:\n",
    "    icon = \"üî¥\" if alert['type'] == 'CRITICAL' else \"üü°\"\n",
    "    print(f\"\\n{icon} {alert['type']}: {alert['feature']}\")\n",
    "    print(f\"   {alert['message']}\")\n",
    "    print(f\"   –î–µ–π—Å—Ç–≤–∏–µ: {alert['action']}\")\n",
    "\n",
    "if not alerts:\n",
    "    print(\"\\nüü¢ –í—Å–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤ –Ω–æ—Ä–º–µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "print(\"=\" * 60)\n",
    "print(\"–ü–†–û–î–í–ò–ù–£–¢–ê–Ø MLOPS –ò–ù–§–†–ê–°–¢–†–£–ö–¢–£–†–ê - –ò–¢–û–ì–ò\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. Kubernetes Deployment\")\n",
    "print(\"   –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: Deployment, Service, HPA, ConfigMap\")\n",
    "print(\"   –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\")\n",
    "print(\"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ CPU\")\n",
    "print(\"   ‚Ä¢ Health checks (liveness/readiness)\")\n",
    "print(\"   ‚Ä¢ Rolling updates –±–µ–∑ –ø—Ä–æ—Å—Ç–æ—è\")\n",
    "print(\"   ‚Ä¢ Prometheus –º–µ—Ç—Ä–∏–∫–∏\")\n",
    "\n",
    "print(\"\\n2. Feature Store\")\n",
    "print(\"   –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: Registry, Offline/Online Store\")\n",
    "print(\"   –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\")\n",
    "print(\"   ‚Ä¢ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "print(\"   ‚Ä¢ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏\")\n",
    "print(\"   ‚Ä¢ –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –¥–ª—è inference\")\n",
    "print(\"   ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\")\n",
    "\n",
    "print(\"\\n3. Drift Detection\")\n",
    "print(\"   –ú–µ—Ç–æ–¥—ã: K-S —Ç–µ—Å—Ç, PSI\")\n",
    "print(\"   –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\")\n",
    "print(\"   ‚Ä¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\")\n",
    "print(\"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–µ—Ä—Ç—ã\")\n",
    "print(\"   ‚Ä¢ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∏—Ñ—Ç–∞\")\n",
    "print(\"   ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø PRODUCTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Kubernetes –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏\")\n",
    "print(\"‚Ä¢ –í–Ω–µ–¥—Ä–∏—Ç–µ Feature Store –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏\")\n",
    "print(\"‚Ä¢ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞ —Å –∞–ª–µ—Ä—Ç–∞–º–∏\")\n",
    "print(\"‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –¥—Ä–∏—Ñ—Ç–µ\")\n",
    "print(\"‚Ä¢ –í–µ–¥–∏—Ç–µ –ª–æ–≥–∏ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9ba02",
   "metadata": {},
   "source": [
    "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "\n",
    "### –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "1. **Kubernetes Deployment** - —Å–æ–∑–¥–∞–ª–∏ –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è ML –º–æ–¥–µ–ª–∏ —Å –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º, health checks –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ Prometheus.\n",
    "\n",
    "2. **Feature Store** - —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏ —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â—É—é –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏: —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ inference.\n",
    "\n",
    "3. **Drift Detection** - –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –¥—Ä–∏—Ñ—Ç –≤ production –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º monthly_charges –∏ num_support_tickets.\n",
    "\n",
    "### –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –¥—Ä–∏—Ñ—Ç\n",
    "\n",
    "Production –¥–∞–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞–ª–∏:\n",
    "- –£–≤–µ–ª–∏—á–µ–Ω–∏–µ monthly_charges –Ω–∞ ~30%\n",
    "- –†–æ—Å—Ç —á–∏—Å–ª–∞ —Ç–∏–∫–µ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏\n",
    "- –°–º–µ—â–µ–Ω–∏–µ –∫ –º–µ—Å—è—á–Ω—ã–º –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º\n",
    "\n",
    "–≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏!\n",
    "\n",
    "### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ\n",
    "\n",
    "1. **CI/CD –¥–ª—è ML** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
    "2. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - —Ä–∞–Ω–Ω–µ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "3. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** - —Ç—Ä–∏–≥–≥–µ—Ä—ã –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –¥—Ä–∏—Ñ—Ç–µ\n",
    "\n",
    "### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è\n",
    "\n",
    "- **Kubernetes**: minikube, kind –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏\n",
    "- **Feature Store**: Feast, Tecton, Hopsworks\n",
    "- **Drift Detection**: Evidently, WhyLabs, Arize\n",
    "\n",
    "### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏\n",
    "\n",
    "- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CI/CD (GitHub Actions, GitLab CI)\n",
    "- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ production\n",
    "- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "- –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
