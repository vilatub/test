# –£—á–µ–±–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö –∏ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é

–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Python, –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```
.
‚îú‚îÄ‚îÄ notebooks/              # Jupyter notebooks —Å –∞–Ω–∞–ª–∏–∑–æ–º
‚îÇ   ‚îú‚îÄ‚îÄ titanic/           # –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¢–∏—Ç–∞–Ω–∏–∫
‚îÇ   ‚îî‚îÄ‚îÄ game_of_thrones/   # –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Game of Thrones
‚îú‚îÄ‚îÄ datasets/              # –î–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
‚îú‚îÄ‚îÄ models/                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ requirements.txt       # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îî‚îÄ‚îÄ README.md             # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## üéØ –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–∑–¥–∞–Ω –¥–ª—è **–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª–µ–π** –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
- –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª Data Science –ø—Ä–æ–µ–∫—Ç–∞
- –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (EDA)
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –∏ Feature Engineering
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- –û—Ü–µ–Ω–∫—É –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π

## üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã

### 1. –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¢–∏—Ç–∞–Ω–∏–∫
**–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** `notebooks/titanic/titanic_analysis.ipynb`

–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–Ω–∞–º–µ–Ω–∏—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –¢–∏—Ç–∞–Ω–∏–∫–∞.

**–ó–∞–¥–∞—á–∞:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫

**–ß—Ç–æ –≤–∫–ª—é—á–µ–Ω–æ:**
- –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (EDA)
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- Feature Engineering (—Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
- 6 —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- –û—Ü–µ–Ω–∫–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** Random Forest —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é ~82-85%

---

### 2. –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Game of Thrones
**–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** `notebooks/game_of_thrones/got_analysis.ipynb`

–ê–Ω–∞–ª–∏–∑ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤—Å–µ–ª–µ–Ω–Ω–æ–π "–ò–≥—Ä—ã –ü—Ä–µ—Å—Ç–æ–ª–æ–≤" –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ A Wiki of Ice and Fire.

**–ó–∞–¥–∞—á–∞:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å, –∫—Ç–æ –∏–∑ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —É–º—Ä–µ—Ç, –∞ –∫—Ç–æ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –≤ –∂–∏–≤—ã—Ö

**–ü—Ä–∏–∑–Ω–∞–∫–∏:**
- –°–æ—Ü–∏–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å –∏ –∑–Ω–∞—Ç–Ω–æ—Å—Ç—å
- –î–æ–º –∏ –∫—É–ª—å—Ç—É—Ä–∞
- –ü–æ—è–≤–ª–µ–Ω–∏—è –≤ –∫–Ω–∏–≥–∞—Ö
- –í–æ–∑—Ä–∞—Å—Ç –∏ –ø–æ–ª
- –°–µ–º–µ–π–Ω—ã–µ —Å–≤—è–∑–∏ (—Ä–æ–¥–∏—Ç–µ–ª–∏, —Å—É–ø—Ä—É–≥–∏, –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∏)
- –°—Ç–∞—Ç—É—Å —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ (–∂–∏–≤—ã/–º–µ—Ä—Ç–≤—ã)
- –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å –Ω–∞ –≤–∏–∫–∏

**–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è:** isAlive - –∂–∏–≤ –ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂

---

## üõ†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Python 3.8+
- pip –∏–ª–∏ conda

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

–ò–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º conda:

```bash
conda install --file requirements.txt
```

## üñ•Ô∏è –†–∞–±–æ—Ç–∞ –Ω–∞ Windows

**–í–∞–∂–Ω–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π Windows:** Jupyter Notebook –Ω–∞ Windows –º–æ–∂–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª—ã —Å Windows line endings (CRLF), —á—Ç–æ —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –≤ git.

üëâ **–°–º. –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é:** [WINDOWS_SETUP.md](WINDOWS_SETUP.md)

**–ö—Ä–∞—Ç–∫–∞—è –≤–µ—Ä—Å–∏—è:**
```bash
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ git (–æ–¥–∏–Ω —Ä–∞–∑)
git config core.autocrlf input

# Pre-commit hook –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç line endings
```

–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å `.gitattributes` –∏ pre-commit hook –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è —ç—Ç–æ–π –ø—Ä–æ–±–ª–µ–º—ã.

---

## üöÄ –ó–∞–ø—É—Å–∫

### –õ–æ–∫–∞–ª—å–Ω–æ —Å Jupyter Notebook

```bash
# –ó–∞–ø—É—Å–∫ Jupyter
jupyter notebook

# –ó–∞—Ç–µ–º –æ—Ç–∫—Ä–æ–π—Ç–µ –Ω—É–∂–Ω—ã–π –Ω–æ—É—Ç–±—É–∫ –∏–∑ –ø–∞–ø–∫–∏ notebooks/
```

### –í Google Colab

1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω—É–∂–Ω—ã–π `.ipynb` —Ñ–∞–π–ª –Ω–∞ Google Drive
2. –û—Ç–∫—Ä–æ–π—Ç–µ —Å –ø–æ–º–æ—â—å—é Google Colaboratory
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏ (Runtime ‚Üí Run all)

## üìö –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- **pandas** - —Ä–∞–±–æ—Ç–∞ —Å —Ç–∞–±–ª–∏—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
- **numpy** - —á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
- **matplotlib** - –±–∞–∑–æ–≤–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- **seaborn** - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- **scikit-learn** - –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- **jupyter** - –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ notebooks

## üéì –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å

–ö–∞–∂–¥—ã–π –Ω–æ—É—Ç–±—É–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç:
- ‚úÖ –ü–æ–¥—Ä–æ–±–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
- ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ –ü–æ—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞
- ‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤
- ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:
- üìñ –û–±—É—á–µ–Ω–∏—è Data Science —Å –Ω—É–ª—è
- üíº –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è–º
- üèÜ –£—á–∞—Å—Ç–∏—è –≤ Kaggle —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö
- üíª –°–æ–∑–¥–∞–Ω–∏—è –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ –ø—Ä–æ–µ–∫—Ç–æ–≤
- üë®‚Äçüè´ –ü—Ä–µ–ø–æ–¥–∞–≤–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö

## üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

### –î–ª—è –æ–±—É—á–µ–Ω–∏—è
1. –ß–∏—Ç–∞–π—Ç–µ –∫–æ–¥ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
2. –ó–∞–ø—É—Å–∫–∞–π—Ç–µ —è—á–µ–π–∫–∏ –∏ –∏–∑—É—á–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
3. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –¥—Ä—É–≥–∏—Ö –¥–∞–Ω–Ω—ã—Ö

### –î–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏
1. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –∫–æ–¥
2. –°–æ–∑–¥–∞–≤–∞–π—Ç–µ –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
3. –ü—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏
4. –£–ª—É—á—à–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

### –ö–∞–∫ —à–∞–±–ª–æ–Ω –¥–ª—è —Å–≤–æ–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–æ—É—Ç–±—É–∫–∞
2. –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –ø–æ–¥ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ
3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–µ –∂–µ —ç—Ç–∞–ø—ã –∞–Ω–∞–ª–∏–∑–∞
4. –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–≤–æ–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è

## üîÆ –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è

- [ ] –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Iris
- [ ] –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Boston Housing
- [ ] –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã (Time Series)
- [ ] NLP –ø—Ä–æ–µ–∫—Ç—ã
- [ ] Computer Vision –ø—Ä–∏–º–µ—Ä—ã
- [ ] –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã

## üìà –û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–∞–∂–¥–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞

–í—Å–µ –Ω–æ—É—Ç–±—É–∫–∏ —Å–ª–µ–¥—É—é—Ç –µ–¥–∏–Ω–æ–º—É —à–∞–±–ª–æ–Ω—É:

1. **–ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫** - –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
2. **–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö** - –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
3. **–ü–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä** - –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å –¥–∞–Ω–Ω—ã–º–∏
4. **–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤** - —Ä–∞–±–æ—Ç–∞ —Å missing values
5. **EDA** - –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
6. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è** - –≥—Ä–∞—Ñ–∏–∫–∏ –∏ –¥–∏–∞–≥—Ä–∞–º–º—ã
7. **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞** - –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
8. **Feature Engineering** - —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
9. **–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ** - –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
10. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ** - –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
11. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** - —Ç—é–Ω–∏–Ω–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
12. **–í—ã–≤–æ–¥—ã** - –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

## üó∫Ô∏è Roadmap —Ä–∞–∑–≤–∏—Ç–∏—è –ø—Ä–æ–µ–∫—Ç–∞

–ü–æ–¥—Ä–æ–±–Ω—ã–π –ø–ª–∞–Ω —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ —Å –ø–µ—Ä–µ—Ö–æ–¥–æ–º –æ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤ ML –∫ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

---

## üéØ –ú–∞—Ç—Ä–∏—Ü–∞ –º–µ—Ç–æ–¥–æ–≤ –∏ —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á

### –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–µ—Ç–æ–¥—ã

| –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç–æ–¥—ã | –ü–æ—á–µ–º—É –ø–æ–¥—Ö–æ–¥—è—Ç |
|------------|---------------------|-----------------|
| **–¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ** (Titanic, –∫—Ä–µ–¥–∏—Ç–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥) | XGBoost, LightGBM, CatBoost, Random Forest, Logistic Regression | –û—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤, —É—Å—Ç–æ–π—á–∏–≤—ã –∫ –≤—ã–±—Ä–æ—Å–∞–º, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã |
| **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è** | CNN (ResNet, EfficientNet, ViT) | –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ —Å–¥–≤–∏–≥–∞–º |
| **–¢–µ–∫—Å—Ç** | Transformers (BERT, GPT), RNN, LSTM | –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ, attention –º–µ—Ö–∞–Ω–∏–∑–º |
| **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã** | LSTM, GRU, ARIMA, Prophet, Temporal CNN | –£—á–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, —Ç—Ä–µ–Ω–¥—ã |
| **–ê—É–¥–∏–æ** | CNN (–¥–ª—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º), RNN, WaveNet | –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å + –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ |
| **–ì—Ä–∞—Ñ—ã** | GNN (Graph Neural Networks) | –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —É–∑–ª–∞–º |
| **–í–∏–¥–µ–æ** | 3D-CNN, CNN+RNN –≥–∏–±—Ä–∏–¥—ã, TimeSformer | –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã |

### –¢–∏–ø—ã –∑–∞–¥–∞—á –∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–µ—Ç–æ–¥—ã

| –ó–∞–¥–∞—á–∞ | –õ—É—á—à–∏–µ –º–µ—Ç–æ–¥—ã | –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å |
|--------|---------------|-----------------|
| **–ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö** | XGBoost, LightGBM, CatBoost, Logistic Regression | –ö—Ä–µ–¥–∏—Ç–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ |
| **–ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è** | Gradient Boosting, Random Forest, MLP | –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ |
| **–†–µ–≥—Ä–µ—Å—Å–∏—è** | XGBoost, LightGBM, Linear Regression, MLP | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã, –æ—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏, –ø—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ |
| **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π** | CNN (ResNet, EfficientNet), Vision Transformers | –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è, –∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ |
| **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π** | U-Net, Mask R-CNN, DeepLab | –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è, –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –≤–æ–∂–¥–µ–Ω–∏–µ, –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–æ–≤ |
| **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤** | YOLO, Faster R-CNN, RetinaNet | –í–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ, –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, –ø–æ–¥—Å—á–µ—Ç –æ–±—ä–µ–∫—Ç–æ–≤ |
| **–û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞** | BERT, GPT, RoBERTa, T5 | –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π |
| **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞** | GPT, T5, BART | –ß–∞—Ç-–±–æ—Ç—ã, —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è, –ø–µ—Ä–µ–≤–æ–¥ |
| **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤** | LSTM, Prophet, ARIMA, Temporal Fusion Transformer | –ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂, –±–∏—Ä–∂–µ–≤–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è |
| **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π** | Isolation Forest, Autoencoders, One-Class SVM | –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞, –¥–µ—Ñ–µ–∫—Ç–æ–≤, –∫–∏–±–µ—Ä–∞—Ç–∞–∫ |
| **–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è** | K-Means, DBSCAN, Hierarchical, GMM | –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤, –∞–Ω–∞–ª–∏–∑ –ø–æ–≤–µ–¥–µ–Ω–∏—è, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ |
| **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã** | Matrix Factorization, Neural Collaborative Filtering, Transformers | E-commerce, —Å—Ç—Ä–∏–º–∏–Ω–≥ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –ª–µ–Ω—Ç—ã |
| **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π** | GAN, VAE, Diffusion Models | –°–∏–Ω—Ç–µ–∑ –¥–∞–Ω–Ω—ã—Ö, –¥–∏–∑–∞–π–Ω, –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è |
| **–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º** | DQN, PPO, A3C | –ò–≥—Ä—ã, —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ |

### –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞

| –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ | –ü–æ—á–µ–º—É |
|---------------|--------------|--------|
| **–ú–∞–ª—ã–π** (< 1k –æ–±—Ä–∞–∑—Ü–æ–≤) | Logistic Regression, Decision Trees, k-NN, Transfer Learning | –ü—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏ —Å –º–µ–Ω—å—à–∏–º —Ä–∏—Å–∫–æ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è |
| **–°—Ä–µ–¥–Ω–∏–π** (1k - 100k) | Random Forest, Gradient Boosting, MLP | –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é –∏ –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é |
| **–ë–æ–ª—å—à–æ–π** (100k - 1M) | XGBoost, LightGBM, Deep Learning | –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –±–æ–ª—å—à–∏–º–∏ –æ–±—ä–µ–º–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö |
| **–û—á–µ–Ω—å –±–æ–ª—å—à–æ–π** (> 1M) | Deep Learning, LightGBM, Distributed ML | –ì–ª—É–±–æ–∫–∏–µ –º–æ–¥–µ–ª–∏ —Ä–∞—Å–∫—Ä—ã–≤–∞—é—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö |

### –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å vs –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

| –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç | –ú–µ—Ç–æ–¥—ã | Trade-off |
|-----------|--------|-----------|
| **–í—ã—Å–æ–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** | Logistic Regression, Decision Trees, Linear Regression, Rule-based | –õ–µ–≥–∫–æ –æ–±—ä—è—Å–Ω–∏—Ç—å, –Ω–æ –º–æ–∂–µ—Ç —É—Å—Ç—É–ø–∞—Ç—å –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ |
| **–°—Ä–µ–¥–Ω—è—è** | Random Forest, Gradient Boosting + SHAP/LIME | –•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å + –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ |
| **–ù–∏–∑–∫–∞—è** (—á–µ—Ä–Ω—ã–π —è—â–∏–∫) | Deep Neural Networks, Complex Ensembles | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ —Å–ª–æ–∂–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å |

### –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∏ inference

| –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ | –ú–µ—Ç–æ–¥—ã | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ |
|------------|--------|------------|
| **–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ** | Logistic Regression, Naive Bayes, LightGBM | –ë—ã—Å—Ç—Ä–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è, –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **–ë—ã—Å—Ç—Ä—ã–π inference** | Decision Trees, Linear Models, Distilled Models | Real-time –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, edge computing |
| **Batch processing** | Deep Learning, Gradient Boosting | –û—Ñ–ª–∞–π–Ω –∞–Ω–∞–ª–∏–∑ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö |

---

### üìä –§–∞–∑–∞ 1: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–µ ML (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í—ã—Å–æ–∫–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –û—Å–≤–æ–∏—Ç—å state-of-the-art –º–µ—Ç–æ–¥—ã –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–±–µ–∂–¥–∞—é—Ç –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ Kaggle —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º.

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- –ë–∏–Ω–∞—Ä–Ω–∞—è –∏ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –†–µ–≥—Ä–µ—Å—Å–∏—è (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
- –†–∞–±–æ—Ç–∞ —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏
- –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ (ranking tasks)

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- ‚úÖ –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
- ‚úÖ –°—Ä–µ–¥–Ω–∏–µ –∏ –±–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (1k+ –æ–±—Ä–∞–∑—Ü–æ–≤)
- ‚úÖ –¢—Ä–µ–±—É–µ—Ç—Å—è –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏
- ‚úÖ –ï—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- ‚ùå –ù–ï –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç–µ–∫—Å—Ç–∞, –∞—É–¥–∏–æ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏)

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** Gradient Boosting (XGBoost/LightGBM/CatBoost) - —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á –∏–º–µ–Ω–Ω–æ —ç—Ç–∏ –º–µ—Ç–æ–¥—ã –¥–∞—é—Ç –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

#### 1.1 –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥
- [ ] **XGBoost** - —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Random Forest
  - –¢—é–Ω–∏–Ω–≥ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (learning_rate, max_depth, n_estimators)
  - –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
  - Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- [ ] **LightGBM** - –±—ã—Å—Ç—Ä–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ XGBoost
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
  - –†–∞–±–æ—Ç–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –Ω–∞–ø—Ä—è–º—É—é
  - Histogram-based –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥
- [ ] **CatBoost** - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
  - Ordered boosting –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
  - Symmetric trees

#### 1.2 –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã
- [ ] **Stacking** - –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
  - –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ –∏–∑ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
  - Cross-validation –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
  - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
- [ ] **Blending** - –ø—Ä–æ—Å—Ç–æ–µ —Å–º–µ—à–∏–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
  - Weighted averaging —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
  - Voting classifier (hard –∏ soft voting)
  - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
- [ ] **Bagging** - —É–º–µ–Ω—å—à–µ–Ω–∏–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
  - Bootstrap aggregating
  - Out-of-bag –æ—Ü–µ–Ω–∫–∞

#### 1.3 –†–∞–±–æ—Ç–∞ —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
- [ ] **Oversampling**: SMOTE, ADASYN
- [ ] **Undersampling**: RandomUnderSampler, TomekLinks
- [ ] **–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã**: SMOTETomek
- [ ] **Class weights** - –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ loss —Ñ—É–Ω–∫—Ü–∏–∏
- [ ] **Threshold tuning** - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

#### 1.4 –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π Feature Engineering
- [ ] –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è)
- [ ] Target encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- [ ] Frequency encoding
- [ ] WoE (Weight of Evidence) encoding
- [ ] –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–µ–¥–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- [ ] –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π
- [ ] Feature selection (RFE, SelectKBest, Feature importance)

---

### üß† –§–∞–∑–∞ 2: –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ - –û—Å–Ω–æ–≤—ã (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í—ã—Å–æ–∫–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –ü–æ–Ω—è—Ç—å —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø—Ä–æ—Å—Ç—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Ö –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ—Ö–æ–¥–æ–º –∫ —Å–ª–æ–∂–Ω—ã–º.

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- **MLP:** –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä–µ–≥—Ä–µ—Å—Å–∏—è
- **CNN:** –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞—É–¥–∏–æ (—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã), —Å–∏–≥–Ω–∞–ª—ã, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã (1D-CNN)
- **Autoencoders:** –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π, –¥–µnoising, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- **MLP:** –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Gradient Boosting –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ–±—ã—á–Ω–æ —É—Å—Ç—É–ø–∞–µ—Ç, –Ω–æ –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π)
- **CNN:** ‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, ‚úÖ –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, ‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- **Autoencoders:** ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π, ‚úÖ –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, ‚úÖ –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** –ë–∞–∑–æ–≤—ã–µ –±–ª–æ–∫–∏, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å—Ç—Ä–æ—è—Ç—Å—è –≤—Å–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã. –ü–æ–Ω–∏–º–∞–Ω–∏–µ MLP, CNN –∏ Autoencoders –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Transformers, GAN, –∏ –¥—Ä—É–≥–∏–º–∏ —Å–ª–æ–∂–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.

#### 2.1 –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (FNN/MLP)
- [ ] **–ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¢–∏—Ç–∞–Ω–∏–∫–∞
  - Multi-Layer Perceptron —Å 2-3 —Å–∫—Ä—ã—Ç—ã–º–∏ —Å–ª–æ—è–º–∏
  - Batch normalization
  - Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
  - –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: ReLU, LeakyReLU, ELU
- [ ] **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**
  - Adam, AdamW, RMSprop –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã
  - Learning rate scheduling (ReduceLROnPlateau, CosineAnnealing)
  - Early stopping –∏ model checkpointing
- [ ] **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**
  - L1/L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
  - Dropout (—Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
  - Weight decay
  - Data augmentation –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

#### 2.2 –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (CNN)
- [ ] **1D-CNN –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**
  - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω–≤–æ–ª—é—Ü–∏–π –∫ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
  - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
- [ ] **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã**
  - –ü—Ä–æ—Å—Ç–∞—è CNN (2-3 —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—è)
  - ResNet-like skip connections –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  - Inception modules
- [ ] **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è**
  - Feature maps
  - Activation maps
  - Filter visualization

#### 2.3 –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—ã (Autoencoders)
- [ ] **Vanilla Autoencoder** - —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
  - –û–±—É—á–µ–Ω–∏–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å PCA
  - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- [ ] **Denoising Autoencoder** - –æ–±—É—á–µ–Ω–∏–µ —Ä–æ–±–∞—Å—Ç–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º
  - –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ –∫ –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º
  - –û—á–∏—Å—Ç–∫–∞ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
- [ ] **Variational Autoencoder (VAE)** - –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
  - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤
  - –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ
  - –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

---

### üìà –§–∞–∑–∞ 3: –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°—Ä–µ–¥–Ω–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –ù–∞—É—á–∏—Ç—å—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –≥–¥–µ –≤–∞–∂–µ–Ω –ø–æ—Ä—è–¥–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ (forecasting)
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (—Ç–µ–∫—Å—Ç, –º—É–∑—ã–∫–∞)
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ (seq2seq)

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- ‚úÖ **LSTM/GRU:** –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ä–µ–¥–Ω–µ–π –¥–ª–∏–Ω—ã (–¥–æ ~1000 —à–∞–≥–æ–≤), –∫–æ–≥–¥–∞ –≤–∞–∂–Ω—ã –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- ‚úÖ **ARIMA/SARIMA:** Univariate –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã —Å —á–µ—Ç–∫–∏–º–∏ —Ç—Ä–µ–Ω–¥–∞–º–∏ –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é
- ‚úÖ **Prophet:** –ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏ —Å –≥–æ–¥–∏—á–Ω–æ–π/–Ω–µ–¥–µ–ª—å–Ω–æ–π —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é, –ø—Ä–∞–∑–¥–Ω–∏–∫–∞–º–∏
- ‚ùå **–ù–ï –¥–ª—è:** –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Transformers), —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** –û–≥—Ä–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á —Å–≤—è–∑–∞–Ω–æ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏: —Ñ–∏–Ω–∞–Ω—Å—ã, IoT-—Å–µ–Ω—Å–æ—Ä—ã, –ª–æ–≥–∏—Å—Ç–∏–∫–∞, —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞, –º–µ–¥–∏—Ü–∏–Ω–∞. RNN/LSTM - –º–æ—Å—Ç –º–µ–∂–¥—É –ø—Ä–æ—Å—Ç—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ Transformers.

#### 3.1 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- [ ] **–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¢–∏—Ç–∞–Ω–∏–∫–∞ –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ**
  - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–±—ã—Ç–∏–π (boarding ‚Üí journey ‚Üí outcome)
  - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
  - –°–∏–º—É–ª—è—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —ç–≤–∞–∫—É–∞—Ü–∏–∏
- [ ] **–ù–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏**
  - **–ü–∞—Å—Å–∞–∂–∏—Ä–æ–ø–æ—Ç–æ–∫** - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤
  - **–¶–µ–Ω—ã –Ω–∞ –±–∏–ª–µ—Ç—ã** - –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
  - **–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—é—Ç** - –¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º–æ—Å—Ç–∏
  - **–ü–æ–≥–æ–¥–Ω—ã–µ —É—Å–ª–æ–≤–∏—è** - –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ä–µ–π—Å–æ–≤

#### 3.2 –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (RNN)
- [ ] **Vanilla RNN** - –±–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
  - –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
  - –ü—Ä–æ–±–ª–µ–º–∞ –∏—Å—á–µ–∑–∞—é—â–µ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞
  - –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø—Ä–æ—Å—Ç—ã—Ö RNN
- [ ] **LSTM (Long Short-Term Memory)**
  - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å gates (forget, input, output)
  - –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
  - Bidirectional LSTM
  - Stacked LSTM (–º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è)
- [ ] **GRU (Gated Recurrent Unit)**
  - –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å LSTM
  - –ú–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–µ–Ω–∏–µ
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ LSTM vs GRU
- [ ] **Attention –¥–ª—è RNN**
  - –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –≤ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–µ—Ç—è—Ö
  - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è attention weights
  - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–∞–∂–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤

#### 3.3 –ó–∞–¥–∞—á–∏ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö
- [ ] **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (Forecasting)**
  - Univariate forecasting - –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫
  - Multivariate forecasting - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
  - Multi-step ahead prediction
- [ ] **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π**
  - Seq-to-label (–≤—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Üí –º–µ—Ç–∫–∞)
  - Many-to-one –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- [ ] **Seq2Seq –º–æ–¥–µ–ª–∏**
  - Encoder-Decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
  - Sequence-to-sequence –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
  - Teacher forcing –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏

#### 3.4 –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
- [ ] **ARIMA/SARIMA** - –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
- [ ] **Prophet** (Facebook) - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] **Exponential Smoothing** - —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
- [ ] **Seasonal decomposition** - –∞–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏

---

### ü§ñ –§–∞–∑–∞ 4: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°—Ä–µ–¥–Ω–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –û—Å–≤–æ–∏—Ç—å cutting-edge –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–ª–∞ NLP –∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ –¥—Ä—É–≥–∏–µ –æ–±–ª–∞—Å—Ç–∏ (vision, —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã).

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- **NLP:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, NER, QA, –º–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
- **Computer Vision:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Vision Transformers)
- **–¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:** TabTransformer, FT-Transformer –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã:** Temporal Fusion Transformer, Informer
- **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å:** CLIP (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è), DALL-E

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- ‚úÖ **–¢–µ–∫—Å—Ç:** –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞ (BERT, GPT, T5)
- ‚úÖ **–î–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:** –õ—É—á—à–µ RNN –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ **–ë–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã:** Transformers —Ç—Ä–µ–±—É—é—Ç –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ **–¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (TabTransformer):** –ö–æ–≥–¥–∞ –µ—Å—Ç—å –º–Ω–æ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –¥–∞–Ω–Ω—ã—Ö
- ‚ùå **–ù–ï –¥–ª—è:** –ú–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (< 10k –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö, < 100k –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π), –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** Transformers - –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º ML. –ü–æ–Ω–∏–º–∞–Ω–∏–µ attention –º–µ—Ö–∞–Ω–∏–∑–º–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏. –î–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —ç—Ç–æ –ø–µ—Ä–µ–¥–æ–≤–æ–π –∫—Ä–∞–π –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π (—Ö–æ—Ç—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ —á–∞—Å—Ç–æ –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–µ—Ç Gradient Boosting).

#### 4.1 –ú–µ—Ö–∞–Ω–∏–∑–º Self-Attention
- [ ] **Scaled Dot-Product Attention**
  - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è
  - –í—ã—á–∏—Å–ª–µ–Ω–∏–µ Query, Key, Value
  - Softmax –¥–ª—è –≤–µ—Å–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è
  - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –≤–Ω–∏–º–∞–Ω–∏—è
- [ ] **Multi-Head Attention**
  - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≥–æ–ª–æ–≤—ã –≤–Ω–∏–º–∞–Ω–∏—è
  - –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –∏ –ø—Ä–æ–µ–∫—Ü–∏—è
  - –†–∞–∑–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- [ ] **Self-Attention –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**
  - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤
  - –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
  - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è attention weights

#### 4.2 Transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- [ ] **–ë–∞–∑–æ–≤—ã–π Transformer Encoder**
  - Positional encoding –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  - Layer normalization
  - Feed-forward —Å–µ—Ç–∏
  - Residual connections
- [ ] **Transformer –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¢–∏—Ç–∞–Ω–∏–∫–∞**
  - –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å MLP –∏ CNN
  - –ê–Ω–∞–ª–∏–∑ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
- [ ] **TabTransformer**
  - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Ç–∞–±–ª–∏—Ü
  - Embedding –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
  - Self-attention –Ω–∞–¥ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏

#### 4.3 –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—á–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã
- [ ] **FT-Transformer** (Feature Tokenizer)
  - –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Ç–æ–∫–µ–Ω—ã
  - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Transformer encoder
  - State-of-the-art –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- [ ] **SAINT** (Self-Attention and Intersample Attention)
  - –í–Ω–∏–º–∞–Ω–∏–µ –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏
  - Contrastive learning
- [ ] **TabNet** (Google)
  - Sequential attention
  - Feature selection –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ
  - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å

#### 4.4 Transfer Learning –∏ Pre-training
- [ ] **–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏**
  - Fine-tuning –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –¢–∏—Ç–∞–Ω–∏–∫–∞
  - Domain adaptation
- [ ] **Self-supervised learning**
  - Masked feature prediction
  - Contrastive learning –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- [ ] **Few-shot learning**
  - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–∞–ª–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–∏–º–µ—Ä–æ–≤

---

### üîç –§–∞–∑–∞ 5: –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°—Ä–µ–¥–Ω–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –ù–∞–π—Ç–∏ —Å–∫—Ä—ã—Ç—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã—è–≤–∏—Ç—å –Ω–µ–æ–±—ã—á–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏.

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞:** –ö—Ä–µ–¥–∏—Ç–Ω—ã–µ –∫–∞—Ä—Ç—ã, —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –ø—Ä–µ—Ç–µ–Ω–∑–∏–∏, –æ–Ω–ª–∞–π–Ω-—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
- **–ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç—å:** –ü—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
- **–ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:** –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—Ç–æ—Ä–∂–µ–Ω–∏–π, –∞–Ω–æ–º–∞–ª—å–Ω–æ–π —Å–µ—Ç–µ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
- **–ú–µ–¥–∏—Ü–∏–Ω–∞:** –í—ã—è–≤–ª–µ–Ω–∏–µ —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π, –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
- **Retail:** –ü–æ–∏—Å–∫ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª (market basket analysis)
- **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è:** –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤, –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- ‚úÖ **Isolation Forest, LOF:** –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–µ—Ç –º–µ—Ç–æ–∫ –∞–Ω–æ–º–∞–ª–∏–π
- ‚úÖ **Autoencoders:** –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- ‚úÖ **One-Class SVM:** –ö–æ–≥–¥–∞ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ "–Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ" –ø—Ä–∏–º–µ—Ä—ã
- ‚úÖ **LSTM-AE:** –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
- ‚úÖ **Association Rules:** –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ä–∑–∏–Ω—ã –ø–æ–∫—É–ø–æ–∫
- ‚úÖ **Clustering:** –ù–µ—Ç —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π, –Ω—É–∂–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** –í —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º - —ç—Ç–æ –Ω–µ –æ–±—ã—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è. –ê–Ω–æ–º–∞–ª–∏–∏ —Ä–µ–¥–∫–∏, –Ω–æ –∫—Ä–∏—Ç–∏—á–Ω—ã (–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–∏—Ç –º–∏–ª–ª–∏–∞—Ä–¥—ã). –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—é—Ç –∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –±–∏–∑–Ω–µ—Å-—Ä–µ—à–µ–Ω–∏–π.

#### 5.1 –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
- [ ] **Association Rules** (Apriori, FP-Growth)
  - –ü–æ–∏—Å–∫ —á–∞—Å—Ç—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
  - Support, Confidence, Lift –º–µ—Ç—Ä–∏–∫–∏
  - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–∞–≤–∏–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: "1st class + female ‚Üí survived")
- [ ] **Sequence Mining**
  - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Å–æ–±—ã—Ç–∏—è—Ö
  - GSP (Generalized Sequential Pattern) –∞–ª–≥–æ—Ä–∏—Ç–º
- [ ] **Clustering**
  - K-Means, DBSCAN, Hierarchical clustering
  - –ü–æ–∏—Å–∫ –≥—Ä—É–ø–ø –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤
  - –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

#### 5.2 –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π (Anomaly Detection)
- [ ] **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã**
  - Z-score, IQR –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤
  - Mahalanobis distance
  - Chi-square test
- [ ] **Isolation Forest**
  - –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ä–µ–¥–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
  - –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–∞—Å—Å–∞–∂–∏—Ä—ã (–Ω–µ–æ–±—ã—á–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
- [ ] **One-Class SVM**
  - –û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞ "–Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö" –¥–∞–Ω–Ω—ã—Ö
  - –í—ã—è–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
- [ ] **Autoencoders –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–π**
  - Reconstruction error –∫–∞–∫ –º–µ—Ç—Ä–∏–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏
  - Threshold tuning
  - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
- [ ] **Local Outlier Factor (LOF)**
  - –ü–ª–æ—Ç–Ω–æ—Å—Ç—å –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏
  - –õ–æ–∫–∞–ª—å–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã

#### 5.3 –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
- [ ] **Change Point Detection**
  - –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ä–µ–∑–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
  - CUSUM, PELT –∞–ª–≥–æ—Ä–∏—Ç–º—ã
- [ ] **LSTM-Autoencoders –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤**
  - –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
  - Multi-variate time series anomaly detection
- [ ] **Prophet –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–π**
  - –í—ã—è–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –æ—Ç —Ç—Ä–µ–Ω–¥–∞

#### 5.4 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
- [ ] **t-SNE, UMAP** - —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
  - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ 2D/3D –≥—Ä–∞—Ñ–∏–∫–∏
  - –¶–≤–µ—Ç–æ–≤–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏
- [ ] **Parallel Coordinates** - –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- [ ] **Sankey Diagrams** - –ø–æ—Ç–æ–∫–∏ –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
- [ ] **Network Graphs** - —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏

---

### üî¨ –§–∞–∑–∞ 6: –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ Explainable AI (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í—ã—Å–æ–∫–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –ü–æ–Ω—è—Ç—å, –ö–ê–ö –∏ –ü–û–ß–ï–ú–£ –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è —Ä–µ–≥—É–ª–∏—Ä—É–µ–º—ã—Ö –∏–Ω–¥—É—Å—Ç—Ä–∏–π –∏ –¥–æ–≤–µ—Ä–∏—è –∫ AI.

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- **–ú–µ–¥–∏—Ü–∏–Ω–∞:** –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–∏–∞–≥–Ω–æ–∑–∞ (GDPR, FDA —Ç—Ä–µ–±—É—é—Ç –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç–∏)
- **–§–∏–Ω–∞–Ω—Å—ã:** –ü–æ—á–µ–º—É –∫—Ä–µ–¥–∏—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω (–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ)
- **–ö—Ä–µ–¥–∏—Ç–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥:** –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞
- **–°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ:** –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–º–∏–∏
- **–†–µ–∫—Ä—É—Ç–∏–Ω–≥:** Fairness –∞–Ω–∞–ª–∏–∑ (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–∏)
- **–û—Ç–ª–∞–¥–∫–∞ –º–æ–¥–µ–ª–µ–π:** –ü–æ–∏—Å–∫ –æ—à–∏–±–æ–∫ –∏ bias
- **–ë–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç—ã:** –ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ –ø—Ä–æ–¥–∞–∂–∏/–æ—Ç—Ç–æ–∫

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- ‚úÖ **SHAP:** –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞ - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π, —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥
- ‚úÖ **LIME:** –ë—ã—Å—Ç—Ä—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ SHAP
- ‚úÖ **PDP/ICE:** –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- ‚úÖ **Feature Importance:** Tree-based –º–æ–¥–µ–ª–∏ (–≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)
- ‚úÖ **Attention Visualization:** Transformers (–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–≥–æ, –Ω–∞ —á—Ç–æ "—Å–º–æ—Ç—Ä–∏—Ç" –º–æ–¥–µ–ª—å)
- ‚ö†Ô∏è **Trade-off:** –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ (–ª–∏–Ω–µ–π–Ω—ã–µ, –¥–µ—Ä–µ–≤—å—è) vs —Ç–æ—á–Ω—ã–µ (deep learning)

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** "Black box" –º–æ–¥–µ–ª–∏ –Ω–µ–ø—Ä–∏–µ–º–ª–µ–º—ã –≤ —Ä–µ–≥—É–ª–∏—Ä—É–µ–º—ã—Ö –∏–Ω–¥—É—Å—Ç—Ä–∏—è—Ö (–º–µ–¥–∏—Ü–∏–Ω–∞, —Ñ–∏–Ω–∞–Ω—Å—ã). SHAP/LIME –ø–æ–∑–≤–æ–ª—è—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è production-—Å–∏—Å—Ç–µ–º, –≤–ª–∏—è—é—â–∏—Ö –Ω–∞ –ª—é–¥–µ–π.

#### 6.1 Model-Agnostic –º–µ—Ç–æ–¥—ã
- [ ] **SHAP (SHapley Additive exPlanations)**
  - TreeSHAP –¥–ª—è –¥—Ä–µ–≤–æ–≤–∏–¥–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
  - KernelSHAP –¥–ª—è –ª—é–±—ã—Ö –º–æ–¥–µ–ª–µ–π
  - DeepSHAP –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
  - Waterfall plots, force plots, summary plots
  - Dependence plots –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- [ ] **LIME (Local Interpretable Model-agnostic Explanations)**
  - –õ–æ–∫–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
  - –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å SHAP
- [ ] **Permutation Importance**
  - –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é
- [ ] **Partial Dependence Plots (PDP)**
  - –í–ª–∏—è–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
  - Individual Conditional Expectation (ICE) curves
  - 2D PDP –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π

#### 6.2 Model-Specific –º–µ—Ç–æ–¥—ã
- [ ] **Feature Importance** –∏–∑ –¥—Ä–µ–≤–æ–≤–∏–¥–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
  - Gini importance vs Permutation importance
  - Feature importance bias
- [ ] **Decision Tree Visualization**
  - –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª
  - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—É—Ç–µ–π
- [ ] **Linear Model Coefficients**
  - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–µ—Å–æ–≤ Logistic Regression
  - –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
- [ ] **Attention Visualization** –¥–ª—è Transformers
  - Heatmap –º–∞—Ç—Ä–∏—Ü—ã –≤–Ω–∏–º–∞–Ω–∏—è
  - –ö–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–∞–∂–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

#### 6.3 –ì–ª–æ–±–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
- [ ] **Model Distillation** - —É–ø—Ä–æ—â–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ–π –º–æ–¥–µ–ª–∏
  - –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö —Å–ª–æ–∂–Ω–æ–π
  - Decision tree –∫–∞–∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ç–æ—Ä
- [ ] **Rule Extraction** - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª
  - –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –Ω–∞–±–æ—Ä if-then –ø—Ä–∞–≤–∏–ª
- [ ] **Surrogate Models** - –∑–∞–º–µ–Ω–∞ –Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—É—é –º–æ–¥–µ–ª—å

#### 6.4 Fairness –∏ Bias Analysis
- [ ] **Demographic Parity** - —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å –ø–æ –≥—Ä—É–ø–ø–∞–º
  - –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –ø–æ–ª—É, –∫–ª–∞—Å—Å—É
  - Disparate Impact
- [ ] **Calibration Analysis** - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
- [ ] **Counterfactual Explanations**
  - "–ß—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å, —á—Ç–æ–±—ã –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ?"
  - DiCE, Alibi –∞–ª–≥–æ—Ä–∏—Ç–º—ã

#### 6.5 –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- [ ] **Interactive Dashboards** (Plotly Dash, Streamlit)
  - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ SHAP
  - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- [ ] **What-If Tool** - –∞–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
- [ ] **Model Cards** - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

---

### üöÄ –§–∞–∑–∞ 7: Production –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°—Ä–µ–¥–Ω–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ Jupyter Notebook –≤ production-ready —Å–∏—Å—Ç–µ–º—É, —Ä–∞–±–æ—Ç–∞—é—â—É—é 24/7 —Å –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –∑–∞–ø—Ä–æ—Å–æ–≤.

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- **Deployment:** –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ production (API, –æ–±–ª–∞–∫–æ, edge)
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- **Data Drift:** –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- **Model Drift:** –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
- **A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ production
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ:** –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
- **CI/CD –¥–ª—è ML:** –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –∏ deployment
- **–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ:** –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤, –¥–∞–Ω–Ω—ã—Ö, –º–æ–¥–µ–ª–µ–π

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- ‚úÖ **–í—Å–µ–≥–¥–∞** - –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–¥–µ—Ç –≤ production
- ‚ö†Ô∏è **API (FastAPI/Flask):** Web-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã
- ‚ö†Ô∏è **Docker:** –ò–∑–æ–ª—è—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è, –ø–æ—Ä—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å
- ‚ö†Ô∏è **–û–±–ª–∞–∫–æ (AWS/GCP/Azure):** –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ —Å–µ—Ä–≤–∏—Å—ã
- ‚ö†Ô∏è **MLflow/Wandb:** –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã, –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- ‚ö†Ô∏è **Monitoring (Evidently/Prometheus):** –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** 90% ML-–ø—Ä–æ–µ–∫—Ç–æ–≤ –Ω–µ –¥–æ—Ö–æ–¥—è—Ç –¥–æ production. –ü—Ä–∏—á–∏–Ω–∞ - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ MLOps –Ω–∞–≤—ã–∫–æ–≤. –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Data Scientist –∏ ML Engineer - —É–º–µ–Ω–∏–µ –¥–µ–ø–ª–æ–∏—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –º–æ–¥–µ–ª–∏. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è –∫–∞—Ä—å–µ—Ä—ã.

**‚ö†Ô∏è –†–µ–∞–ª—å–Ω–æ—Å—Ç—å:** –ú–æ–¥–µ–ª—å –≤ Jupyter - 10% —Ä–∞–±–æ—Ç—ã. Production-ready —Å–∏—Å—Ç–µ–º–∞ - 90% —Ä–∞–±–æ—Ç—ã.

#### 7.1 MLOps –∏ Pipeline
- [ ] **scikit-learn Pipeline**
  - –ü–æ–ª–Ω—ã–π pipeline –æ—Ç —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
  - ColumnTransformer –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
  - Custom transformers
- [ ] **Feature Store**
  - –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
  - Feast, Tecton
- [ ] **Experiment Tracking**
  - MLflow –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
  - Weights & Biases (wandb)
  - TensorBoard
- [ ] **Model Versioning**
  - DVC (Data Version Control)
  - Git –¥–ª—è –∫–æ–¥–∞ + DVC –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–µ–π

#### 7.2 Deployment
- [ ] **Model Serialization**
  - Pickle, Joblib –¥–ª—è sklearn
  - ONNX –¥–ª—è –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ—Å—Ç–∏
  - TorchScript –¥–ª—è PyTorch
  - SavedModel –¥–ª—è TensorFlow
- [ ] **REST API** –¥–ª—è –º–æ–¥–µ–ª–∏
  - FastAPI / Flask —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
  - Request validation —Å Pydantic
  - Async –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
- [ ] **Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è**
  - Dockerfile –¥–ª—è –º–æ–¥–µ–ª–∏
  - Multi-stage builds
  - Docker Compose –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- [ ] **Cloud Deployment**
  - AWS SageMaker
  - Google Cloud AI Platform
  - Azure ML
  - Heroku –¥–ª—è –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤

#### 7.3 –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
- [ ] **Model Performance Monitoring**
  - –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ production
  - Alerting –ø—Ä–∏ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏
- [ ] **Data Drift Detection**
  - Evidently AI –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–∏—Ñ—Ç–∞
  - KS-test, PSI (Population Stability Index)
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- [ ] **A/B Testing**
  - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ production
  - Statistical significance tests
- [ ] **Logging –∏ Debugging**
  - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏
  - Distributed tracing

#### 7.4 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- [ ] **Model Compression**
  - Pruning (—É–¥–∞–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤)
  - Quantization (—É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏)
  - Knowledge Distillation
- [ ] **Inference Optimization**
  - ONNX Runtime
  - TensorRT (NVIDIA)
  - OpenVINO (Intel)
  - Batch inference
- [ ] **Caching** - –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- [ ] **Parallel Processing** - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

#### 7.5 Testing –∏ CI/CD
- [ ] **Unit Tests** –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
  - pytest –¥–ª—è transformers, models
  - Mocking –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- [ ] **Integration Tests** - —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ pipeline
- [ ] **Model Tests**
  - Smoke tests (–±–∞–∑–æ–≤–∞—è —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å)
  - Performance tests (—Å–∫–æ—Ä–æ—Å—Ç—å inference)
  - Data validation tests
- [ ] **CI/CD Pipeline**
  - GitHub Actions / GitLab CI
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π deployment

---

### üìö –§–∞–∑–∞ 8: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ù–∏–∑–∫–∏–π)

**üéØ –î–ª—è —á–µ–≥–æ:** –†–∞—Å—à–∏—Ä–∏—Ç—å –∫—Ä—É–≥–æ–∑–æ—Ä –∏ –∏–∑—É—á–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ ML –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á.

**üíº –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏:**
- **Survival Analysis:** –ú–µ–¥–∏—Ü–∏–Ω–∞ (–≤—Ä–µ–º—è –¥–æ —Å–æ–±—ã—Ç–∏—è), –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
- **Causal Inference:** –û—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –∫–∞–º–ø–∞–Ω–∏–π, A/B —Ç–µ—Å—Ç–æ–≤
- **Meta-Learning:** Few-shot –æ–±—É—á–µ–Ω–∏–µ, transfer learning, AutoML
- **Federated Learning:** –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∏—Ö —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–∞—Ü–∏–∏ (privacy)
- **Online Learning:** –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Ç–æ–∫–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- **Active Learning:** –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- **NAS (Neural Architecture Search):** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

**üìà –ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å:**
- ‚úÖ **Survival Analysis:** –ö–æ–≥–¥–∞ –≤–∞–∂–Ω–æ –≤—Ä–µ–º—è –¥–æ —Å–æ–±—ã—Ç–∏—è, —Ü–µ–Ω–∑—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- ‚úÖ **Causal Inference:** –ù—É–∂–Ω–æ –ø–æ–Ω—è—Ç—å –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏, –∞ –Ω–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
- ‚úÖ **Meta-Learning:** –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –º–Ω–æ–≥–æ –∑–∞–¥–∞—á
- ‚úÖ **Federated Learning:** –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ, —Ñ–∏–Ω–∞–Ω—Å—ã (privacy constraints)
- ‚úÖ **Online Learning:** Streaming –¥–∞–Ω–Ω—ã–µ, concept drift
- ‚úÖ **Active Learning:** –†–∞–∑–º–µ—Ç–∫–∞ –¥–æ—Ä–æ–≥–∞—è, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤

**üèÜ –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ:** –≠—Ç–∏ —Ç–µ—Ö–Ω–∏–∫–∏ —Ä–µ—à–∞—é—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏. –î–ª—è senior-–ø–æ–∑–∏—Ü–∏–π —ç—Ç–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É—é—â–∏–π —Ñ–∞–∫—Ç–æ—Ä.

#### 8.1 –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏
- [ ] **Regression** - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–∞
- [ ] **Multi-task Learning** - –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–∂–∏–≤–∞–Ω–∏—è –∏ –∫–ª–∞—Å—Å–∞
- [ ] **Survival Analysis** - –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —Å–æ–±—ã—Ç–∏—è
  - Kaplan-Meier estimator
  - Cox Proportional Hazards model
- [ ] **Causal Inference** - –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏
  - Uplift modeling
  - Propensity score matching

#### 8.2 –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏
- [ ] **Meta-Learning** - –æ–±—É—á–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—é
- [ ] **Neural Architecture Search (NAS)**
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- [ ] **Federated Learning** - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- [ ] **Online Learning** - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Ç–æ–∫–µ –¥–∞–Ω–Ω—ã—Ö
- [ ] **Active Learning** - –≤—ã–±–æ—Ä –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏

#### 8.3 –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
- [ ] **Web-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ** (Streamlit/Gradio)
  - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
  - –ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö
  - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
- [ ] **Telegram/Discord –±–æ—Ç**
  - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä
- [ ] **Mobile App** - –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

#### 8.4 –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ
- [ ] **–ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ç—É—Ç–æ—Ä–∏–∞–ª—ã** –ø–æ –∫–∞–∂–¥–æ–π —Ñ–∞–∑–µ
- [ ] **–í–∏–¥–µ–æ-—É—Ä–æ–∫–∏** (YouTube)
- [ ] **Blog posts** —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
- [ ] **Kaggle Kernels** –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
- [ ] **Medium articles** –¥–ª—è –ø–æ–ø—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏

---

### üéØ –ü–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)

**–ö–æ—Ä–æ—Ç–∫–∏–π –ø—É—Ç—å (Quick Wins - 2-4 –Ω–µ–¥–µ–ª–∏):**
1. –§–∞–∑–∞ 1.1-1.2: XGBoost, LightGBM, CatBoost + Stacking ‚úÖ
2. –§–∞–∑–∞ 6.1: SHAP –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è ‚úÖ
3. –§–∞–∑–∞ 2.1: –ü—Ä–æ—Å—Ç–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å ‚úÖ
4. –§–∞–∑–∞ 7.1-7.2: –ë–∞–∑–æ–≤—ã–π deployment (API + Docker) ‚úÖ

**–°—Ä–µ–¥–Ω–∏–π –ø—É—Ç—å (Comprehensive - 2-3 –º–µ—Å—è—Ü–∞):**
1. –ü–æ–ª–Ω–∞—è –§–∞–∑–∞ 1: –í—Å–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã
2. –ü–æ–ª–Ω–∞—è –§–∞–∑–∞ 6: –í—Å—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
3. –§–∞–∑–∞ 2: Deep Learning –æ—Å–Ω–æ–≤—ã
4. –§–∞–∑–∞ 5.1-5.2: –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∞–Ω–æ–º–∞–ª–∏–∏
5. –§–∞–∑–∞ 7: Production-ready solution

**–î–ª–∏–Ω–Ω—ã–π –ø—É—Ç—å (Full Mastery - 6+ –º–µ—Å—è—Ü–µ–≤):**
- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∞–∑ 1-8
- –ì–ª—É–±–æ–∫–æ–µ –∏–∑—É—á–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π —Ç–µ—Ö–Ω–∏–∫–∏
- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –Ω–æ—É—Ç–±—É–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
- –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ —Ç—É—Ç–æ—Ä–∏–∞–ª—ã

---

### üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è

**–¢–µ–∫—É—â–∏–π:**
- pandas, numpy, matplotlib, seaborn, scikit-learn

**–î–ª—è –§–∞–∑—ã 1-2:**
- xgboost, lightgbm, catboost
- imbalanced-learn
- tensorflow / pytorch (–¥–ª—è Deep Learning)

**–î–ª—è –§–∞–∑—ã 3:**
- tensorflow / pytorch (LSTM, GRU)
- statsmodels (ARIMA)
- prophet

**–î–ª—è –§–∞–∑—ã 4:**
- pytorch (Transformers)
- huggingface transformers
- pytorch-tabular

**–î–ª—è –§–∞–∑—ã 5:**
- mlxtend (Association Rules)
- pyod (Anomaly Detection)
- umap-learn

**–î–ª—è –§–∞–∑—ã 6:**
- shap, lime
- alibi, dice-ml
- yellowbrick

**–î–ª—è –§–∞–∑—ã 7:**
- mlflow, wandb
- fastapi, flask
- docker
- evidently

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª—è—Ö –∏ —Å–≤–æ–±–æ–¥–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.

## ‚≠ê –ï—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –ø–æ–ª–µ–∑–µ–Ω

–ü–æ—Å—Ç–∞–≤—å—Ç–µ –∑–≤–µ–∑–¥—É –ø—Ä–æ–µ–∫—Ç—É, —á—Ç–æ–±—ã –¥—Ä—É–≥–∏–µ —Å—Ç—É–¥–µ–Ω—Ç—ã –º–æ–≥–ª–∏ –µ–≥–æ –Ω–∞–π—Ç–∏!

---

**–°–æ–∑–¥–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é:** Claude Code
**–í–µ—Ä—Å–∏—è:** 2.0
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025
