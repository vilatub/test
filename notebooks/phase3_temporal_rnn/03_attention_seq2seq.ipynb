{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Advanced RNN: Attention & Seq2Seq\n",
    "\n",
    "**Phase 3: Temporal Data & RNN - Step 3 (FINALE)**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ –¶–µ–ª–∏ –Ω–æ—É—Ç–±—É–∫–∞\n",
    "\n",
    "1. **Attention –º–µ—Ö–∞–Ω–∏–∑–º** –¥–ª—è RNN - —Ñ–æ–∫—É—Å –Ω–∞ –≤–∞–∂–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "2. **Seq2Seq –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** (Encoder-Decoder) –¥–ª—è multi-step forecasting\n",
    "3. **–ü—Ä–∞–∫—Ç–∏–∫–∞ –Ω–∞ PyTorch:** –ø–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å –Ω—É–ª—è\n",
    "4. **Multi-step ahead:** –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥\n",
    "5. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ:** Baseline LSTM vs LSTM+Attention vs Seq2Seq\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ –ü–æ—á–µ–º—É Attention –∏ Seq2Seq?\n",
    "\n",
    "**–ü—Ä–æ–±–ª–µ–º—ã –±–∞–∑–æ–≤–æ–≥–æ LSTM:**\n",
    "- ‚ùå –í—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–∂–∏–º–∞–µ—Ç—Å—è –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä (bottleneck)\n",
    "- ‚ùå –°–ª–æ–∂–Ω–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (–¥–∞–∂–µ —Å LSTM)\n",
    "- ‚ùå –û–¥–∏–Ω–∞–∫–æ–≤–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –∫–æ –≤—Å–µ–º —á–∞—Å—Ç—è–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "\n",
    "**–†–µ—à–µ–Ω–∏—è:**\n",
    "\n",
    "### üîç Attention Mechanism\n",
    "- ‚úÖ **–§–æ–∫—É—Å –Ω–∞ –≤–∞–∂–Ω–æ–º:** –º–æ–¥–µ–ª—å \"—Å–º–æ—Ç—Ä–∏—Ç\" –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞—Å—Ç–∏ –≤—Ö–æ–¥–∞\n",
    "- ‚úÖ **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞:** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–∞–∑–Ω—ã–µ —á–∞—Å—Ç–∏ –≤–∞–∂–Ω—ã\n",
    "- ‚úÖ **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:** –≤–∏–¥–∏–º, –∫—É–¥–∞ –º–æ–¥–µ–ª—å \"—Å–º–æ—Ç—Ä–∏—Ç\"\n",
    "\n",
    "### üîÑ Seq2Seq (Sequence-to-Sequence)\n",
    "- ‚úÖ **Multi-step forecasting:** –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –∑–∞ —Ä–∞–∑\n",
    "- ‚úÖ **Encoder-Decoder:** —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "- ‚úÖ **–ì–∏–±–∫–æ—Å—Ç—å:** —Ä–∞–∑–Ω–∞—è –¥–ª–∏–Ω–∞ –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞\n",
    "\n",
    "---\n",
    "\n",
    "## üìä –î–∞—Ç–∞—Å–µ—Ç: Airline Passengers\n",
    "\n",
    "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.\n",
    "\n",
    "**–ó–∞–¥–∞—á–∞:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ **3 –º–µ—Å—è—Ü–∞** –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö **12 –º–µ—Å—è—Ü–µ–≤**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö –ß–∞—Å—Ç—å 1: –¢–µ–æ—Ä–∏—è Attention\n",
    "\n",
    "### 1.1 –ü—Ä–æ–±–ª–µ–º–∞: Information Bottleneck\n",
    "\n",
    "**–ë–∞–∑–æ–≤—ã–π LSTM –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:**\n",
    "\n",
    "```\n",
    "–í—Ö–æ–¥: [x‚ÇÅ, x‚ÇÇ, ..., x‚ÇÅ‚ÇÇ]  (12 –º–µ—Å—è—Ü–µ–≤)\n",
    "         ‚Üì\n",
    "    LSTM Encoder\n",
    "         ‚Üì\n",
    "    h‚ÇÅ‚ÇÇ (–æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä!)  ‚Üê –í–°–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ó–î–ï–°–¨\n",
    "         ‚Üì\n",
    "    Prediction\n",
    "         ‚Üì\n",
    "       ≈∑‚ÇÅ‚ÇÉ\n",
    "```\n",
    "\n",
    "**–ü—Ä–æ–±–ª–µ–º–∞:** –í–µ–∫—Ç–æ—Ä $h_{12}$ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –í–°–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ 12 –º–µ—Å—è—Ü–∞—Ö!\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 –†–µ—à–µ–Ω–∏–µ: Attention Mechanism\n",
    "\n",
    "**–ò–¥–µ—è:** –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è \"—Å–º–æ—Ç—Ä–∏–º\" –Ω–∞ –í–°–ï —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —ç–Ω–∫–æ–¥–µ—Ä–∞.\n",
    "\n",
    "#### Attention —Ñ–æ—Ä–º—É–ª—ã\n",
    "\n",
    "–ü—É—Å—Ç—å $h_1, h_2, ..., h_T$ ‚Äî —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è encoder LSTM.  \n",
    "–î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —à–∞–≥–µ $t$ –¥–µ–∫–æ–¥–µ—Ä –∏–º–µ–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ $s_t$.\n",
    "\n",
    "**1. Attention scores (—ç–Ω–µ—Ä–≥–∏—è):**\n",
    "\n",
    "$$e_{ti} = \\text{score}(s_t, h_i)$$\n",
    "\n",
    "–≥–¥–µ `score` –º–æ–∂–µ—Ç –±—ã—Ç—å:\n",
    "- **Dot product:** $e_{ti} = s_t^T h_i$\n",
    "- **General:** $e_{ti} = s_t^T W h_i$\n",
    "- **Concat:** $e_{ti} = v^T \\tanh(W[s_t; h_i])$ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ—Ç)\n",
    "\n",
    "**2. Attention weights (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è):**\n",
    "\n",
    "$$\\alpha_{ti} = \\frac{\\exp(e_{ti})}{\\sum_{j=1}^{T} \\exp(e_{tj})}$$\n",
    "\n",
    "(softmax ‚Üí —Å—É–º–º–∞ –≤–µ—Å–æ–≤ = 1)\n",
    "\n",
    "**3. Context vector (–≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞):**\n",
    "\n",
    "$$c_t = \\sum_{i=1}^{T} \\alpha_{ti} h_i$$\n",
    "\n",
    "**4. –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:**\n",
    "\n",
    "$$\\tilde{s}_t = \\tanh(W_c [c_t; s_t])$$\n",
    "\n",
    "$$y_t = W_y \\tilde{s}_t$$\n",
    "\n",
    "---\n",
    "\n",
    "**–ò–Ω—Ç—É–∏—Ü–∏—è:**\n",
    "- $\\alpha_{ti}$ ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ –≤–∞–∂–µ–Ω $i$-–π —à–∞–≥ —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è $t$-–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "- $c_t$ ‚Äî –∫–æ–Ω—Ç–µ–∫—Å—Ç, —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞—Å—Ç—è—Ö\n",
    "- –ú–æ–¥–µ–ª—å —Å–∞–º–∞ **–æ–±—É—á–∞–µ—Ç—Å—è**, –∫—É–¥–∞ —Å–º–æ—Ç—Ä–µ—Ç—å!\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Attention\n",
    "\n",
    "**Heatmap attention weights:**\n",
    "\n",
    "```\n",
    "         Input timesteps ‚Üí\n",
    "         1  2  3  4  5  6  7  8  9 10 11 12\n",
    "Output ‚Üì\n",
    "  13  [0.1 0.1 0.1 0.2 0.1 0.1 0.2 0.05 0.02 0.01 0.01 0.01]\n",
    "  14  [0.05 0.05 0.1 0.15 0.2 0.15 0.1 0.1 0.05 0.02 0.02 0.01]\n",
    "  15  [0.02 0.02 0.05 0.1 0.15 0.2 0.15 0.1 0.1 0.05 0.03 0.03]\n",
    "```\n",
    "\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:** –ë–æ–ª–µ–µ —Å–≤–µ—Ç–ª—ã–µ —è—á–µ–π–∫–∏ = –º–æ–¥–µ–ª—å \"—Å–º–æ—Ç—Ä–∏—Ç\" —Ç—É–¥–∞ –±–æ–ª—å—à–µ.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Seq2Seq Architecture\n",
    "\n",
    "**Sequence-to-Sequence** ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∑–∞–¥–∞—á \"–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Üí –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\".\n",
    "\n",
    "#### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n",
    "\n",
    "**1. Encoder (–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫):**\n",
    "- –ß–∏—Ç–∞–µ—Ç –≤—Ö–æ–¥–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "- –°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ\n",
    "- –ú–æ–∂–µ—Ç –±—ã—Ç—å LSTM/GRU\n",
    "\n",
    "**2. Decoder (–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫):**\n",
    "- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤—ã—Ö–æ–¥–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç —ç–Ω–∫–æ–¥–µ—Ä–∞\n",
    "- –¢–æ–∂–µ LSTM/GRU\n",
    "\n",
    "**3. Attention (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ):**\n",
    "- –°–≤—è–∑—ã–≤–∞–µ—Ç —ç–Ω–∫–æ–¥–µ—Ä –∏ –¥–µ–∫–æ–¥–µ—Ä\n",
    "- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å\n",
    "\n",
    "---\n",
    "\n",
    "#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–µ–∑ Attention\n",
    "\n",
    "```\n",
    "ENCODER:\n",
    "x‚ÇÅ ‚Üí [LSTM] ‚Üí h‚ÇÅ\n",
    "x‚ÇÇ ‚Üí [LSTM] ‚Üí h‚ÇÇ\n",
    "...\n",
    "x‚ÇÅ‚ÇÇ ‚Üí [LSTM] ‚Üí h‚ÇÅ‚ÇÇ  (context vector)\n",
    "\n",
    "DECODER:\n",
    "h‚ÇÅ‚ÇÇ ‚Üí [LSTM] ‚Üí s‚ÇÅ ‚Üí y‚ÇÅ‚ÇÉ\n",
    "y‚ÇÅ‚ÇÉ ‚Üí [LSTM] ‚Üí s‚ÇÇ ‚Üí y‚ÇÅ‚ÇÑ  (autoregressive)\n",
    "y‚ÇÅ‚ÇÑ ‚Üí [LSTM] ‚Üí s‚ÇÉ ‚Üí y‚ÇÅ‚ÇÖ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å Attention\n",
    "\n",
    "```\n",
    "ENCODER:\n",
    "x‚ÇÅ ‚Üí [LSTM] ‚Üí h‚ÇÅ ‚îê\n",
    "x‚ÇÇ ‚Üí [LSTM] ‚Üí h‚ÇÇ ‚îÇ\n",
    "...              ‚îÇ ‚Üí All encoder states\n",
    "x‚ÇÅ‚ÇÇ ‚Üí [LSTM] ‚Üí h‚ÇÅ‚ÇÇ‚îò\n",
    "\n",
    "DECODER —Å ATTENTION:\n",
    "                  ‚îå‚îÄ Attention ‚îÄ‚îê\n",
    "                  ‚Üì              ‚Üì\n",
    "[h‚ÇÅ..h‚ÇÅ‚ÇÇ] ‚Üí c‚ÇÅ + s‚ÇÄ ‚Üí [LSTM] ‚Üí s‚ÇÅ ‚Üí y‚ÇÅ‚ÇÉ\n",
    "[h‚ÇÅ..h‚ÇÅ‚ÇÇ] ‚Üí c‚ÇÇ + s‚ÇÅ ‚Üí [LSTM] ‚Üí s‚ÇÇ ‚Üí y‚ÇÅ‚ÇÑ\n",
    "[h‚ÇÅ..h‚ÇÅ‚ÇÇ] ‚Üí c‚ÇÉ + s‚ÇÇ ‚Üí [LSTM] ‚Üí s‚ÇÉ ‚Üí y‚ÇÅ‚ÇÖ\n",
    "```\n",
    "\n",
    "–≥–¥–µ $c_i$ ‚Äî context vector —á–µ—Ä–µ–∑ attention.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5 Multi-step Forecasting\n",
    "\n",
    "**–ó–∞–¥–∞—á–∞:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ $N$ —à–∞–≥–æ–≤.\n",
    "\n",
    "**–ü–æ–¥—Ö–æ–¥—ã:**\n",
    "\n",
    "**1. Recursive (–∞–≤—Ç–æ—Ä —Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π):**\n",
    "```python\n",
    "y‚ÇÅ‚ÇÉ = model([x‚ÇÅ..x‚ÇÅ‚ÇÇ])\n",
    "y‚ÇÅ‚ÇÑ = model([x‚ÇÇ..x‚ÇÅ‚ÇÇ, y‚ÇÅ‚ÇÉ])\n",
    "y‚ÇÅ‚ÇÖ = model([x‚ÇÉ..x‚ÇÅ‚ÇÇ, y‚ÇÅ‚ÇÉ, y‚ÇÅ‚ÇÑ])\n",
    "```\n",
    "- ‚ö†Ô∏è –û—à–∏–±–∫–∏ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è\n",
    "\n",
    "**2. Direct (–º–Ω–æ–≥–æ–≤—ã—Ö–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å):**\n",
    "```python\n",
    "[y‚ÇÅ‚ÇÉ, y‚ÇÅ‚ÇÑ, y‚ÇÅ‚ÇÖ] = model([x‚ÇÅ..x‚ÇÅ‚ÇÇ])\n",
    "```\n",
    "- ‚úÖ –ù–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫\n",
    "- ‚ùå –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –≤—ã—Ö–æ–¥–∞–º–∏\n",
    "\n",
    "**3. Seq2Seq (–ª—É—á—à–∏–π):**\n",
    "```python\n",
    "# Encoder\n",
    "context = encoder([x‚ÇÅ..x‚ÇÅ‚ÇÇ])\n",
    "# Decoder (–∞–≤—Ç–æ—Ä —Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å attention)\n",
    "y‚ÇÅ‚ÇÉ = decoder(context, <start>)\n",
    "y‚ÇÅ‚ÇÑ = decoder(context, y‚ÇÅ‚ÇÉ)\n",
    "y‚ÇÅ‚ÇÖ = decoder(context, y‚ÇÅ‚ÇÑ)\n",
    "```\n",
    "- ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "- ‚úÖ Attention –∫–æ–º–ø–µ–Ω—Å–∏—Ä—É–µ—Ç –æ—à–∏–±–∫–∏\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª –ß–∞—Å—Ç—å 2: –ü—Ä–∞–∫—Ç–∏–∫–∞ - Attention & Seq2Seq –Ω–∞ PyTorch\n",
    "\n",
    "### 2.1 –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–∞–∑–æ–≤—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "try:\n",
    "    from statsmodels.datasets import get_rdataset\n",
    "    airline_data = get_rdataset('AirPassengers', 'datasets')\n",
    "    df = airline_data.data\n",
    "    df.columns = ['time', 'passengers']\n",
    "except:\n",
    "    url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "    df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "    df.columns = ['passengers']\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['time', 'passengers']\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "print(f\"–î–∞—Ç–∞—Å–µ—Ç: {df.shape[0]} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π\")\n",
    "print(f\"–ü–µ—Ä–∏–æ–¥: {df.index.min()} - {df.index.max()}\")\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(df.index, df['passengers'], linewidth=2)\n",
    "plt.title('Airline Passengers - Seq2Seq Multi-step Forecasting', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Passengers')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Seq2Seq\n",
    "\n",
    "**–û—Ç–ª–∏—á–∏–µ –æ—Ç –æ–±—ã—á–Ω–æ–≥–æ LSTM:**\n",
    "- –í—Ö–æ–¥: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, 12 –º–µ—Å—è—Ü–µ–≤)\n",
    "- –í—ã—Ö–æ–¥: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, 3 –º–µ—Å—è—Ü–∞)\n",
    "\n",
    "**–§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö:**\n",
    "- `X`: shape (n_samples, input_seq_len, 1)\n",
    "- `y`: shape (n_samples, output_seq_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq2seq_data(data, input_len=12, output_len=3):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è Seq2Seq: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Üí –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "    \n",
    "    Args:\n",
    "        data: –º–∞—Å—Å–∏–≤ numpy\n",
    "        input_len: –¥–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "        output_len: –¥–ª–∏–Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    \n",
    "    Returns:\n",
    "        X: shape (n_samples, input_len, 1)\n",
    "        y: shape (n_samples, output_len, 1)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(data) - input_len - output_len + 1):\n",
    "        # –í—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "        input_seq = data[i:i + input_len]\n",
    "        # –í—ã—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–ª–µ–¥—É—é—â–∏–µ output_len —Ç–æ—á–µ–∫)\n",
    "        output_seq = data[i + input_len:i + input_len + output_len]\n",
    "        \n",
    "        X.append(input_seq)\n",
    "        y.append(output_seq)\n",
    "    \n",
    "    X = np.array(X).reshape(-1, input_len, 1)\n",
    "    y = np.array(y).reshape(-1, output_len, 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "INPUT_SEQ_LEN = 12   # –∏—Å–ø–æ–ª—å–∑—É–µ–º 12 –º–µ—Å—è—Ü–µ–≤\n",
    "OUTPUT_SEQ_LEN = 3   # –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º 3 –º–µ—Å—è—Ü–∞\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "data = df['passengers'].values.astype(float)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_normalized = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Train/Test split\n",
    "train_size = int(len(data_normalized) * TRAIN_SIZE)\n",
    "train_data = data_normalized[:train_size]\n",
    "test_data = data_normalized[train_size - INPUT_SEQ_LEN:]  # overlap –¥–ª—è –ø–µ—Ä–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "X_train, y_train = create_seq2seq_data(train_data, INPUT_SEQ_LEN, OUTPUT_SEQ_LEN)\n",
    "X_test, y_test = create_seq2seq_data(test_data, INPUT_SEQ_LEN, OUTPUT_SEQ_LEN)\n",
    "\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"\\n–ü—Ä–∏–º–µ—Ä:\")\n",
    "print(f\"  –í—Ö–æ–¥ (12 –º–µ—Å—è—Ü–µ–≤): {X_train[0].flatten()[:5]}...\")\n",
    "print(f\"  –í—ã—Ö–æ–¥ (3 –º–µ—Å—è—Ü–∞): {y_train[0].flatten()}\")\n",
    "\n",
    "# PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "# DataLoader\n",
    "BATCH_SIZE = 8\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Attention Layer\n",
    "\n",
    "–†–µ–∞–ª–∏–∑—É–µ–º Bahdanau Attention (concat-based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bahdanau Attention (—Ç–∞–∫–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫ Additive Attention)\n",
    "    \n",
    "    e_ti = v^T tanh(W_1 h_i + W_2 s_t)\n",
    "    alpha_ti = softmax(e_ti)\n",
    "    c_t = sum(alpha_ti * h_i)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        \n",
    "        self.W1 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W2 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "    \n",
    "    def forward(self, encoder_outputs, decoder_hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder_outputs: (batch, seq_len, hidden_size)\n",
    "            decoder_hidden: (batch, hidden_size)\n",
    "        \n",
    "        Returns:\n",
    "            context: (batch, hidden_size)\n",
    "            attention_weights: (batch, seq_len)\n",
    "        \"\"\"\n",
    "        # –†–∞—Å—à–∏—Ä—è–µ–º decoder_hidden –¥–æ (batch, seq_len, hidden_size)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        decoder_hidden_expanded = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        # e = v^T tanh(W1*h + W2*s)\n",
    "        energy = torch.tanh(\n",
    "            self.W1(encoder_outputs) + self.W2(decoder_hidden_expanded)\n",
    "        )\n",
    "        attention_scores = self.v(energy).squeeze(-1)  # (batch, seq_len)\n",
    "        \n",
    "        # Normalize with softmax\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch, seq_len)\n",
    "        \n",
    "        # Compute context vector (weighted sum)\n",
    "        # c = sum(alpha_i * h_i)\n",
    "        context = torch.bmm(\n",
    "            attention_weights.unsqueeze(1),  # (batch, 1, seq_len)\n",
    "            encoder_outputs  # (batch, seq_len, hidden_size)\n",
    "        ).squeeze(1)  # (batch, hidden_size)\n",
    "        \n",
    "        return context, attention_weights\n",
    "\n",
    "print(\"‚úÖ BahdanauAttention —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Baseline: Simple LSTM Seq2Seq (–±–µ–∑ Attention)\n",
    "\n",
    "–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ–∑–¥–∞–¥–∏–º –ø—Ä–æ—Å—Ç–æ–π Seq2Seq –±–µ–∑ Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSeq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    –ë–∞–∑–æ–≤—ã–π Seq2Seq –±–µ–∑ Attention:\n",
    "    - Encoder —Å–∂–∏–º–∞–µ—Ç –≤—Ö–æ–¥ –≤ –æ–¥–∏–Ω context vector\n",
    "    - Decoder –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ context\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=64, output_size=1, \n",
    "                 num_layers=2, output_len=3):\n",
    "        super(SimpleSeq2Seq, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_len = output_len\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers,\n",
    "            batch_first=True, dropout=0.2 if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.LSTM(\n",
    "            output_size, hidden_size, num_layers,\n",
    "            batch_first=True, dropout=0.2 if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, target_len=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_len, input_size)\n",
    "            target_len: int (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç self.output_len)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        target_len = target_len or self.output_len\n",
    "        \n",
    "        # ENCODER\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "        \n",
    "        # DECODER (autoregressive)\n",
    "        decoder_input = torch.zeros(batch_size, 1, 1).to(x.device)\n",
    "        outputs = []\n",
    "        \n",
    "        for _ in range(target_len):\n",
    "            decoder_output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
    "            prediction = self.fc(decoder_output.squeeze(1))\n",
    "            outputs.append(prediction)\n",
    "            \n",
    "            # –°–ª–µ–¥—É—é—â–∏–π –≤—Ö–æ–¥ = —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "            decoder_input = prediction.unsqueeze(1)\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)  # (batch, target_len, 1)\n",
    "        return outputs\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "simple_seq2seq = SimpleSeq2Seq(\n",
    "    input_size=1,\n",
    "    hidden_size=64,\n",
    "    output_size=1,\n",
    "    num_layers=2,\n",
    "    output_len=OUTPUT_SEQ_LEN\n",
    ").to(device)\n",
    "\n",
    "print(\"Simple Seq2Seq (–±–µ–∑ Attention):\")\n",
    "print(simple_seq2seq)\n",
    "print(f\"\\n–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in simple_seq2seq.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Seq2Seq —Å Attention\n",
    "\n",
    "–ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Encoder-Decoder —Å Attention –º–µ—Ö–∞–Ω–∏–∑–º–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Seq2Seq —Å Bahdanau Attention:\n",
    "    - Encoder —Å–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π\n",
    "    - Decoder –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Attention –¥–ª—è —Ñ–æ–∫—É—Å–∞\n",
    "    - Context vector –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç—Å—è —Å decoder state\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=64, output_size=1,\n",
    "                 num_layers=2, output_len=3):\n",
    "        super(Seq2SeqAttention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_len = output_len\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers,\n",
    "            batch_first=True, dropout=0.2 if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Attention\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        \n",
    "        # Decoder (input = –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ + context)\n",
    "        self.decoder = nn.LSTM(\n",
    "            output_size + hidden_size,  # concatenate input and context\n",
    "            hidden_size, num_layers,\n",
    "            batch_first=True, dropout=0.2 if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Output layer (decoder hidden + context)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, target_len=None, return_attention=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_len, input_size)\n",
    "            target_len: int\n",
    "            return_attention: bool (–≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ attention weights)\n",
    "        \n",
    "        Returns:\n",
    "            outputs: (batch, target_len, output_size)\n",
    "            attention_weights: (batch, target_len, seq_len) –µ—Å–ª–∏ return_attention=True\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        target_len = target_len or self.output_len\n",
    "        \n",
    "        # ENCODER: –ø–æ–ª—É—á–∞–µ–º –í–°–ï —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(x)\n",
    "        # encoder_outputs: (batch, seq_len, hidden_size)\n",
    "        \n",
    "        # DECODER —Å ATTENTION\n",
    "        decoder_input = torch.zeros(batch_size, 1, 1).to(x.device)\n",
    "        outputs = []\n",
    "        attention_weights_list = []\n",
    "        \n",
    "        for t in range(target_len):\n",
    "            # 1. Attention: –≤—ã—á–∏—Å–ª—è–µ–º context vector\n",
    "            decoder_hidden = hidden[-1]  # –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π\n",
    "            context, attention_weights = self.attention(encoder_outputs, decoder_hidden)\n",
    "            \n",
    "            # 2. Concatenate decoder input and context\n",
    "            decoder_input_combined = torch.cat(\n",
    "                [decoder_input, context.unsqueeze(1)], dim=2\n",
    "            )  # (batch, 1, output_size + hidden_size)\n",
    "            \n",
    "            # 3. Decoder step\n",
    "            decoder_output, (hidden, cell) = self.decoder(\n",
    "                decoder_input_combined, (hidden, cell)\n",
    "            )\n",
    "            \n",
    "            # 4. Output prediction (decoder hidden + context)\n",
    "            combined = torch.cat([decoder_output.squeeze(1), context], dim=1)\n",
    "            prediction = self.fc(combined)\n",
    "            \n",
    "            outputs.append(prediction)\n",
    "            attention_weights_list.append(attention_weights)\n",
    "            \n",
    "            # 5. –°–ª–µ–¥—É—é—â–∏–π –≤—Ö–æ–¥ = —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "            decoder_input = prediction.unsqueeze(1)\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)  # (batch, target_len, output_size)\n",
    "        \n",
    "        if return_attention:\n",
    "            attention_weights_tensor = torch.stack(attention_weights_list, dim=1)\n",
    "            return outputs, attention_weights_tensor\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "seq2seq_attention = Seq2SeqAttention(\n",
    "    input_size=1,\n",
    "    hidden_size=64,\n",
    "    output_size=1,\n",
    "    num_layers=2,\n",
    "    output_len=OUTPUT_SEQ_LEN\n",
    ").to(device)\n",
    "\n",
    "print(\"Seq2Seq —Å Bahdanau Attention:\")\n",
    "print(seq2seq_attention)\n",
    "print(f\"\\n–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in seq2seq_attention.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è –ß–∞—Å—Ç—å 3: –û–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "\n",
    "### 3.1 –§—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(model, train_loader, criterion, optimizer, num_epochs=100, patience=15):\n",
    "    \"\"\"\n",
    "    –û–±—É—á–µ–Ω–∏–µ Seq2Seq –º–æ–¥–µ–ª–∏\n",
    "    \"\"\"\n",
    "    history = {'train_loss': []}\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_seq2seq(model, X, y, scaler):\n",
    "    \"\"\"\n",
    "    –û—Ü–µ–Ω–∫–∞ Seq2Seq –º–æ–¥–µ–ª–∏\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X).cpu().numpy()\n",
    "    \n",
    "    # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    y_true = scaler.inverse_transform(y.cpu().numpy().reshape(-1, 1))\n",
    "    y_pred = scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "    \n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # Reshape –æ–±—Ä–∞—Ç–Ω–æ –≤ (n_samples, output_len)\n",
    "    y_true_seq = y_true.reshape(-1, OUTPUT_SEQ_LEN)\n",
    "    y_pred_seq = y_pred.reshape(-1, OUTPUT_SEQ_LEN)\n",
    "    \n",
    "    return y_pred_seq, y_true_seq, rmse, mae\n",
    "\n",
    "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 20\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Training Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input sequence length: {INPUT_SEQ_LEN}\")\n",
    "print(f\"Output sequence length: {OUTPUT_SEQ_LEN}\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Simple Seq2Seq\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Simple Seq2Seq (–±–µ–∑ Attention)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "simple_optimizer = optim.Adam(simple_seq2seq.parameters(), lr=LEARNING_RATE)\n",
    "simple_history = train_seq2seq(simple_seq2seq, train_loader, criterion, \n",
    "                               simple_optimizer, NUM_EPOCHS, PATIENCE)\n",
    "\n",
    "simple_pred, simple_true, simple_rmse, simple_mae = evaluate_seq2seq(\n",
    "    simple_seq2seq, X_test_tensor, y_test_tensor, scaler\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Simple Seq2Seq:\")\n",
    "print(f\"   RMSE: {simple_rmse:.2f}\")\n",
    "print(f\"   MAE: {simple_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Seq2Seq with Attention\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Seq2Seq —Å Attention\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "attention_optimizer = optim.Adam(seq2seq_attention.parameters(), lr=LEARNING_RATE)\n",
    "attention_history = train_seq2seq(seq2seq_attention, train_loader, criterion,\n",
    "                                  attention_optimizer, NUM_EPOCHS, PATIENCE)\n",
    "\n",
    "attention_pred, attention_true, attention_rmse, attention_mae = evaluate_seq2seq(\n",
    "    seq2seq_attention, X_test_tensor, y_test_tensor, scaler\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Seq2Seq + Attention:\")\n",
    "print(f\"   RMSE: {attention_rmse:.2f}\")\n",
    "print(f\"   MAE: {attention_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Attention Weights\n",
    "\n",
    "**–°–∞–º–æ–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ:** –ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫—É–¥–∞ –º–æ–¥–µ–ª—å \"—Å–º–æ—Ç—Ä–∏—Ç\" –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª—É—á–∞–µ–º attention weights –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞\n",
    "seq2seq_attention.eval()\n",
    "with torch.no_grad():\n",
    "    sample_idx = 0\n",
    "    sample_input = X_test_tensor[sample_idx:sample_idx+1]\n",
    "    sample_output, sample_attention = seq2seq_attention(\n",
    "        sample_input, return_attention=True\n",
    "    )\n",
    "\n",
    "# Attention weights: (1, output_len, input_len)\n",
    "attention_weights = sample_attention.cpu().numpy()[0]\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(\n",
    "    attention_weights,\n",
    "    cmap='YlOrRd',\n",
    "    xticklabels=[f't-{INPUT_SEQ_LEN-i}' for i in range(INPUT_SEQ_LEN)],\n",
    "    yticklabels=[f't+{i+1}' for i in range(OUTPUT_SEQ_LEN)],\n",
    "    cbar_kws={'label': 'Attention Weight'},\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "plt.title('Attention Weights Heatmap\\n' + \n",
    "          '–°—Ç—Ä–æ–∫–∏ = –≤—ã—Ö–æ–¥–Ω—ã–µ —à–∞–≥–∏, –°—Ç–æ–ª–±—Ü—ã = –≤—Ö–æ–¥–Ω—ã–µ —à–∞–≥–∏',\n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Input Time Steps', fontsize=12)\n",
    "plt.ylabel('Output Time Steps', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è Attention:\")\n",
    "print(\"  - –ë–æ–ª–µ–µ —Å–≤–µ—Ç–ª—ã–µ —è—á–µ–π–∫–∏ = –º–æ–¥–µ–ª—å —É–¥–µ–ª—è–µ—Ç –±–æ–ª—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è\")\n",
    "print(\"  - –î–ª—è t+1: –º–æ–¥–µ–ª—å —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —à–∞–≥–∏ (–Ω–µ–¥–∞–≤–Ω–µ–µ –ø—Ä–æ—à–ª–æ–µ)\")\n",
    "print(\"  - –î–ª—è t+2, t+3: –º–æ–∂–µ—Ç —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —Å–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (12 –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥)\")\n",
    "print(\"  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—É—á–∞–µ—Ç—Å—è —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞—Å—Ç—è—Ö!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–¥—Ö–æ–¥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(simple_history['train_loss'], label='Simple Seq2Seq', linewidth=2)\n",
    "plt.plot(attention_history['train_loss'], label='Seq2Seq + Attention', linewidth=2)\n",
    "plt.title('Training Loss Comparison', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Attention –º–æ–¥–µ–ª—å —Å—Ö–æ–¥–∏—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ –∏ –∫ –º–µ–Ω—å—à–µ–º—É loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions visualization\n",
    "# –í—ã–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "num_examples = 3\n",
    "\n",
    "fig, axes = plt.subplots(num_examples, 1, figsize=(14, 4*num_examples))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    ax = axes[i] if num_examples > 1 else axes\n",
    "    \n",
    "    # –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "    true_vals = simple_true[i]\n",
    "    \n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "    simple_vals = simple_pred[i]\n",
    "    attention_vals = attention_pred[i]\n",
    "    \n",
    "    # X-axis\n",
    "    x = np.arange(OUTPUT_SEQ_LEN)\n",
    "    \n",
    "    ax.plot(x, true_vals, 'o-', label='True', linewidth=3, markersize=8, color='black')\n",
    "    ax.plot(x, simple_vals, 's--', label='Simple Seq2Seq', linewidth=2, markersize=6)\n",
    "    ax.plot(x, attention_vals, '^--', label='Seq2Seq + Attention', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax.set_title(f'Multi-step Forecast Example {i+1}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Future Time Steps', fontsize=12)\n",
    "    ax.set_ylabel('Passengers', fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f't+{j+1}' for j in x])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Attention –º–æ–¥–µ–ª—å –æ–±—ã—á–Ω–æ —Ç–æ—á–Ω–µ–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ –¥–∞–ª—å–Ω–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—Ö (t+2, t+3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Simple Seq2Seq', 'Seq2Seq + Attention'],\n",
    "    'RMSE': [simple_rmse, attention_rmse],\n",
    "    'MAE': [simple_mae, attention_mae],\n",
    "    'Parameters': [\n",
    "        sum(p.numel() for p in simple_seq2seq.parameters()),\n",
    "        sum(p.numel() for p in seq2seq_attention.parameters())\n",
    "    ],\n",
    "    'Attention': ['‚ùå', '‚úÖ']\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-STEP FORECASTING COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Bar plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "comparison_df.plot(x='Model', y='RMSE', kind='bar', ax=axes[0], \n",
    "                   legend=False, color='steelblue')\n",
    "axes[0].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('RMSE', fontsize=12)\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "comparison_df.plot(x='Model', y='MAE', kind='bar', ax=axes[1], \n",
    "                   legend=False, color='coral')\n",
    "axes[1].set_title('MAE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('MAE', fontsize=12)\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì –í—ã–≤–æ–¥—ã: Phase 3 Complete\n",
    "\n",
    "### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Advanced RNN\n",
    "\n",
    "**Attention –º–µ—Ö–∞–Ω–∏–∑–º:**\n",
    "- ‚úÖ **–£–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å** –Ω–∞ multi-step forecasting\n",
    "- ‚úÖ **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:** –≤–∏–¥–∏–º, –∫—É–¥–∞ –º–æ–¥–µ–ª—å —Å–º–æ—Ç—Ä–∏—Ç\n",
    "- ‚úÖ **–ì–∏–±–∫–æ—Å—Ç—å:** –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ñ–æ–∫—É—Å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –≤—Ö–æ–¥–∞\n",
    "- ‚ö†Ô∏è **–ë–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** ‚Üí —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**Seq2Seq –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**\n",
    "- ‚úÖ **–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è** –¥–ª—è multi-step forecasting\n",
    "- ‚úÖ **Encoder-Decoder** —Ä–∞–∑–¥–µ–ª—è–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é\n",
    "- ‚úÖ **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è** –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "- ‚ùå **–°–ª–æ–∂–Ω–µ–µ** –æ–±—É—á–∞—Ç—å, —á–µ–º –ø—Ä–æ—Å—Ç–æ–π LSTM\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ –ò—Ç–æ–≥–∏ Phase 3: Temporal Data & RNN\n",
    "\n",
    "–ú—ã –ø—Ä–æ—à–ª–∏ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –æ—Ç –∫–ª–∞—Å—Å–∏–∫–∏ –∫ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ—Ç–æ–¥–∞–º:\n",
    "\n",
    "#### Step 1: Classical Time Series\n",
    "- **ARIMA/SARIMA:** —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏, –æ—Ç–ª–∏—á–Ω–æ –Ω–∞ –º–∞–ª—ã—Ö univariate –¥–∞–Ω–Ω—ã—Ö\n",
    "- **Prophet:** –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è, –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏, –ø—Ä–∞–∑–¥–Ω–∏–∫–∏\n",
    "- **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** < 1000 —Ç–æ—á–µ–∫, —á–µ—Ç–∫–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –Ω—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è\n",
    "\n",
    "#### Step 2: RNN/LSTM/GRU\n",
    "- **Vanilla RNN:** –ø—Ä–æ–±–ª–µ–º–∞ vanishing gradient\n",
    "- **LSTM:** —Ä–µ—à–∞–µ—Ç long-term dependencies —á–µ—Ä–µ–∑ gates\n",
    "- **GRU:** –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
    "- **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** > 1000 —Ç–æ—á–µ–∫, multivariate, –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
    "\n",
    "#### Step 3: Attention & Seq2Seq (—Å–µ–≥–æ–¥–Ω—è)\n",
    "- **Attention:** –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å –Ω–∞ –≤–∞–∂–Ω—ã—Ö —á–∞—Å—Ç—è—Ö\n",
    "- **Seq2Seq:** multi-step forecasting, encoder-decoder\n",
    "- **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, multi-step ahead, –Ω—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Practical Decision Tree\n",
    "\n",
    "**–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:**\n",
    "\n",
    "```\n",
    "START\n",
    "  ‚Üì\n",
    "–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö?\n",
    "  ‚îú‚îÄ < 500 —Ç–æ—á–µ–∫ ‚Üí ARIMA/SARIMA/Prophet\n",
    "  ‚îî‚îÄ > 500 —Ç–æ—á–µ–∫ ‚Üí ‚Üì\n",
    "       ‚Üì\n",
    "Univariate –∏–ª–∏ Multivariate?\n",
    "  ‚îú‚îÄ Univariate ‚Üí SARIMA vs LSTM (–ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±–∞)\n",
    "  ‚îî‚îÄ Multivariate ‚Üí LSTM/GRU\n",
    "       ‚Üì\n",
    "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è?\n",
    "  ‚îú‚îÄ 1 —à–∞–≥ (t+1) ‚Üí Simple LSTM\n",
    "  ‚îî‚îÄ –ú–Ω–æ–≥–æ —à–∞–≥–æ–≤ (t+1..t+N) ‚Üí Seq2Seq\n",
    "       ‚Üì\n",
    "–ù—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è?\n",
    "  ‚îú‚îÄ –î–∞ ‚Üí Seq2Seq + Attention\n",
    "  ‚îî‚îÄ –ù–µ—Ç ‚Üí –ü—Ä–æ—Å—Ç–æ–π Seq2Seq –±—ã—Å—Ç—Ä–µ–µ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ –ß—Ç–æ –¥–∞–ª—å—à–µ? Phase 4: Transformers\n",
    "\n",
    "**–ü—Ä–æ–±–ª–µ–º—ã RNN (–¥–∞–∂–µ —Å Attention):**\n",
    "- ‚ùå –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–º–µ–¥–ª–µ–Ω–Ω–æ)\n",
    "- ‚ùå –°–ª–æ–∂–Ω–æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–æ–≤–∞—Ç—å\n",
    "- ‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "\n",
    "**–†–µ—à–µ–Ω–∏–µ: Transformers**\n",
    "- ‚úÖ **Self-Attention:** –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "- ‚úÖ **Positional Encoding:** –ø–æ—Ä—è–¥–æ–∫ –±–µ–∑ —Ä–µ–∫—É—Ä—Å–∏–∏\n",
    "- ‚úÖ **Scalable:** –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –æ–≥—Ä–æ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**Transformers –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:**\n",
    "- Temporal Fusion Transformer (Google)\n",
    "- Informer (–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ)\n",
    "- TabTransformer (—Ç–∞–±–ª–∏—á–Ω—ã–µ + –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)\n",
    "\n",
    "**Transformers –¥–ª—è NLP/Vision:**\n",
    "- BERT, GPT (—Ç–µ–∫—Å—Ç)\n",
    "- Vision Transformer (ViT)\n",
    "- CLIP (–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å)\n",
    "\n",
    "---\n",
    "\n",
    "### üí° –ö–ª—é—á–µ–≤—ã–µ —É—Ä–æ–∫–∏ Phase 3\n",
    "\n",
    "**1. –ù–µ –≤—Å–µ–≥–¥–∞ —Å–ª–æ–∂–Ω–æ–µ = –ª—É—á—à–µ–µ**\n",
    "- SARIMA —á–∞—Å—Ç–æ –ø–æ–±–µ–∂–¥–∞–µ—Ç LSTM –Ω–∞ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ, —É—Å–ª–æ–∂–Ω—è–π—Ç–µ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "\n",
    "**2. Attention = –º–æ—â—å + –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**\n",
    "- –£–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å\n",
    "- –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –ö–ê–ö –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è\n",
    "- –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è production –≤ —Ä–µ–≥—É–ª–∏—Ä—É–µ–º—ã—Ö –∏–Ω–¥—É—Å—Ç—Ä–∏—è—Ö\n",
    "\n",
    "**3. Multi-step forecasting ‚â† –º–Ω–æ–≥–æ 1-step –º–æ–¥–µ–ª–µ–π**\n",
    "- Seq2Seq —É—á–∏—Ç—ã–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –≤—ã—Ö–æ–¥–∞–º–∏\n",
    "- –ú–µ–Ω—å—à–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫\n",
    "\n",
    "**4. –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –≤–∞–∂–µ–Ω**\n",
    "- Deep Learning —Ç—Ä–µ–±—É–µ—Ç –¥–∞–Ω–Ω—ã—Ö\n",
    "- < 1k —Ç–æ—á–µ–∫: –∫–ª–∞—Å—Å–∏–∫–∞\n",
    "- > 10k —Ç–æ—á–µ–∫: DL –Ω–∞—á–∏–Ω–∞–µ—Ç –ø–æ–±–µ–∂–¥–∞—Ç—å\n",
    "\n",
    "---\n",
    "\n",
    "### üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
    "\n",
    "**Attention –º–µ—Ö–∞–Ω–∏–∑–º:**\n",
    "- [\"Attention Is All You Need\" (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762)\n",
    "- [\"Neural Machine Translation by Jointly Learning to Align and Translate\" (Bahdanau et al., 2014)](https://arxiv.org/abs/1409.0473)\n",
    "- [Visualizing Attention (distill.pub)](https://distill.pub/2016/augmented-rnns/)\n",
    "\n",
    "**Seq2Seq:**\n",
    "- [\"Sequence to Sequence Learning\" (Sutskever et al., 2014)](https://arxiv.org/abs/1409.3215)\n",
    "- [PyTorch Seq2Seq Tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "**Time Series Forecasting:**\n",
    "- [\"Temporal Fusion Transformers\" (Google, 2021)](https://arxiv.org/abs/1912.09363)\n",
    "- [\"Deep Learning for Time Series Forecasting\" (Januschowski et al., 2020)](https://arxiv.org/abs/2004.10240)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Phase 3: Temporal Data & RNN - COMPLETE!**\n",
    "\n",
    "**–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è:**\n",
    "- ‚úÖ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã: ARIMA, SARIMA, Prophet\n",
    "- ‚úÖ –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏: RNN, LSTM, GRU\n",
    "- ‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏: Attention, Seq2Seq\n",
    "- ‚úÖ Multi-step forecasting\n",
    "- ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å —á–µ—Ä–µ–∑ Attention\n",
    "\n",
    "**Next Phase:** Transformers –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}