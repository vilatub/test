#!/usr/bin/env python3
"""
Phase 7: Production & MLOps - Part 2
Model Serialization & FastAPI Development
"""

import json

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π notebook
notebook_path = '/home/user/test/notebooks/phase7_production_mlops/01_production_mlops.ipynb'
with open(notebook_path, 'r', encoding='utf-8') as f:
    notebook = json.load(f)

cells = notebook['cells']

# ============================================================================
# MODEL SERIALIZATION
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "---\n",
        "\n",
        "## üì¶ –ß–∞—Å—Ç—å 3: Model Serialization\n",
        "\n",
        "### –ó–∞—á–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å?\n",
        "\n",
        "1. **Persistence:** –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∑–¥–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "2. **Deployment:** –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –≤ production —Å–µ—Ä–≤–∏—Å\n",
        "3. **Sharing:** –ü–µ—Ä–µ–¥–∞—Ç—å –º–æ–¥–µ–ª—å –¥—Ä—É–≥–æ–π –∫–æ–º–∞–Ω–¥–µ\n",
        "4. **Versioning:** –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–∞–∑–Ω—ã–µ –≤–µ—Ä—Å–∏–∏\n",
        "\n",
        "### –§–æ—Ä–º–∞—Ç—ã —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏:\n",
        "\n",
        "| –§–æ—Ä–º–∞—Ç | Pros | Cons | Use Case |\n",
        "|--------|------|------|----------|\n",
        "| **Pickle** | Simple, native Python | Security risks, version issues | Quick prototypes |\n",
        "| **Joblib** | Efficient for numpy arrays | Python-only | Sklearn models |\n",
        "| **ONNX** | Cross-platform, optimized | Limited model support | Production inference |\n",
        "| **MLflow** | Full lineage, metadata | Heavier | Full MLOps pipeline |\n",
        "\n",
        "---\n"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "print(\"=\" * 70)\n",
        "print(\"MODEL SERIALIZATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# –í—ã–±–µ—Ä–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (–∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—é—é trained)\n",
        "best_model = gb  # Gradient Boosting\n",
        "model_name = \"churn_predictor\"\n",
        "\n",
        "# Create directory for models\n",
        "import os\n",
        "model_dir = \"./models\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# ========================================\n",
        "# 1. Pickle\n",
        "# ========================================\n",
        "print(\"\\n[1/3] Pickle serialization\")\n",
        "pickle_path = f\"{model_dir}/{model_name}.pkl\"\n",
        "\n",
        "with open(pickle_path, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "pickle_size = os.path.getsize(pickle_path) / 1024  # KB\n",
        "print(f\"‚úÖ Saved: {pickle_path}\")\n",
        "print(f\"   Size: {pickle_size:.2f} KB\")\n",
        "\n",
        "# Load and verify\n",
        "with open(pickle_path, 'rb') as f:\n",
        "    loaded_pickle = pickle.load(f)\n",
        "    \n",
        "pickle_pred = loaded_pickle.predict(X_test_scaled.iloc[:5])\n",
        "print(f\"   Verification: {pickle_pred}\")\n",
        "\n",
        "# ========================================\n",
        "# 2. Joblib (better for sklearn)\n",
        "# ========================================\n",
        "print(\"\\n[2/3] Joblib serialization\")\n",
        "joblib_path = f\"{model_dir}/{model_name}.joblib\"\n",
        "\n",
        "joblib.dump(best_model, joblib_path)\n",
        "\n",
        "joblib_size = os.path.getsize(joblib_path) / 1024\n",
        "print(f\"‚úÖ Saved: {joblib_path}\")\n",
        "print(f\"   Size: {joblib_size:.2f} KB\")\n",
        "\n",
        "# Load and verify\n",
        "loaded_joblib = joblib.load(joblib_path)\n",
        "joblib_pred = loaded_joblib.predict(X_test_scaled.iloc[:5])\n",
        "print(f\"   Verification: {joblib_pred}\")\n",
        "\n",
        "# ========================================\n",
        "# 3. Save preprocessing artifacts\n",
        "# ========================================\n",
        "print(\"\\n[3/3] Saving preprocessing artifacts\")\n",
        "\n",
        "# Save scaler\n",
        "scaler_path = f\"{model_dir}/scaler.joblib\"\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f\"‚úÖ Scaler saved: {scaler_path}\")\n",
        "\n",
        "# Save label encoders\n",
        "encoders_path = f\"{model_dir}/label_encoders.joblib\"\n",
        "joblib.dump(label_encoders, encoders_path)\n",
        "print(f\"‚úÖ Label encoders saved: {encoders_path}\")\n",
        "\n",
        "# Save feature columns\n",
        "config = {\n",
        "    'numerical_cols': numerical_cols,\n",
        "    'categorical_cols': categorical_cols,\n",
        "    'feature_cols': feature_cols\n",
        "}\n",
        "config_path = f\"{model_dir}/config.json\"\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "print(f\"‚úÖ Config saved: {config_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ ALL ARTIFACTS SAVED\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nDirectory: {model_dir}\")\n",
        "for f in os.listdir(model_dir):\n",
        "    size = os.path.getsize(f\"{model_dir}/{f}\") / 1024\n",
        "    print(f\"  {f}: {size:.2f} KB\")\n"
    ]
})

# ============================================================================
# FASTAPI DEVELOPMENT
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "---\n",
        "\n",
        "## üåê –ß–∞—Å—Ç—å 4: API Development —Å FastAPI\n",
        "\n",
        "### –ü–æ—á–µ–º—É FastAPI?\n",
        "\n",
        "**FastAPI** - —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π Python framework –¥–ª—è building APIs:\n",
        "\n",
        "- ‚úÖ **Very fast:** –ù–∞ —É—Ä–æ–≤–Ω–µ Node.js –∏ Go (–±–ª–∞–≥–æ–¥–∞—Ä—è Starlette –∏ Pydantic)\n",
        "- ‚úÖ **Type hints:** Automatic validation –∏ documentation\n",
        "- ‚úÖ **Async support:** –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤\n",
        "- ‚úÖ **Auto documentation:** Swagger UI –∏ ReDoc –∏–∑ –∫–æ—Ä–æ–±–∫–∏\n",
        "- ‚úÖ **Easy testing:** –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π test client\n",
        "\n",
        "### Architecture –¥–ª—è ML API:\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   Client    ‚îÇ ‚Üí ‚îÇ   FastAPI   ‚îÇ ‚Üí ‚îÇ    Model    ‚îÇ\n",
        "‚îÇ  (Request)  ‚îÇ     ‚îÇ   Server    ‚îÇ     ‚îÇ  Inference  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "       ‚îÇ                   ‚îÇ                   ‚îÇ\n",
        "       ‚îÇ                   ‚Üì                   ‚îÇ\n",
        "       ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ\n",
        "       ‚îÇ         ‚îÇ   Pydantic  ‚îÇ              ‚îÇ\n",
        "       ‚îÇ         ‚îÇ  Validation ‚îÇ              ‚îÇ\n",
        "       ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ\n",
        "       ‚îÇ                                       ‚îÇ\n",
        "       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                    (Response)\n",
        "```\n",
        "\n",
        "---\n"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 4.1 Pydantic Schemas –¥–ª—è Validation\n",
        "\n",
        "**Pydantic** –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:\n",
        "- Type validation\n",
        "- Data parsing\n",
        "- JSON serialization\n",
        "- Auto-documentation"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "from pydantic import BaseModel, Field, validator\n",
        "from typing import List, Optional\n",
        "from enum import Enum\n",
        "\n",
        "# Enum –¥–ª—è categorical fields\n",
        "class ContractType(str, Enum):\n",
        "    month_to_month = \"Month-to-month\"\n",
        "    one_year = \"One year\"\n",
        "    two_year = \"Two year\"\n",
        "\n",
        "class PaymentMethod(str, Enum):\n",
        "    credit_card = \"Credit card\"\n",
        "    bank_transfer = \"Bank transfer\"\n",
        "    electronic_check = \"Electronic check\"\n",
        "\n",
        "class InternetService(str, Enum):\n",
        "    dsl = \"DSL\"\n",
        "    fiber_optic = \"Fiber optic\"\n",
        "    no = \"No\"\n",
        "\n",
        "class YesNo(str, Enum):\n",
        "    yes = \"Yes\"\n",
        "    no = \"No\"\n",
        "\n",
        "# Request schema\n",
        "class CustomerData(BaseModel):\n",
        "    \"\"\"Schema for customer churn prediction request.\"\"\"\n",
        "    \n",
        "    tenure: int = Field(..., ge=0, le=100, description=\"Months with company\")\n",
        "    monthly_charges: float = Field(..., ge=0, le=500, description=\"Monthly bill amount\")\n",
        "    total_charges: float = Field(..., ge=0, description=\"Total amount paid\")\n",
        "    num_tickets: int = Field(..., ge=0, le=50, description=\"Number of support tickets\")\n",
        "    contract_type: ContractType = Field(..., description=\"Contract type\")\n",
        "    payment_method: PaymentMethod = Field(..., description=\"Payment method\")\n",
        "    internet_service: InternetService = Field(..., description=\"Internet service type\")\n",
        "    online_security: YesNo = Field(..., description=\"Online security service\")\n",
        "    tech_support: YesNo = Field(..., description=\"Tech support service\")\n",
        "    senior_citizen: int = Field(..., ge=0, le=1, description=\"Senior citizen (0 or 1)\")\n",
        "    \n",
        "    @validator('total_charges')\n",
        "    def total_charges_must_be_reasonable(cls, v, values):\n",
        "        if 'tenure' in values and 'monthly_charges' in values:\n",
        "            expected = values['tenure'] * values['monthly_charges']\n",
        "            if v < expected * 0.5:\n",
        "                raise ValueError(f'Total charges too low for tenure and monthly charges')\n",
        "        return v\n",
        "    \n",
        "    class Config:\n",
        "        schema_extra = {\n",
        "            \"example\": {\n",
        "                \"tenure\": 24,\n",
        "                \"monthly_charges\": 65.5,\n",
        "                \"total_charges\": 1500.0,\n",
        "                \"num_tickets\": 2,\n",
        "                \"contract_type\": \"One year\",\n",
        "                \"payment_method\": \"Credit card\",\n",
        "                \"internet_service\": \"Fiber optic\",\n",
        "                \"online_security\": \"Yes\",\n",
        "                \"tech_support\": \"No\",\n",
        "                \"senior_citizen\": 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Response schema\n",
        "class PredictionResponse(BaseModel):\n",
        "    \"\"\"Schema for churn prediction response.\"\"\"\n",
        "    \n",
        "    customer_id: Optional[str] = Field(None, description=\"Customer ID if provided\")\n",
        "    churn_prediction: int = Field(..., description=\"Churn prediction (0 or 1)\")\n",
        "    churn_probability: float = Field(..., ge=0, le=1, description=\"Probability of churn\")\n",
        "    confidence: str = Field(..., description=\"Confidence level (Low/Medium/High)\")\n",
        "    risk_factors: List[str] = Field(default=[], description=\"Top risk factors\")\n",
        "    \n",
        "    class Config:\n",
        "        schema_extra = {\n",
        "            \"example\": {\n",
        "                \"customer_id\": \"CUST-123\",\n",
        "                \"churn_prediction\": 1,\n",
        "                \"churn_probability\": 0.73,\n",
        "                \"confidence\": \"High\",\n",
        "                \"risk_factors\": [\"Month-to-month contract\", \"No tech support\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Batch request/response\n",
        "class BatchPredictionRequest(BaseModel):\n",
        "    \"\"\"Schema for batch predictions.\"\"\"\n",
        "    customers: List[CustomerData]\n",
        "\n",
        "class BatchPredictionResponse(BaseModel):\n",
        "    \"\"\"Schema for batch prediction response.\"\"\"\n",
        "    predictions: List[PredictionResponse]\n",
        "    total_processed: int\n",
        "    processing_time_ms: float\n",
        "\n",
        "# Health check\n",
        "class HealthResponse(BaseModel):\n",
        "    \"\"\"Health check response.\"\"\"\n",
        "    status: str\n",
        "    model_loaded: bool\n",
        "    model_version: str\n",
        "    timestamp: str\n",
        "\n",
        "print(\"‚úÖ Pydantic schemas defined\")\n",
        "print(\"\\nSchemas:\")\n",
        "print(\"  - CustomerData (request)\")\n",
        "print(\"  - PredictionResponse (response)\")\n",
        "print(\"  - BatchPredictionRequest/Response\")\n",
        "print(\"  - HealthResponse\")\n"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 4.2 FastAPI Application\n",
        "\n",
        "–°–æ–∑–¥–∞–¥–∏–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–µ API –¥–ª—è serving ML –º–æ–¥–µ–ª–∏."
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# FastAPI Application Code\n",
        "# –≠—Ç–æ—Ç –∫–æ–¥ –æ–±—ã—á–Ω–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ app.py\n",
        "\n",
        "fastapi_code = '''\n",
        "\"\"\"FastAPI application for Churn Prediction ML Model.\"\"\"\n",
        "\n",
        "from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "import uvicorn\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from enum import Enum\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI(\n",
        "    title=\"Churn Prediction API\",\n",
        "    description=\"ML API for predicting customer churn\",\n",
        "    version=\"1.0.0\",\n",
        "    docs_url=\"/docs\",  # Swagger UI\n",
        "    redoc_url=\"/redoc\"  # ReDoc\n",
        ")\n",
        "\n",
        "# CORS middleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Global variables for model and artifacts\n",
        "model = None\n",
        "scaler = None\n",
        "label_encoders = None\n",
        "config = None\n",
        "model_version = \"1.0.0\"\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def load_model():\n",
        "    \"\"\"Load model and artifacts on startup.\"\"\"\n",
        "    global model, scaler, label_encoders, config\n",
        "    \n",
        "    logger.info(\"Loading model and artifacts...\")\n",
        "    \n",
        "    try:\n",
        "        model = joblib.load(\"models/churn_predictor.joblib\")\n",
        "        scaler = joblib.load(\"models/scaler.joblib\")\n",
        "        label_encoders = joblib.load(\"models/label_encoders.joblib\")\n",
        "        \n",
        "        with open(\"models/config.json\", \"r\") as f:\n",
        "            config = json.load(f)\n",
        "        \n",
        "        logger.info(\"‚úÖ Model and artifacts loaded successfully\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"‚ùå Failed to load model: {e}\")\n",
        "        raise\n",
        "\n",
        "def preprocess_input(data: dict) -> np.ndarray:\n",
        "    \"\"\"Preprocess input data for prediction.\"\"\"\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame([data])\n",
        "    \n",
        "    # Convert senior_citizen to string for encoding\n",
        "    df[\\'senior_citizen\\'] = df[\\'senior_citizen\\'].astype(str)\n",
        "    \n",
        "    # Apply label encoding\n",
        "    for col in config[\\'categorical_cols\\']:\n",
        "        if col in label_encoders:\n",
        "            df[col] = label_encoders[col].transform(df[col])\n",
        "    \n",
        "    # Apply scaling to numerical columns\n",
        "    df[config[\\'numerical_cols\\']] = scaler.transform(df[config[\\'numerical_cols\\']])\n",
        "    \n",
        "    # Select features in correct order\n",
        "    X = df[config[\\'feature_cols\\']].values\n",
        "    \n",
        "    return X\n",
        "\n",
        "def get_risk_factors(data: dict, probability: float) -> List[str]:\n",
        "    \"\"\"Identify risk factors based on input data.\"\"\"\n",
        "    risk_factors = []\n",
        "    \n",
        "    if data.get(\\'contract_type\\') == \"Month-to-month\":\n",
        "        risk_factors.append(\"Month-to-month contract (high churn risk)\")\n",
        "    if data.get(\\'tenure\\', 0) < 12:\n",
        "        risk_factors.append(\"Short tenure (< 12 months)\")\n",
        "    if data.get(\\'monthly_charges\\', 0) > 70:\n",
        "        risk_factors.append(\"High monthly charges\")\n",
        "    if data.get(\\'tech_support\\') == \"No\":\n",
        "        risk_factors.append(\"No tech support\")\n",
        "    if data.get(\\'online_security\\') == \"No\":\n",
        "        risk_factors.append(\"No online security\")\n",
        "    if data.get(\\'num_tickets\\', 0) > 3:\n",
        "        risk_factors.append(\"Many support tickets\")\n",
        "    \n",
        "    return risk_factors[:5]  # Top 5\n",
        "\n",
        "def get_confidence(probability: float) -> str:\n",
        "    \"\"\"Get confidence level based on probability.\"\"\"\n",
        "    if probability < 0.3 or probability > 0.7:\n",
        "        return \"High\"\n",
        "    elif probability < 0.4 or probability > 0.6:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Low\"\n",
        "\n",
        "# ========================================\n",
        "# ENDPOINTS\n",
        "# ========================================\n",
        "\n",
        "@app.get(\"/\", tags=[\"Root\"])\n",
        "async def root():\n",
        "    \"\"\"Root endpoint.\"\"\"\n",
        "    return {\n",
        "        \"message\": \"Churn Prediction API\",\n",
        "        \"version\": model_version,\n",
        "        \"docs\": \"/docs\"\n",
        "    }\n",
        "\n",
        "@app.get(\"/health\", response_model=HealthResponse, tags=[\"Health\"])\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint.\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\" if model is not None else \"unhealthy\",\n",
        "        \"model_loaded\": model is not None,\n",
        "        \"model_version\": model_version,\n",
        "        \"timestamp\": datetime.utcnow().isoformat()\n",
        "    }\n",
        "\n",
        "@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"Prediction\"])\n",
        "async def predict(customer: CustomerData, customer_id: Optional[str] = None):\n",
        "    \"\"\"Make a single churn prediction.\"\"\"\n",
        "    try:\n",
        "        # Convert to dict\n",
        "        data = {\n",
        "            \"tenure\": customer.tenure,\n",
        "            \"monthly_charges\": customer.monthly_charges,\n",
        "            \"total_charges\": customer.total_charges,\n",
        "            \"num_tickets\": customer.num_tickets,\n",
        "            \"contract_type\": customer.contract_type.value,\n",
        "            \"payment_method\": customer.payment_method.value,\n",
        "            \"internet_service\": customer.internet_service.value,\n",
        "            \"online_security\": customer.online_security.value,\n",
        "            \"tech_support\": customer.tech_support.value,\n",
        "            \"senior_citizen\": customer.senior_citizen\n",
        "        }\n",
        "        \n",
        "        # Preprocess\n",
        "        X = preprocess_input(data)\n",
        "        \n",
        "        # Predict\n",
        "        prediction = int(model.predict(X)[0])\n",
        "        probability = float(model.predict_proba(X)[0, 1])\n",
        "        \n",
        "        # Get risk factors and confidence\n",
        "        risk_factors = get_risk_factors(data, probability)\n",
        "        confidence = get_confidence(probability)\n",
        "        \n",
        "        return {\n",
        "            \"customer_id\": customer_id,\n",
        "            \"churn_prediction\": prediction,\n",
        "            \"churn_probability\": round(probability, 4),\n",
        "            \"confidence\": confidence,\n",
        "            \"risk_factors\": risk_factors\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Prediction error: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/predict/batch\", response_model=BatchPredictionResponse, tags=[\"Prediction\"])\n",
        "async def predict_batch(request: BatchPredictionRequest):\n",
        "    \"\"\"Make batch churn predictions.\"\"\"\n",
        "    start_time = time.time()\n",
        "    predictions = []\n",
        "    \n",
        "    for i, customer in enumerate(request.customers):\n",
        "        try:\n",
        "            result = await predict(customer, customer_id=f\"batch_{i}\")\n",
        "            predictions.append(result)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Batch prediction error for customer {i}: {e}\")\n",
        "            predictions.append({\n",
        "                \"customer_id\": f\"batch_{i}\",\n",
        "                \"churn_prediction\": -1,\n",
        "                \"churn_probability\": 0.0,\n",
        "                \"confidence\": \"Error\",\n",
        "                \"risk_factors\": [str(e)]\n",
        "            })\n",
        "    \n",
        "    processing_time = (time.time() - start_time) * 1000\n",
        "    \n",
        "    return {\n",
        "        \"predictions\": predictions,\n",
        "        \"total_processed\": len(predictions),\n",
        "        \"processing_time_ms\": round(processing_time, 2)\n",
        "    }\n",
        "\n",
        "@app.get(\"/model/info\", tags=[\"Model\"])\n",
        "async def model_info():\n",
        "    \"\"\"Get model information.\"\"\"\n",
        "    return {\n",
        "        \"model_type\": type(model).__name__,\n",
        "        \"model_version\": model_version,\n",
        "        \"features\": config[\\'feature_cols\\'],\n",
        "        \"n_features\": len(config[\\'feature_cols\\']),\n",
        "        \"numerical_features\": config[\\'numerical_cols\\'],\n",
        "        \"categorical_features\": config[\\'categorical_cols\\']\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000, reload=True)\n",
        "'''\n",
        "\n",
        "# Save FastAPI code\n",
        "api_path = \"./app.py\"\n",
        "with open(api_path, 'w') as f:\n",
        "    f.write(fastapi_code)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FASTAPI APPLICATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n‚úÖ FastAPI app saved to: {api_path}\")\n",
        "print(\"\\nEndpoints:\")\n",
        "print(\"  GET  /              - Root endpoint\")\n",
        "print(\"  GET  /health        - Health check\")\n",
        "print(\"  POST /predict       - Single prediction\")\n",
        "print(\"  POST /predict/batch - Batch predictions\")\n",
        "print(\"  GET  /model/info    - Model information\")\n",
        "print(\"\\nRun with: uvicorn app:app --reload\")\n",
        "print(\"Docs available at: http://localhost:8000/docs\")\n"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 4.3 API Testing\n",
        "\n",
        "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º API –ª–æ–∫–∞–ª—å–Ω–æ —Å –ø–æ–º–æ—â—å—é Python requests."
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –°–∏–º—É–ª—è—Ü–∏—è API –∑–∞–ø—Ä–æ—Å–æ–≤ (–±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞)\n",
        "# –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –±—ã requests.post()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"API TESTING (SIMULATION)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test data\n",
        "test_customer = {\n",
        "    \"tenure\": 24,\n",
        "    \"monthly_charges\": 65.5,\n",
        "    \"total_charges\": 1500.0,\n",
        "    \"num_tickets\": 2,\n",
        "    \"contract_type\": \"One year\",\n",
        "    \"payment_method\": \"Credit card\",\n",
        "    \"internet_service\": \"Fiber optic\",\n",
        "    \"online_security\": \"Yes\",\n",
        "    \"tech_support\": \"No\",\n",
        "    \"senior_citizen\": 0\n",
        "}\n",
        "\n",
        "print(\"\\nTest Request:\")\n",
        "print(json.dumps(test_customer, indent=2))\n",
        "\n",
        "# Simulate preprocessing and prediction\n",
        "df_test = pd.DataFrame([test_customer])\n",
        "df_test['senior_citizen'] = df_test['senior_citizen'].astype(str)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col in label_encoders:\n",
        "        df_test[col] = label_encoders[col].transform(df_test[col])\n",
        "\n",
        "df_test[numerical_cols] = scaler.transform(df_test[numerical_cols])\n",
        "X_test_api = df_test[feature_cols].values\n",
        "\n",
        "prediction = int(best_model.predict(X_test_api)[0])\n",
        "probability = float(best_model.predict_proba(X_test_api)[0, 1])\n",
        "\n",
        "# Determine confidence\n",
        "if probability < 0.3 or probability > 0.7:\n",
        "    confidence = \"High\"\n",
        "elif probability < 0.4 or probability > 0.6:\n",
        "    confidence = \"Medium\"\n",
        "else:\n",
        "    confidence = \"Low\"\n",
        "\n",
        "# Risk factors\n",
        "risk_factors = []\n",
        "if test_customer['contract_type'] == \"Month-to-month\":\n",
        "    risk_factors.append(\"Month-to-month contract\")\n",
        "if test_customer['tenure'] < 12:\n",
        "    risk_factors.append(\"Short tenure\")\n",
        "if test_customer['tech_support'] == \"No\":\n",
        "    risk_factors.append(\"No tech support\")\n",
        "\n",
        "response = {\n",
        "    \"customer_id\": \"TEST-001\",\n",
        "    \"churn_prediction\": prediction,\n",
        "    \"churn_probability\": round(probability, 4),\n",
        "    \"confidence\": confidence,\n",
        "    \"risk_factors\": risk_factors\n",
        "}\n",
        "\n",
        "print(\"\\nSimulated Response:\")\n",
        "print(json.dumps(response, indent=2))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ API SIMULATION COMPLETE\")\n",
        "print(\"=\" * 70)\n"
    ]
})

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π notebook
notebook['cells'] = cells

with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f'\\n‚úÖ Updated notebook: {notebook_path}')
print(f'Total cells: {len(cells)}')
print('Model serialization and FastAPI added!')
