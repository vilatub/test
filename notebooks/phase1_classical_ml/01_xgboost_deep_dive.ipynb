{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Deep Dive: \u041e\u0442 \u0442\u0435\u043e\u0440\u0438\u0438 \u043a \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0435\n",
    "\n",
    "## \ud83c\udfaf \u0426\u0435\u043b\u0438 \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0430\n",
    "\n",
    "1. **\u0413\u043b\u0443\u0431\u043e\u043a\u043e\u0435 \u043f\u043e\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u043c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u043a\u0438** \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430 \u0438 XGBoost\n",
    "2. **\u041f\u0440\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435** \u043d\u0430 \u0440\u0435\u0430\u043b\u044c\u043d\u043e\u0439 \u0431\u0438\u0437\u043d\u0435\u0441-\u0437\u0430\u0434\u0430\u0447\u0435 \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u043e\u0433\u043e \u0441\u043a\u043e\u0440\u0438\u043d\u0433\u0430\n",
    "3. **\u0414\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0430\u043d\u0430\u043b\u0438\u0437** \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438 \u0438\u0445 \u0432\u043b\u0438\u044f\u043d\u0438\u044f\n",
    "4. **Best practices** \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f XGBoost \u0432 production\n",
    "\n",
    "## \ud83d\udcbc \u0411\u0438\u0437\u043d\u0435\u0441-\u0437\u0430\u0434\u0430\u0447\u0430: \u041a\u0440\u0435\u0434\u0438\u0442\u043d\u044b\u0439 \u0441\u043a\u043e\u0440\u0438\u043d\u0433\n",
    "\n",
    "**\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442:** \u041a\u0440\u0443\u043f\u043d\u044b\u0439 \u0442\u0430\u0439\u0432\u0430\u043d\u044c\u0441\u043a\u0438\u0439 \u0431\u0430\u043d\u043a \u0432\u044b\u0434\u0430\u0435\u0442 \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u044b\u0435 \u043a\u0430\u0440\u0442\u044b \u043a\u043b\u0438\u0435\u043d\u0442\u0430\u043c. \u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u043a\u0442\u043e \u0438\u0437 \u043a\u043b\u0438\u0435\u043d\u0442\u043e\u0432 \u0441\u0434\u0435\u043b\u0430\u0435\u0442 \u0434\u0435\u0444\u043e\u043b\u0442 (\u043d\u0435 \u0437\u0430\u043f\u043b\u0430\u0442\u0438\u0442) \u0432 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u043c \u043c\u0435\u0441\u044f\u0446\u0435.\n",
    "\n",
    "**\u041f\u043e\u0447\u0435\u043c\u0443 \u044d\u0442\u043e \u0432\u0430\u0436\u043d\u043e:**\n",
    "- \ud83d\udcb0 **\u0424\u0438\u043d\u0430\u043d\u0441\u043e\u0432\u044b\u0435 \u043f\u043e\u0442\u0435\u0440\u0438:** \u0414\u0435\u0444\u043e\u043b\u0442 = \u043f\u043e\u0442\u0435\u0440\u044f \u0434\u0435\u043d\u0435\u0433 \u0431\u0430\u043d\u043a\u043e\u043c\n",
    "- \u2696\ufe0f **\u0420\u0435\u0433\u0443\u043b\u044f\u0442\u043e\u0440\u043d\u044b\u0435 \u0442\u0440\u0435\u0431\u043e\u0432\u0430\u043d\u0438\u044f:** Basel III \u0442\u0440\u0435\u0431\u0443\u0435\u0442 \u0442\u043e\u0447\u043d\u043e\u0439 \u043e\u0446\u0435\u043d\u043a\u0438 \u0440\u0438\u0441\u043a\u043e\u0432\n",
    "- \ud83c\udfaf **\u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f:** \u0411\u0430\u043b\u0430\u043d\u0441 \u043c\u0435\u0436\u0434\u0443 \u043e\u0434\u043e\u0431\u0440\u0435\u043d\u0438\u0435\u043c \u0437\u0430\u044f\u0432\u043e\u043a \u0438 \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0435\u0439 \u0440\u0438\u0441\u043a\u043e\u0432\n",
    "- \ud83d\udcca **\u0418\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0438\u0440\u0443\u0435\u043c\u043e\u0441\u0442\u044c:** \u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043e\u0431\u044a\u044f\u0441\u043d\u0438\u0442\u044c \u0440\u0435\u0448\u0435\u043d\u0438\u0435 \u043a\u043b\u0438\u0435\u043d\u0442\u0443\n",
    "\n",
    "**\u041c\u0435\u0442\u0440\u0438\u043a\u0438 \u0443\u0441\u043f\u0435\u0445\u0430:**\n",
    "- **Precision:** \u041a\u0430\u043a\u043e\u0439 % \u0438\u0437 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0434\u0435\u0444\u043e\u043b\u0442\u043e\u0432 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0434\u0435\u0444\u043e\u043b\u0442\u044b (\u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f false positives)\n",
    "- **Recall:** \u041a\u0430\u043a\u043e\u0439 % \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0434\u0435\u0444\u043e\u043b\u0442\u043e\u0432 \u043c\u044b \u043f\u043e\u0439\u043c\u0430\u043b\u0438 (\u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f false negatives)\n",
    "- **ROC-AUC:** \u041e\u0431\u0449\u0435\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0430\u043d\u0436\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\n",
    "- **PR-AUC:** \u0412\u0430\u0436\u043d\u0435\u0435 \u0434\u043b\u044f \u043d\u0435\u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n",
    "\n",
    "**\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043e\u0448\u0438\u0431\u043e\u043a:**\n",
    "- **False Negative (\u043f\u0440\u043e\u043f\u0443\u0441\u0442\u0438\u043b\u0438 \u0434\u0435\u0444\u043e\u043b\u0442):** \u0411\u0430\u043d\u043a \u0442\u0435\u0440\u044f\u0435\u0442 \u0434\u0435\u043d\u044c\u0433\u0438 (~5000-50000 TWD)\n",
    "- **False Positive (\u043e\u0442\u043a\u0430\u0437\u0430\u043b\u0438 \u0445\u043e\u0440\u043e\u0448\u0435\u043c\u0443 \u043a\u043b\u0438\u0435\u043d\u0442\u0443):** \u041f\u043e\u0442\u0435\u0440\u044f \u043f\u0440\u0438\u0431\u044b\u043b\u0438 \u043e\u0442 \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u043e\u0432 (~500-2000 TWD)\n",
    "- \u0421\u043e\u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0435: FN \u0432 10-100 \u0440\u0430\u0437 \u0434\u043e\u0440\u043e\u0436\u0435 FP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcda \u0427\u0430\u0441\u0442\u044c 1: \u0422\u0435\u043e\u0440\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0444\u0443\u043d\u0434\u0430\u043c\u0435\u043d\u0442\n",
    "\n",
    "### 1.1 \u041e\u0442 \u0440\u0435\u0448\u0430\u044e\u0449\u0438\u0445 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043a \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u043c\u0443 \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0443\n",
    "\n",
    "#### \u0420\u0435\u0448\u0430\u044e\u0449\u0435\u0435 \u0434\u0435\u0440\u0435\u0432\u043e (Decision Tree)\n",
    "\n",
    "\u0411\u0430\u0437\u043e\u0432\u044b\u0439 \u0441\u0442\u0440\u043e\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0431\u043b\u043e\u043a. \u0414\u0435\u0440\u0435\u0432\u043e \u0440\u0430\u0437\u0434\u0435\u043b\u044f\u0435\u0442 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043d\u0430 \u0440\u0435\u0433\u0438\u043e\u043d\u044b.\n",
    "\n",
    "**\u041c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438:** \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0434\u0435\u0440\u0435\u0432\u0430 $T(x; \\Theta)$, \u0433\u0434\u0435 $\\Theta = \\{R_j, \\gamma_j\\}_{j=1}^J$\n",
    "\n",
    "$$f(x) = \\sum_{j=1}^{J} \\gamma_j \\cdot \\mathbb{1}(x \\in R_j)$$\n",
    "\n",
    "\u0433\u0434\u0435:\n",
    "- $J$ - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0438\u0441\u0442\u044c\u0435\u0432 (\u0442\u0435\u0440\u043c\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u0443\u0437\u043b\u043e\u0432)\n",
    "- $R_j$ - \u0440\u0435\u0433\u0438\u043e\u043d (\u043f\u0440\u044f\u043c\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u0430\u044f \u043e\u0431\u043b\u0430\u0441\u0442\u044c \u0432 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432)\n",
    "- $\\gamma_j$ - \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0434\u043b\u044f \u0440\u0435\u0433\u0438\u043e\u043d\u0430 $R_j$\n",
    "- $\\mathbb{1}(\\cdot)$ - \u0438\u043d\u0434\u0438\u043a\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044f\n",
    "\n",
    "**\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f (\u0436\u0430\u0434\u043d\u044b\u0439, \u0440\u0435\u043a\u0443\u0440\u0441\u0438\u0432\u043d\u044b\u0439):**\n",
    "\n",
    "1. \u041d\u0430\u0447\u0438\u043d\u0430\u0435\u043c \u0441 \u043a\u043e\u0440\u043d\u044f (\u0432\u0441\u0435 \u0434\u0430\u043d\u043d\u044b\u0435)\n",
    "2. \u0414\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 $k$ \u0438 \u043f\u043e\u0440\u043e\u0433\u0430 $s$:\n",
    "   - \u0420\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u043d\u0430 $R_L(k,s) = \\{X | X_k \u2264 s\\}$ \u0438 $R_R(k,s) = \\{X | X_k > s\\}$\n",
    "3. \u0412\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435, \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u044e\u0449\u0435\u0435 loss:\n",
    "\n",
    "$$\\min_{k,s} \\left[ \\min_{\\gamma_L} \\sum_{x_i \\in R_L} L(y_i, \\gamma_L) + \\min_{\\gamma_R} \\sum_{x_i \\in R_R} L(y_i, \\gamma_R) \\right]$$\n",
    "\n",
    "4. \u0420\u0435\u043a\u0443\u0440\u0441\u0438\u0432\u043d\u043e \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u0435\u043c \u0434\u043b\u044f \u0434\u043e\u0447\u0435\u0440\u043d\u0438\u0445 \u0443\u0437\u043b\u043e\u0432\n",
    "\n",
    "**\u041f\u0440\u043e\u0431\u043b\u0435\u043c\u044b \u043e\u0434\u043d\u043e\u0433\u043e \u0434\u0435\u0440\u0435\u0432\u0430:**\n",
    "- \ud83d\udd34 **\u0412\u044b\u0441\u043e\u043a\u0430\u044f \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044f:** \u041c\u0430\u043b\u0435\u043d\u044c\u043a\u043e\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u2192 \u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0434\u0435\u0440\u0435\u0432\u0430\n",
    "- \ud83d\udd34 **\u041f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435:** \u0421\u043b\u0438\u0448\u043a\u043e\u043c \u043f\u043e\u0434\u0441\u0442\u0440\u0430\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u043f\u043e\u0434 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443\n",
    "- \ud83d\udd34 **\u0416\u0435\u0441\u0442\u043a\u0438\u0435 \u0433\u0440\u0430\u043d\u0438\u0446\u044b:** \u041d\u0435 smooth \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 \u0411\u044d\u0433\u0433\u0438\u043d\u0433 (Bootstrap Aggregating)\n",
    "\n",
    "**\u0418\u0434\u0435\u044f:** \u0423\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u0435 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442 \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044e!\n",
    "\n",
    "$$f_{bag}(x) = \\frac{1}{B} \\sum_{b=1}^{B} f_b(x)$$\n",
    "\n",
    "\u0433\u0434\u0435 $f_b$ - \u0434\u0435\u0440\u0435\u0432\u043e, \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0435 \u043d\u0430 bootstrap \u0432\u044b\u0431\u043e\u0440\u043a\u0435 $b$.\n",
    "\n",
    "**\u041f\u043e\u0447\u0435\u043c\u0443 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442:**\n",
    "\n",
    "\u041f\u0443\u0441\u0442\u044c $f_1, \\ldots, f_B$ - \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u044b\u0435 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b \u0441 \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u0435\u0439 $\\sigma^2$. \u0422\u043e\u0433\u0434\u0430:\n",
    "\n",
    "$$\\text{Var}\\left(\\frac{1}{B} \\sum_{b=1}^B f_b\\right) = \\frac{\\sigma^2}{B}$$\n",
    "\n",
    "\u0414\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044f \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442\u0441\u044f \u0432 $B$ \u0440\u0430\u0437!\n",
    "\n",
    "**Random Forest = Bagging + Feature randomness** (\u0434\u043b\u044f \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u044f \u0440\u0430\u0437\u043d\u043e\u043e\u0431\u0440\u0430\u0437\u0438\u044f)\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 \u0411\u0443\u0441\u0442\u0438\u043d\u0433: \u041f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n",
    "\n",
    "**\u0418\u0434\u0435\u044f \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430:** \u0412\u043c\u0435\u0441\u0442\u043e \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e, \u043a\u0430\u0436\u0434\u0430\u044f \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0438\u0441\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u0442 \u043e\u0448\u0438\u0431\u043a\u0438 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0445.\n",
    "\n",
    "#### AdaBoost (Adaptive Boosting) - \u0438\u0441\u0442\u043e\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\n",
    "\n",
    "\u041f\u0435\u0440\u0435\u0432\u0430\u0436\u0438\u0432\u0430\u043d\u0438\u0435 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432:\n",
    "\n",
    "$$w_i^{(t+1)} = w_i^{(t)} \\cdot \\exp(\\alpha_t \\cdot \\mathbb{1}(y_i \\neq f_t(x_i)))$$\n",
    "\n",
    "\u0424\u0438\u043d\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435:\n",
    "\n",
    "$$F(x) = \\text{sign}\\left(\\sum_{t=1}^T \\alpha_t f_t(x)\\right)$$\n",
    "\n",
    "**\u041e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u0435:** \u0420\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438, \u043d\u0435 \u043e\u0431\u043e\u0431\u0449\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u0434\u0440\u0443\u0433\u0438\u0435 loss \u0444\u0443\u043d\u043a\u0446\u0438\u0438.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 \u0413\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u044b\u0439 \u0431\u0443\u0441\u0442\u0438\u043d\u0433: \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u043e\u0434\u0445\u043e\u0434\n",
    "\n",
    "#### \u041a\u043b\u044e\u0447\u0435\u0432\u0430\u044f \u0438\u0434\u0435\u044f (Jerome Friedman, 2001)\n",
    "\n",
    "\u0411\u0443\u0441\u0442\u0438\u043d\u0433 = **\u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f \u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u043c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435**\n",
    "\n",
    "**\u041f\u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0437\u0430\u0434\u0430\u0447\u0438:**\n",
    "\n",
    "\u0425\u043e\u0442\u0438\u043c \u043d\u0430\u0439\u0442\u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u044e $F^*(x)$, \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u044e\u0449\u0443\u044e \u043e\u0436\u0438\u0434\u0430\u0435\u043c\u044b\u0435 \u043f\u043e\u0442\u0435\u0440\u0438:\n",
    "\n",
    "$$F^* = \\arg\\min_F \\mathbb{E}_{x,y}[L(y, F(x))]$$\n",
    "\n",
    "\u0433\u0434\u0435 $L(y, F(x))$ - \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c (loss function).\n",
    "\n",
    "**\u0410\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0430\u0446\u0438\u044f \u043d\u0430 \u043a\u043e\u043d\u0435\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435:**\n",
    "\n",
    "$$F^* \\approx \\arg\\min_F \\sum_{i=1}^n L(y_i, F(x_i))$$\n",
    "\n",
    "#### \u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c Gradient Boosting\n",
    "\n",
    "**\u0428\u0430\u0433 0 (\u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f):**\n",
    "\n",
    "$$F_0(x) = \\arg\\min_\\gamma \\sum_{i=1}^n L(y_i, \\gamma)$$\n",
    "\n",
    "\u0414\u043b\u044f regression (MSE): $F_0(x) = \\bar{y}$ (\u0441\u0440\u0435\u0434\u043d\u0435\u0435)  \n",
    "\u0414\u043b\u044f classification (log-loss): $F_0(x) = \\log\\frac{p}{1-p}$ (log-odds)\n",
    "\n",
    "**\u0428\u0430\u0433 $m = 1, 2, \\ldots, M$:**\n",
    "\n",
    "1. **\u0412\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c \u043f\u0441\u0435\u0432\u0434\u043e-\u043e\u0441\u0442\u0430\u0442\u043a\u0438 (negative gradient):**\n",
    "\n",
    "$$r_{im} = -\\left[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}\\right]_{F=F_{m-1}}$$\n",
    "\n",
    "   \u0418\u043d\u0442\u0443\u0438\u0446\u0438\u044f: $r_{im}$ \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043d\u0443\u0436\u043d\u043e \"\u0434\u0432\u0438\u0433\u0430\u0442\u044c\u0441\u044f\", \u0447\u0442\u043e\u0431\u044b \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0442\u044c loss \u0434\u043b\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u0430 $i$.\n",
    "\n",
    "2. **\u041e\u0431\u0443\u0447\u0430\u0435\u043c \u0434\u0435\u0440\u0435\u0432\u043e $h_m(x)$ \u043d\u0430 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043e\u0441\u0442\u0430\u0442\u043a\u043e\u0432:**\n",
    "\n",
    "$$h_m = \\arg\\min_h \\sum_{i=1}^n (r_{im} - h(x_i))^2$$\n",
    "\n",
    "   \u0414\u0435\u0440\u0435\u0432\u043e \u0430\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0438\u0440\u0443\u0435\u0442 anti-gradient!\n",
    "\n",
    "3. **\u0414\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043b\u0438\u0441\u0442\u0430 $j$ \u0434\u0435\u0440\u0435\u0432\u0430 $h_m$, \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435:**\n",
    "\n",
    "$$\\gamma_{jm} = \\arg\\min_\\gamma \\sum_{x_i \\in R_{jm}} L(y_i, F_{m-1}(x_i) + \\gamma)$$\n",
    "\n",
    "   Line search \u0432 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0438 gradient \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0440\u0435\u0433\u0438\u043e\u043d\u0430.\n",
    "\n",
    "4. **\u041e\u0431\u043d\u043e\u0432\u043b\u044f\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c:**\n",
    "\n",
    "$$F_m(x) = F_{m-1}(x) + \\nu \\cdot h_m(x)$$\n",
    "\n",
    "   \u0433\u0434\u0435 $\\nu$ - learning rate (shrinkage parameter), \u043e\u0431\u044b\u0447\u043d\u043e $\\nu \\in [0.01, 0.3]$\n",
    "\n",
    "**\u0424\u0438\u043d\u0430\u043b\u044c\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c:**\n",
    "\n",
    "$$F(x) = F_0(x) + \\nu \\sum_{m=1}^M h_m(x)$$\n",
    "\n",
    "---\n",
    "\n",
    "#### \u041f\u0440\u0438\u043c\u0435\u0440\u044b loss \u0444\u0443\u043d\u043a\u0446\u0438\u0439 \u0438 \u0438\u0445 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432\n",
    "\n",
    "**1. Regression (MSE):**\n",
    "\n",
    "$$L(y, F) = \\frac{1}{2}(y - F)^2$$\n",
    "\n",
    "$$-\\frac{\\partial L}{\\partial F} = y - F = \\text{\u043e\u0441\u0442\u0430\u0442\u043e\u043a}$$\n",
    "\n",
    "\u0413\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u044b\u0439 \u0431\u0443\u0441\u0442\u0438\u043d\u0433 \u0434\u043b\u044f MSE = \u043e\u0431\u044b\u0447\u043d\u044b\u0439 \u0431\u0443\u0441\u0442\u0438\u043d\u0433 \u043f\u043e \u043e\u0441\u0442\u0430\u0442\u043a\u0430\u043c!\n",
    "\n",
    "**2. Binary Classification (Log-Loss):**\n",
    "\n",
    "$$L(y, F) = \\log(1 + e^{-2yF}), \\quad y \\in \\{-1, +1\\}$$\n",
    "\n",
    "$$-\\frac{\\partial L}{\\partial F} = \\frac{2y}{1 + e^{2yF}} = 2y \\cdot p_{model}(y|x)$$\n",
    "\n",
    "\u0433\u0434\u0435 $p_{model}(y|x) = \\frac{1}{1 + e^{-2yF}}$\n",
    "\n",
    "**3. Multi-class (Softmax):**\n",
    "\n",
    "\u041e\u0431\u0443\u0447\u0430\u0435\u043c $K$ \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u0439 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438 (\u043e\u0434\u043d\u043e \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 XGBoost: eXtreme Gradient Boosting\n",
    "\n",
    "#### \u041a\u043b\u044e\u0447\u0435\u0432\u044b\u0435 \u0438\u043d\u043d\u043e\u0432\u0430\u0446\u0438\u0438 (Tianqi Chen, 2016)\n",
    "\n",
    "**1. Second-Order Taylor Expansion (2nd order gradient)**\n",
    "\n",
    "\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0439 GB \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u0435\u0440\u0432\u044b\u0439 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442. XGBoost \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0440\u0430\u0437\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0422\u0435\u0439\u043b\u043e\u0440\u0430 2\u0433\u043e \u043f\u043e\u0440\u044f\u0434\u043a\u0430:\n",
    "\n",
    "$$L(y, F_{m-1} + h_m) \\approx L(y, F_{m-1}) + g_i \\cdot h_m(x_i) + \\frac{1}{2} h_i \\cdot h_m^2(x_i)$$\n",
    "\n",
    "\u0433\u0434\u0435:\n",
    "- $g_i = \\frac{\\partial L(y_i, F)}{\\partial F}\\Big|_{F=F_{m-1}}$ - **\u043f\u0435\u0440\u0432\u044b\u0439 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442** (gradient)\n",
    "- $h_i = \\frac{\\partial^2 L(y_i, F)}{\\partial F^2}\\Big|_{F=F_{m-1}}$ - **\u0432\u0442\u043e\u0440\u043e\u0439 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442** (hessian)\n",
    "\n",
    "**\u0417\u0430\u0447\u0435\u043c \u043d\u0443\u0436\u0435\u043d hessian:**\n",
    "- \ud83d\udcca **\u041b\u0443\u0447\u0448\u0430\u044f \u0430\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0430\u0446\u0438\u044f** loss \u0444\u0443\u043d\u043a\u0446\u0438\u0438 (\u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0438\u0447\u043d\u0430\u044f vs \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f)\n",
    "- \ud83c\udfaf **\u0410\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f** (\u0432\u0442\u043e\u0440\u043e\u0439 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 = \u043c\u0435\u0440\u0430 \"\u0443\u0432\u0435\u0440\u0435\u043d\u043d\u043e\u0441\u0442\u0438\")\n",
    "- \u26a1 **\u0411\u044b\u0441\u0442\u0440\u0435\u0435 \u0441\u0445\u043e\u0434\u0438\u0442\u0441\u044f** (\u043a\u0430\u043a \u043c\u0435\u0442\u043e\u0434 \u041d\u044c\u044e\u0442\u043e\u043d\u0430 vs \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u044b\u0439 \u0441\u043f\u0443\u0441\u043a)\n",
    "\n",
    "**\u041f\u0440\u0438\u043c\u0435\u0440 \u0434\u043b\u044f MSE:**\n",
    "- $g_i = F_{m-1}(x_i) - y_i$ (\u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 - \u0438\u0441\u0442\u0438\u043d\u0430)\n",
    "- $h_i = 1$ (\u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u0430)\n",
    "\n",
    "**\u041f\u0440\u0438\u043c\u0435\u0440 \u0434\u043b\u044f Log-Loss:**\n",
    "- $g_i = p_i - y_i$ \u0433\u0434\u0435 $p_i = \\sigma(F_{m-1}(x_i))$\n",
    "- $h_i = p_i(1 - p_i)$ (\u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044f \u0411\u0435\u0440\u043d\u0443\u043b\u043b\u0438)\n",
    "\n",
    "---\n",
    "\n",
    "**2. \u0420\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0446\u0435\u043b\u0435\u0432\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044f**\n",
    "\n",
    "XGBoost \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u0442:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} = \\sum_{i=1}^n L(y_i, F_{m-1}(x_i) + h_m(x_i)) + \\Omega(h_m)$$\n",
    "\n",
    "\u0433\u0434\u0435 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f:\n",
    "\n",
    "$$\\Omega(h) = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2$$\n",
    "\n",
    "- $T$ - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0438\u0441\u0442\u044c\u0435\u0432 \u0434\u0435\u0440\u0435\u0432\u0430\n",
    "- $w_j$ - \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 (\u0432\u0435\u0441) \u0432 \u043b\u0438\u0441\u0442\u0435 $j$\n",
    "- $\\gamma$ - \u0448\u0442\u0440\u0430\u0444 \u0437\u0430 \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c (\u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0438\u0441\u0442\u044c\u0435\u0432)\n",
    "- $\\lambda$ - L2 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043d\u0430 \u0432\u0435\u0441\u0430\n",
    "\n",
    "**\u0418\u043d\u0442\u0443\u0438\u0446\u0438\u044f:**\n",
    "- $\\gamma T$ - \u00abOccam's Razor\u00bb: \u043f\u0440\u043e\u0449\u0435 \u0434\u0435\u0440\u0435\u0432\u044c\u044f \u043b\u0443\u0447\u0448\u0435\n",
    "- $\\lambda ||w||^2$ - \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0438\u0435 \u0432\u0435\u0441\u0430 \u2192 \u0431\u043e\u043b\u0435\u0435 smooth \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\n",
    "\n",
    "---\n",
    "\n",
    "**3. \u041e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043b\u0438\u0441\u0442\u0430**\n",
    "\n",
    "\u041f\u043e\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u0440\u0430\u0437\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0422\u0435\u0439\u043b\u043e\u0440\u0430 \u0438 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044e:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} \\approx \\sum_{i=1}^n \\left[g_i h_m(x_i) + \\frac{1}{2}h_i h_m^2(x_i)\\right] + \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2$$\n",
    "\n",
    "\u0413\u0440\u0443\u043f\u043f\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u043f\u043e \u043b\u0438\u0441\u0442\u044c\u044f\u043c. \u041f\u0443\u0441\u0442\u044c $I_j = \\{i | x_i \\in \\text{\u043b\u0438\u0441\u0442 } j\\}$:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} = \\sum_{j=1}^T \\left[\\left(\\sum_{i \\in I_j} g_i\\right) w_j + \\frac{1}{2}\\left(\\sum_{i \\in I_j} h_i + \\lambda\\right) w_j^2\\right] + \\gamma T$$\n",
    "\n",
    "\u041e\u0431\u043e\u0437\u043d\u0430\u0447\u0438\u043c:\n",
    "- $G_j = \\sum_{i \\in I_j} g_i$ - \u0441\u0443\u043c\u043c\u0430 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435 $j$\n",
    "- $H_j = \\sum_{i \\in I_j} h_i$ - \u0441\u0443\u043c\u043c\u0430 \u0432\u0442\u043e\u0440\u044b\u0445 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435 $j$\n",
    "\n",
    "\u0422\u043e\u0433\u0434\u0430:\n",
    "\n",
    "$$\\mathcal{L}^{(m)} = \\sum_{j=1}^T \\left[G_j w_j + \\frac{1}{2}(H_j + \\lambda) w_j^2\\right] + \\gamma T$$\n",
    "\n",
    "\u042d\u0442\u043e \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0438\u0447\u043d\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u0442 $w_j$! \u041c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u043e $w_j$:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}^{(m)}}{\\partial w_j} = G_j + (H_j + \\lambda)w_j = 0$$\n",
    "\n",
    "**\u041e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0432\u0435\u0441 \u043b\u0438\u0441\u0442\u0430:**\n",
    "\n",
    "$$w_j^* = -\\frac{G_j}{H_j + \\lambda}$$\n",
    "\n",
    "**\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f loss \u0434\u043b\u044f \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u0434\u0435\u0440\u0435\u0432\u0430:**\n",
    "\n",
    "$$\\mathcal{L}^{(m)*} = -\\frac{1}{2}\\sum_{j=1}^T \\frac{G_j^2}{H_j + \\lambda} + \\gamma T$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. \u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u0434\u0435\u0440\u0435\u0432\u0430 (Split Finding)**\n",
    "\n",
    "**\u0426\u0435\u043b\u044c:** \u041d\u0430\u0439\u0442\u0438 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 loss.\n",
    "\n",
    "\u0414\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u0438 \u043f\u043e\u0440\u043e\u0433\u0430 \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c **gain** (\u0443\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u0435 loss):\n",
    "\n",
    "$$\\text{Gain} = \\frac{1}{2}\\left[\\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{(G_L + G_R)^2}{H_L + H_R + \\lambda}\\right] - \\gamma$$\n",
    "\n",
    "\u0433\u0434\u0435:\n",
    "- $G_L, H_L$ - \u0441\u0443\u043c\u043c\u0430 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432/hessians \u0432 \u043b\u0435\u0432\u043e\u043c \u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u0435\n",
    "- $G_R, H_R$ - \u0432 \u043f\u0440\u0430\u0432\u043e\u043c \u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u0435\n",
    "- $\\gamma$ - \u0448\u0442\u0440\u0430\u0444 \u0437\u0430 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043d\u043e\u0432\u043e\u0433\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f\n",
    "\n",
    "**\u0418\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0446\u0438\u044f Gain:**\n",
    "\n",
    "1. **\u041f\u0435\u0440\u0432\u044b\u0439 \u0442\u0435\u0440\u043c\u0438\u043d:** Gain \u043e\u0442 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043d\u0430 \u0434\u0432\u0430 \u0443\u0437\u043b\u0430\n",
    "2. **\u0412\u0442\u043e\u0440\u043e\u0439 \u0442\u0435\u0440\u043c\u0438\u043d:** Loss \u0435\u0441\u043b\u0438 \u0431\u044b \u043d\u0435 \u0440\u0430\u0437\u0434\u0435\u043b\u044f\u043b\u0438 (\u043e\u0434\u0438\u043d \u0443\u0437\u0435\u043b)\n",
    "3. **\u0422\u0440\u0435\u0442\u0438\u0439 \u0442\u0435\u0440\u043c\u0438\u043d:** \u0428\u0442\u0440\u0430\u0444 \u0437\u0430 \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c\n",
    "\n",
    "**\u041a\u0440\u0438\u0442\u0435\u0440\u0438\u0439 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438:** \u0415\u0441\u043b\u0438 $\\text{Gain} < 0$, \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0435 \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u043c\u043e\u0434\u0435\u043b\u044c.\n",
    "\n",
    "**\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c (\u043f\u0441\u0435\u0432\u0434\u043e\u043a\u043e\u0434):**\n",
    "\n",
    "```\n",
    "def BuildTree(\u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u044b g, hessians h, \u0433\u043b\u0443\u0431\u0438\u043d\u0430):\n",
    "    if \u0433\u043b\u0443\u0431\u0438\u043d\u0430 > max_depth or len(g) < min_samples:\n",
    "        return \u041b\u0438\u0441\u0442 \u0441 \u0432\u0435\u0441\u043e\u043c w = -sum(g) / (sum(h) + lambda)\n",
    "    \n",
    "    best_gain = 0\n",
    "    best_split = None\n",
    "    \n",
    "    # \u041f\u0435\u0440\u0435\u0431\u043e\u0440 \u0432\u0441\u0435\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n",
    "    for \u043f\u0440\u0438\u0437\u043d\u0430\u043a in \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438:\n",
    "        # \u041f\u0435\u0440\u0435\u0431\u043e\u0440 \u0432\u0441\u0435\u0445 \u043f\u043e\u0440\u043e\u0433\u043e\u0432\n",
    "        for \u043f\u043e\u0440\u043e\u0433 in \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435_\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f(\u043f\u0440\u0438\u0437\u043d\u0430\u043a):\n",
    "            G_L = sum(g[\u043f\u0440\u0438\u0437\u043d\u0430\u043a <= \u043f\u043e\u0440\u043e\u0433])\n",
    "            H_L = sum(h[\u043f\u0440\u0438\u0437\u043d\u0430\u043a <= \u043f\u043e\u0440\u043e\u0433])\n",
    "            G_R = sum(g[\u043f\u0440\u0438\u0437\u043d\u0430\u043a > \u043f\u043e\u0440\u043e\u0433])\n",
    "            H_R = sum(h[\u043f\u0440\u0438\u0437\u043d\u0430\u043a > \u043f\u043e\u0440\u043e\u0433])\n",
    "            \n",
    "            gain = 0.5 * (G_L^2/(H_L + lambda) + G_R^2/(H_R + lambda) \n",
    "                         - (G_L + G_R)^2/(H_L + H_R + lambda)) - gamma\n",
    "            \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_split = (\u043f\u0440\u0438\u0437\u043d\u0430\u043a, \u043f\u043e\u0440\u043e\u0433)\n",
    "    \n",
    "    if best_gain == 0:\n",
    "        return \u041b\u0438\u0441\u0442 \u0441 \u0432\u0435\u0441\u043e\u043c w = -sum(g) / (sum(h) + lambda)\n",
    "    \n",
    "    \u043b\u0435\u0432\u043e\u0435_\u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u043e = BuildTree(g_left, h_left, \u0433\u043b\u0443\u0431\u0438\u043d\u0430+1)\n",
    "    \u043f\u0440\u0430\u0432\u043e\u0435_\u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u043e = BuildTree(g_right, h_right, \u0433\u043b\u0443\u0431\u0438\u043d\u0430+1)\n",
    "    \n",
    "    return \u0423\u0437\u0435\u043b(best_split, \u043b\u0435\u0432\u043e\u0435_\u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u043e, \u043f\u0440\u0430\u0432\u043e\u0435_\u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u043e)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**5. \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 XGBoost**\n",
    "\n",
    "**Column Subsampling:**\n",
    "- \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u0432\u044b\u0431\u043e\u0440 \u043f\u043e\u0434\u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0443\u0440\u043e\u0432\u043d\u0435/\u0434\u0435\u0440\u0435\u0432\u0435\n",
    "- \u0423\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435, \u0443\u0441\u043a\u043e\u0440\u044f\u0435\u0442 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n",
    "- \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b: `colsample_bytree`, `colsample_bylevel`, `colsample_bynode`\n",
    "\n",
    "**Row Subsampling:**\n",
    "- \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u0432\u044b\u0431\u043e\u0440 \u043f\u043e\u0434\u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u0430 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0434\u0435\u0440\u0435\u0432\u0430\n",
    "- \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440: `subsample` (\u043e\u0431\u044b\u0447\u043d\u043e 0.5-1.0)\n",
    "\n",
    "**Approximate Split Finding:**\n",
    "- \u0412\u043c\u0435\u0441\u0442\u043e \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0430 \u0432\u0441\u0435\u0445 \u043f\u043e\u0440\u043e\u0433\u043e\u0432, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u043a\u0432\u0430\u043d\u0442\u0438\u043b\u0438\n",
    "- \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440: `tree_method='approx'` \u0438\u043b\u0438 `'hist'`\n",
    "\n",
    "**Weighted Quantile Sketch:**\n",
    "- \u041a\u0432\u0430\u043d\u0442\u0438\u043b\u0438 \u0432\u0437\u0432\u0435\u0448\u0438\u0432\u0430\u044e\u0442\u0441\u044f \u043f\u043e hessian (\u0431\u043e\u043b\u044c\u0448\u0438\u0439 \u0432\u0435\u0441 = \u0432\u0430\u0436\u043d\u0435\u0435)\n",
    "- \u0423\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u0442 \u043d\u0435\u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0435 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432\n",
    "\n",
    "**Sparsity-Aware Split Finding:**\n",
    "- \u042d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u0430\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 missing values \u0438 \u0440\u0430\u0437\u0440\u0435\u0436\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n",
    "- \u0410\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0443\u0447\u0438\u0442\u0441\u044f \"\u043a\u0443\u0434\u0430 \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0442\u044c missing values\" (\u0432\u043b\u0435\u0432\u043e \u0438\u043b\u0438 \u0432\u043f\u0440\u0430\u0432\u043e)\n",
    "\n",
    "**Cache-Aware Access:**\n",
    "- \u0414\u0430\u043d\u043d\u044b\u0435 \u0445\u0440\u0430\u043d\u044f\u0442\u0441\u044f \u0432 \u0431\u043b\u043e\u043a\u0430\u0445, \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f CPU cache\n",
    "- \u0417\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0443\u0441\u043a\u043e\u0440\u044f\u0435\u0442 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n",
    "\n",
    "**Out-of-Core Computation:**\n",
    "- \u041c\u043e\u0436\u0435\u0442 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438, \u043d\u0435 \u043f\u043e\u043c\u0435\u0449\u0430\u044e\u0449\u0438\u043c\u0438\u0441\u044f \u0432 RAM\n",
    "- \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440: `tree_method='external'`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 \u041a\u043b\u044e\u0447\u0435\u0432\u044b\u0435 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b XGBoost\n",
    "\n",
    "#### \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0434\u0435\u0440\u0435\u0432\u0430 (Tree Parameters)\n",
    "\n",
    "| \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 | \u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 | \u0422\u0438\u043f\u0438\u0447\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f | \u0412\u043b\u0438\u044f\u043d\u0438\u0435 |\n",
    "|----------|----------|-------------------|----------|\n",
    "| `max_depth` | \u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430 | 3-10 | \u2191 \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u2192 \u2191 \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c, \u2191 overfitting |\n",
    "| `min_child_weight` | \u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0441\u0443\u043c\u043c\u0430 hessian \u0432 \u043b\u0438\u0441\u0442\u0435 | 1-10 | \u2191 \u0432\u0435\u0441 \u2192 \u0431\u043e\u043b\u0435\u0435 \u043a\u043e\u043d\u0441\u0435\u0440\u0432\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f |\n",
    "| `gamma` | \u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 gain \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f | 0-5 | \u2191 gamma \u2192 \u043c\u0435\u043d\u044c\u0448\u0435 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439, \u2193 overfitting |\n",
    "| `subsample` | \u0414\u043e\u043b\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0434\u0435\u0440\u0435\u0432\u0430 | 0.5-1.0 | < 1 \u2192 \u2193 overfitting, \u043d\u043e \u2191 \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044f |\n",
    "| `colsample_bytree` | \u0414\u043e\u043b\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0434\u0435\u0440\u0435\u0432\u0430 | 0.3-1.0 | < 1 \u2192 \u2193 overfitting, \u2191 \u0440\u0430\u0437\u043d\u043e\u043e\u0431\u0440\u0430\u0437\u0438\u0435 |\n",
    "| `colsample_bylevel` | \u0414\u043e\u043b\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0443\u0440\u043e\u0432\u043d\u044f | 0.3-1.0 | \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f |\n",
    "\n",
    "#### \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n",
    "\n",
    "| \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 | \u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 | \u0422\u0438\u043f\u0438\u0447\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f |\n",
    "|----------|----------|-------------------|\n",
    "| `lambda` (L2) | $\\lambda$ \u0432 \u0444\u043e\u0440\u043c\u0443\u043b\u0435 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438 | 0-10 |\n",
    "| `alpha` (L1) | L1 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043d\u0430 \u0432\u0435\u0441\u0430 | 0-10 |\n",
    "| `max_delta_step` | \u041e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u0448\u0430\u0433 \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f | 0-10 (0 = \u043d\u0435\u0442 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f) |\n",
    "\n",
    "#### \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\n",
    "\n",
    "| \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 | \u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 | \u0422\u0438\u043f\u0438\u0447\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f | \u0412\u043b\u0438\u044f\u043d\u0438\u0435 |\n",
    "|----------|----------|-------------------|----------|\n",
    "| `learning_rate` (\u03b7) | \u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f (shrinkage) | 0.01-0.3 | \u2193 lr \u2192 \u043d\u0443\u0436\u043d\u043e \u0431\u043e\u043b\u044c\u0448\u0435 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432, \u043d\u043e \u043b\u0443\u0447\u0448\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e |\n",
    "| `n_estimators` | \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 | 100-10000 | \u2191 \u0434\u0435\u0440\u0435\u0432\u044c\u044f + \u2193 lr = \u043b\u0443\u0447\u0448\u0435\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e |\n",
    "| `early_stopping_rounds` | \u041e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0435\u0441\u043b\u0438 \u043d\u0435\u0442 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f | 10-50 | \u041f\u0440\u0435\u0434\u043e\u0442\u0432\u0440\u0430\u0449\u0430\u0435\u0442 overfitting |\n",
    "\n",
    "#### \u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0438 \u0442\u044e\u043d\u0438\u043d\u0433\u0430\n",
    "\n",
    "**\u042d\u0442\u0430\u043f 1: \u0424\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u0432\u044b\u0441\u043e\u043a\u0438\u0439 learning rate (0.1)**\n",
    "- \u0422\u044e\u043d\u0438\u043c: `max_depth`, `min_child_weight`\n",
    "- \u0426\u0435\u043b\u044c: \u041d\u0430\u0439\u0442\u0438 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u0443\u044e \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0434\u0435\u0440\u0435\u0432\u0430\n",
    "\n",
    "**\u042d\u0442\u0430\u043f 2: \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c sampling**\n",
    "- \u0422\u044e\u043d\u0438\u043c: `subsample`, `colsample_bytree`\n",
    "- \u0426\u0435\u043b\u044c: \u0423\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c \u0440\u0430\u0437\u043d\u043e\u043e\u0431\u0440\u0430\u0437\u0438\u0435 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432\n",
    "\n",
    "**\u042d\u0442\u0430\u043f 3: \u0420\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f**\n",
    "- \u0422\u044e\u043d\u0438\u043c: `gamma`, `lambda`, `alpha`\n",
    "- \u0426\u0435\u043b\u044c: Fine-tune \u0431\u043e\u0440\u044c\u0431\u044b \u0441 overfitting\n",
    "\n",
    "**\u042d\u0442\u0430\u043f 4: \u0421\u043d\u0438\u0436\u0430\u0435\u043c learning rate**\n",
    "- \u0423\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c `learning_rate` \u0434\u043e 0.01-0.05\n",
    "- \u0423\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u043c `n_estimators` \u043f\u0440\u043e\u043f\u043e\u0440\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\n",
    "- \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c `early_stopping_rounds`\n",
    "- \u0426\u0435\u043b\u044c: \u0424\u0438\u043d\u0430\u043b\u044c\u043d\u0430\u044f \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 \u0418\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0446\u0438\u044f Feature Importance\n",
    "\n",
    "XGBoost \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 3 \u0442\u0438\u043f\u0430 feature importance:\n",
    "\n",
    "#### 1. Weight (Frequency)\n",
    "\n",
    "$$\\text{Importance}_{weight}(k) = \\frac{\\text{\u0447\u0438\u0441\u043b\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439 \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0443 } k}{\\text{\u043e\u0431\u0449\u0435\u0435 \u0447\u0438\u0441\u043b\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439}}$$\n",
    "\n",
    "**\u041a\u043e\u0433\u0434\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c:** \u0411\u044b\u0441\u0442\u0440\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430, \u043a\u0430\u043a\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0447\u0430\u0441\u0442\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442\u0441\u044f.\n",
    "\n",
    "**\u041d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043a\u0438:** \u041d\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u0442, \u043d\u0430\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u043e\u043b\u0435\u0437\u043d\u044b \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f.\n",
    "\n",
    "#### 2. Gain (Average Information Gain)\n",
    "\n",
    "$$\\text{Importance}_{gain}(k) = \\sum_{\\text{splits by } k} \\text{Gain}$$\n",
    "\n",
    "\u0421\u0440\u0435\u0434\u043d\u0438\u0439 gain \u043e\u0442 \u0432\u0441\u0435\u0445 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439 \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0443 $k$.\n",
    "\n",
    "**\u041a\u043e\u0433\u0434\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c:** \u041f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442, \u043a\u0430\u043a\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0434\u0430\u044e\u0442 \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0435\u0435 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u0435 loss.\n",
    "\n",
    "**\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u0442\u0441\u044f \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e!**\n",
    "\n",
    "#### 3. Cover (Sum of Hessian)\n",
    "\n",
    "$$\\text{Importance}_{cover}(k) = \\sum_{\\text{splits by } k} H_L + H_R$$\n",
    "\n",
    "\u0421\u0443\u043c\u043c\u0430 \u0432\u0442\u043e\u0440\u044b\u0445 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 (hessian) \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439 \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0443.\n",
    "\n",
    "**\u0418\u043d\u0442\u0443\u0438\u0446\u0438\u044f:** Hessian = \"\u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u00d7 \u0438\u0445 \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u044c\". \u041f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u043f\u043e\u043a\u0440\u044b\u0432\u0430\u044e\u0449\u0438\u0435 \u0432\u0430\u0436\u043d\u044b\u0435 \u043f\u0440\u0438\u043c\u0435\u0440\u044b, \u043f\u043e\u043b\u0443\u0447\u0430\u044e\u0442 \u0432\u044b\u0441\u043e\u043a\u0438\u0439 cover.\n",
    "\n",
    "**\u041a\u043e\u0433\u0434\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c:** \u0423\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u0442 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u0435, \u043d\u043e \u0438 \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0437\u0430\u0442\u0440\u043e\u043d\u0443\u0442\u043e.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.8 XGBoost vs \u0434\u0440\u0443\u0433\u0438\u0435 \u043c\u0435\u0442\u043e\u0434\u044b\n",
    "\n",
    "| \u0410\u0441\u043f\u0435\u043a\u0442 | Random Forest | Gradient Boosting | XGBoost | LightGBM | CatBoost |\n",
    "|--------|---------------|-------------------|---------|----------|----------|\n",
    "| **\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f** | \u041f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u044b\u0435 \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u044b\u0435 \u0434\u0435\u0440\u0435\u0432\u044c\u044f | \u041f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0434\u0435\u0440\u0435\u0432\u044c\u044f | GBM + regularization | Leaf-wise growth | Ordered boosting |\n",
    "| **\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c** | \u0411\u044b\u0441\u0442\u0440\u043e | \u041c\u0435\u0434\u043b\u0435\u043d\u043d\u043e | \u0411\u044b\u0441\u0442\u0440\u043e | \u041e\u0447\u0435\u043d\u044c \u0431\u044b\u0441\u0442\u0440\u043e | \u0421\u0440\u0435\u0434\u043d\u0435 |\n",
    "| **\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c** | \u0425\u043e\u0440\u043e\u0448\u043e | \u041e\u0447\u0435\u043d\u044c \u0445\u043e\u0440\u043e\u0448\u043e | \u041e\u0442\u043b\u0438\u0447\u043d\u043e | \u041e\u0442\u043b\u0438\u0447\u043d\u043e | \u041e\u0442\u043b\u0438\u0447\u043d\u043e |\n",
    "| **Overfitting** | \u0423\u0441\u0442\u043e\u0439\u0447\u0438\u0432 | \u0421\u043a\u043b\u043e\u043d\u0435\u043d | \u0421\u0440\u0435\u0434\u043d\u0435 (\u0438\u0437-\u0437\u0430 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438) | \u0421\u043a\u043b\u043e\u043d\u0435\u043d | \u0423\u0441\u0442\u043e\u0439\u0447\u0438\u0432 |\n",
    "| **\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438** | One-hot | One-hot | One-hot | Native support | Native support |\n",
    "| **Missing values** | \u041d\u0435\u0442 | \u041d\u0435\u0442 | \u0410\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438 | \u0410\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438 | \u0410\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438 |\n",
    "| **\u0418\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0446\u0438\u044f** | \u0421\u0440\u0435\u0434\u043d\u0435 | \u0425\u043e\u0440\u043e\u0448\u043e | \u0425\u043e\u0440\u043e\u0448\u043e | \u0425\u043e\u0440\u043e\u0448\u043e | \u0425\u043e\u0440\u043e\u0448\u043e |\n",
    "\n",
    "**\u041a\u043e\u0433\u0434\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c XGBoost:**\n",
    "- \u2705 \u041d\u0443\u0436\u043d\u0430 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0442\u0430\u0431\u043b\u0438\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n",
    "- \u2705 \u0415\u0441\u0442\u044c \u0432\u0440\u0435\u043c\u044f \u043d\u0430 \u0442\u044e\u043d\u0438\u043d\u0433 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\n",
    "- \u2705 \u0414\u0430\u0442\u0430\u0441\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 (10k-1M \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432)\n",
    "- \u2705 \u0412\u0430\u0436\u043d\u0430 \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0438\u0440\u0443\u0435\u043c\u043e\u0441\u0442\u044c\n",
    "- \u274c \u041d\u0443\u0436\u043d\u0430 \u043e\u0447\u0435\u043d\u044c \u0431\u044b\u0441\u0442\u0440\u0430\u044f \u0438\u043d\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u044f (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 Random Forest)\n",
    "- \u274c \u041e\u0447\u0435\u043d\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 >10M \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 LightGBM)\n",
    "- \u274c \u041c\u043d\u043e\u0433\u043e \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 CatBoost)\n",
    "\n",
    "---\n",
    "\n",
    "## \u0422\u0435\u043e\u0440\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0447\u0430\u0441\u0442\u044c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0430! \u041f\u0435\u0440\u0435\u0445\u043e\u0434\u0438\u043c \u043a \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0435 \ud83d\ude80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca \u0427\u0430\u0441\u0442\u044c 2: \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0430\u043d\u0430\u043b\u0438\u0437\n",
    "\n",
    "### 2.1 \u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Baseline \u043c\u043e\u0434\u0435\u043b\u0438 \u0434\u043b\u044f \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044f\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Seed \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print('\u2705 \u0411\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d\u044b')\n",
    "print(f'XGBoost version: {xgb.__version__}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}