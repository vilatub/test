#!/usr/bin/env python3
"""
Phase 4 Step 3: Temporal Fusion Transformer
Part 1: Introduction, Theory, Dataset
"""

import json

# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–æ—É—Ç–±—É–∫–∞
notebook = {
    "cells": [],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

cells = []

# ============================================================================
# TITLE AND INTRODUCTION
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "# üîÆ Temporal Fusion Transformer (TFT)\n",
        "\n",
        "**Phase 4, Step 3: Advanced Transformers for Time Series**\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∑–Ω–∞–Ω–∏—è!\n",
        "\n",
        "### –ß—Ç–æ –º—ã –∏–∑—É—á–∏–ª–∏ –¥–æ —Å–∏—Ö –ø–æ—Ä:\n",
        "\n",
        "**Phase 3: Temporal Data & RNN**\n",
        "- ‚úÖ Classical Time Series (ARIMA, SARIMA, Prophet)\n",
        "- ‚úÖ RNN/LSTM/GRU –¥–ª—è sequences\n",
        "- ‚úÖ Attention & Seq2Seq\n",
        "- ‚ùå –ù–æ: short-term forecasting, univariate/simple multivariate\n",
        "\n",
        "**Phase 4 Step 1: Self-Attention & Transformers**\n",
        "- ‚úÖ Scaled Dot-Product Attention\n",
        "- ‚úÖ Multi-Head Attention\n",
        "- ‚úÖ Transformer Encoder\n",
        "- ‚ùå –ù–æ: –ø—Ä–∏–º–µ–Ω—è–ª–∏ –∫ —Ç–∞–±–ª–∏—á–Ω—ã–º –¥–∞–Ω–Ω—ã–º, –Ω–µ –∫ time series\n",
        "\n",
        "**Phase 4 Step 2: TabTransformer**\n",
        "- ‚úÖ Contextual embeddings –¥–ª—è categorical features\n",
        "- ‚úÖ Attention –º–µ–∂–¥—É features\n",
        "- ‚úÖ Large dataset (48k samples)\n",
        "- ‚ùå –ù–æ: static data, –Ω–µ temporal\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Enter Temporal Fusion Transformer (2020)\n",
        "\n",
        "**\"Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting\"**  \n",
        "(Lim et al., Google Research)\n",
        "\n",
        "**–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è:** –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –ª—É—á—à–µ–µ –∏–∑ –≤—Å–µ—Ö –º–∏—Ä–æ–≤!\n",
        "\n",
        "```\n",
        "TFT = RNN/LSTM + Transformers + Variable Selection + Multi-Horizon\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìê –ß—Ç–æ –¥–µ–ª–∞–µ—Ç TFT —É–Ω–∏–∫–∞–ª—å–Ω—ã–º?\n",
        "\n",
        "### 1. Multi-Horizon Forecasting\n",
        "\n",
        "**Problem:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–µ 1 step, –∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 24 —á–∞—Å–∞ –≤–ø–µ—Ä–µ–¥)\n",
        "\n",
        "**Traditional approaches:**\n",
        "- Recursive: predict t+1, use it to predict t+2, etc. (error accumulation!)\n",
        "- Direct: train separate models for each horizon (expensive!)\n",
        "\n",
        "**TFT solution:**\n",
        "- Single model predicts all horizons simultaneously\n",
        "- Quantile forecasting (uncertainty estimates)\n",
        "- No error accumulation\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Mixed Data Types\n",
        "\n",
        "**Time series —á–∞—Å—Ç–æ –∏–º–µ—é—Ç:**\n",
        "- Static covariates: category, location (–Ω–µ –º–µ–Ω—è—é—Ç—Å—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏)\n",
        "- Known future inputs: day_of_week, hour, holidays (–∏–∑–≤–µ—Å—Ç–Ω—ã –∑–∞—Ä–∞–Ω–µ–µ)\n",
        "- Unknown future inputs: weather (–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã, —Ç–æ–ª—å–∫–æ historical)\n",
        "- Target: —á—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º\n",
        "\n",
        "**–ü—Ä–∏–º–µ—Ä: Electricity Demand Forecasting**\n",
        "```\n",
        "Static:     building_id, region\n",
        "Known:      hour, day_of_week, is_holiday, temperature_forecast\n",
        "Unknown:    actual_temperature, humidity (—Ç–æ–ª—å–∫–æ historical)\n",
        "Target:     electricity_consumption\n",
        "```\n",
        "\n",
        "**TFT handles all types!**\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Variable Selection Networks\n",
        "\n",
        "**Problem:** –ù–µ –≤—Å–µ features –≤–∞–∂–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ prediction\n",
        "\n",
        "**Solution:** Gated Residual Networks (GRN) –¥–ª—è automatic feature selection\n",
        "- –ú–æ–¥–µ–ª—å —Å–∞–º–∞ –≤—ã–±–∏—Ä–∞–µ—Ç, –∫–∞–∫–∏–µ features –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å\n",
        "- Interpretability: –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫–∏–µ features –≤–∞–∂–Ω—ã\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Interpretable Multi-Head Attention\n",
        "\n",
        "**Problem:** Black box predictions\n",
        "\n",
        "**Solution:**\n",
        "- Self-Attention –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞ –∫–∞–∫–∏–µ timesteps –º–æ–¥–µ–ª—å —Å–º–æ—Ç—Ä–∏—Ç\n",
        "- Variable importance weights\n",
        "- Quantile predictions (uncertainty)\n",
        "\n",
        "**Result:** –ú–æ–∂–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ!\n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è TFT Architecture Overview\n",
        "\n",
        "```\n",
        "Inputs: [Static, Known Past, Known Future, Unknown Past]\n",
        "   ‚Üì\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 1. Variable Selection Networks          ‚îÇ\n",
        "‚îÇ    - Select relevant features            ‚îÇ\n",
        "‚îÇ    - Gated Residual Networks (GRN)      ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                   ‚Üì\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 2. LSTM Encoder-Decoder                 ‚îÇ\n",
        "‚îÇ    - Process past sequence               ‚îÇ\n",
        "‚îÇ    - Generate context for future        ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                   ‚Üì\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 3. Multi-Head Attention                 ‚îÇ\n",
        "‚îÇ    - Long-range dependencies            ‚îÇ\n",
        "‚îÇ    - Interpretable attention weights    ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                   ‚Üì\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 4. Gated Linear Unit + Layer Norm       ‚îÇ\n",
        "‚îÇ    - Residual connections                ‚îÇ\n",
        "‚îÇ    - Skip connections                    ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                   ‚Üì\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 5. Output: Multi-Horizon Predictions    ‚îÇ\n",
        "‚îÇ    - Quantile forecasts (P10, P50, P90) ‚îÇ\n",
        "‚îÇ    - All horizons simultaneously         ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Use Cases\n",
        "\n",
        "**TFT –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¥–ª—è:**\n",
        "- ‚ö° Electricity load forecasting\n",
        "- üå§Ô∏è Weather prediction\n",
        "- üí∞ Financial market forecasting\n",
        "- üöó Traffic prediction\n",
        "- üè• Hospital resource planning\n",
        "- üì¶ Demand forecasting (retail/supply chain)\n",
        "\n",
        "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**\n",
        "- Multi-step ahead predictions\n",
        "- Multiple time series (panel data)\n",
        "- Mixed categorical + numerical features\n",
        "- Interpretability –≤–∞–∂–Ω–∞\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ –ß—Ç–æ –º—ã —Ä–µ–∞–ª–∏–∑—É–µ–º\n",
        "\n",
        "–í —ç—Ç–æ–º notebook:\n",
        "\n",
        "### 1. Dataset: Electricity Consumption (Simplified)\n",
        "- –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
        "- ~10,000 timesteps, multiple households\n",
        "- Categorical: household_id, day_of_week\n",
        "- Numerical: hour, temperature\n",
        "- Target: electricity_consumption\n",
        "\n",
        "### 2. Simplified TFT Implementation\n",
        "- Variable Selection Networks (GRN)\n",
        "- LSTM Encoder\n",
        "- Multi-Head Attention\n",
        "- Multi-horizon output (predict 24 hours)\n",
        "\n",
        "### 3. Training & Evaluation\n",
        "- Quantile Loss (P10, P50, P90)\n",
        "- Multi-horizon metrics\n",
        "- Attention visualization\n",
        "- Variable importance\n",
        "\n",
        "### 4. Comparison\n",
        "- LSTM baseline\n",
        "- Prophet (from Phase 3)\n",
        "- TFT (full power)\n",
        "\n",
        "---\n"
    ]
})

# ============================================================================
# IMPORTS
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "## üíª –ß–∞—Å—Ç—å 1: Setup –∏ Dataset\n",
        "\n",
        "### 1.1 –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# –ë–∞–∑–æ–≤—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Math\n",
        "import math\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"\\n‚úÖ –í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")"
    ]
})

# ============================================================================
# SYNTHETIC DATASET CREATION
# ============================================================================

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 1.2 –°–æ–∑–¥–∞–Ω–∏–µ Synthetic Electricity Dataset\n",
        "\n",
        "**–°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**\n",
        "- 10 households (multiple time series)\n",
        "- 365 days √ó 24 hours = 8,760 timesteps per household\n",
        "- Total: 87,600 data points\n",
        "\n",
        "**Features:**\n",
        "- Static: household_id\n",
        "- Known future: hour, day_of_week, is_weekend\n",
        "- Unknown (historical only): temperature\n",
        "- Target: electricity_consumption (kWh)\n",
        "\n",
        "**Patterns:**\n",
        "- Daily seasonality (peak during evening)\n",
        "- Weekly seasonality (weekend vs weekday)\n",
        "- Temperature dependency\n",
        "- Random household baseline"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "def create_electricity_dataset(n_households=10, n_days=365):\n",
        "    \"\"\"\n",
        "    Create synthetic electricity consumption dataset\n",
        "    \"\"\"\n",
        "    print(f\"Creating dataset: {n_households} households, {n_days} days\")\n",
        "    \n",
        "    # Generate timestamps\n",
        "    start_date = datetime(2023, 1, 1)\n",
        "    timestamps = [start_date + timedelta(hours=h) for h in range(n_days * 24)]\n",
        "    \n",
        "    data_list = []\n",
        "    \n",
        "    for household_id in range(n_households):\n",
        "        # Random household baseline (some consume more than others)\n",
        "        baseline = np.random.uniform(2, 5)\n",
        "        \n",
        "        for i, ts in enumerate(timestamps):\n",
        "            hour = ts.hour\n",
        "            day_of_week = ts.weekday()\n",
        "            is_weekend = 1 if day_of_week >= 5 else 0\n",
        "            day_of_year = ts.timetuple().tm_yday\n",
        "            \n",
        "            # Temperature (seasonal + daily variation)\n",
        "            temp = 15 + 10 * np.sin(2 * np.pi * day_of_year / 365) + \\\n",
        "                   3 * np.sin(2 * np.pi * hour / 24) + \\\n",
        "                   np.random.normal(0, 2)\n",
        "            \n",
        "            # Electricity consumption pattern\n",
        "            # 1. Baseline\n",
        "            consumption = baseline\n",
        "            \n",
        "            # 2. Daily pattern (peak in evening 18-22h)\n",
        "            if 6 <= hour <= 8:  # Morning peak\n",
        "                consumption += 2\n",
        "            elif 18 <= hour <= 22:  # Evening peak\n",
        "                consumption += 4\n",
        "            elif 0 <= hour <= 6:  # Night low\n",
        "                consumption -= 1\n",
        "            \n",
        "            # 3. Weekend effect (more consumption during day)\n",
        "            if is_weekend and 10 <= hour <= 20:\n",
        "                consumption += 1.5\n",
        "            \n",
        "            # 4. Temperature effect (heating/cooling)\n",
        "            if temp < 10:  # Heating\n",
        "                consumption += (10 - temp) * 0.2\n",
        "            elif temp > 25:  # Cooling\n",
        "                consumption += (temp - 25) * 0.3\n",
        "            \n",
        "            # 5. Random noise\n",
        "            consumption += np.random.normal(0, 0.5)\n",
        "            \n",
        "            # 6. Ensure positive\n",
        "            consumption = max(0, consumption)\n",
        "            \n",
        "            data_list.append({\n",
        "                'timestamp': ts,\n",
        "                'household_id': household_id,\n",
        "                'hour': hour,\n",
        "                'day_of_week': day_of_week,\n",
        "                'is_weekend': is_weekend,\n",
        "                'temperature': temp,\n",
        "                'consumption': consumption\n",
        "            })\n",
        "    \n",
        "    df = pd.DataFrame(data_list)\n",
        "    print(f\"‚úÖ Dataset created: {len(df):,} rows\")\n",
        "    return df\n",
        "\n",
        "# Create dataset\n",
        "df = create_electricity_dataset(n_households=10, n_days=365)\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()"
    ]
})

cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### 1.3 Exploratory Data Analysis"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Basic statistics\n",
        "print(\"Dataset Statistics:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total samples: {len(df):,}\")\n",
        "print(f\"Number of households: {df['household_id'].nunique()}\")\n",
        "print(f\"Time range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "print(f\"\\nConsumption statistics (kWh):\")\n",
        "print(df['consumption'].describe())\n",
        "print(f\"\\nTemperature statistics (¬∞C):\")\n",
        "print(df['temperature'].describe())\n",
        "print(\"=\"*60)"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Visualize consumption patterns\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# 1. Time series for one household\n",
        "household_0 = df[df['household_id'] == 0].copy()\n",
        "axes[0, 0].plot(household_0['timestamp'], household_0['consumption'], \n",
        "               linewidth=0.5, alpha=0.7)\n",
        "axes[0, 0].set_title('Electricity Consumption: Household 0 (1 year)', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Date')\n",
        "axes[0, 0].set_ylabel('Consumption (kWh)')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# 2. Average by hour of day\n",
        "hourly_avg = df.groupby('hour')['consumption'].mean()\n",
        "axes[0, 1].bar(hourly_avg.index, hourly_avg.values, color='steelblue', alpha=0.7)\n",
        "axes[0, 1].set_title('Average Consumption by Hour of Day', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Hour')\n",
        "axes[0, 1].set_ylabel('Avg Consumption (kWh)')\n",
        "axes[0, 1].grid(alpha=0.3, axis='y')\n",
        "\n",
        "# 3. Average by day of week\n",
        "dow_avg = df.groupby('day_of_week')['consumption'].mean()\n",
        "dow_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "axes[1, 0].bar(dow_names, dow_avg.values, color='orange', alpha=0.7)\n",
        "axes[1, 0].set_title('Average Consumption by Day of Week', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Day of Week')\n",
        "axes[1, 0].set_ylabel('Avg Consumption (kWh)')\n",
        "axes[1, 0].grid(alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Consumption vs Temperature\n",
        "axes[1, 1].hexbin(df['temperature'], df['consumption'], gridsize=30, cmap='YlOrRd')\n",
        "axes[1, 1].set_title('Consumption vs Temperature', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Temperature (¬∞C)')\n",
        "axes[1, 1].set_ylabel('Consumption (kWh)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Observations:\")\n",
        "print(\"  - Clear daily pattern: peaks at morning (6-8h) and evening (18-22h)\")\n",
        "print(\"  - Weekend effect: slightly higher consumption\")\n",
        "print(\"  - Temperature dependency: U-shaped (heating + cooling)\")\n",
        "print(\"  - Multiple seasonalities: hourly, daily, weekly\")"
    ]
})

cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Visualize one week in detail\n",
        "one_week = household_0.iloc[:24*7].copy()\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True)\n",
        "\n",
        "# Consumption\n",
        "axes[0].plot(one_week['timestamp'], one_week['consumption'], \n",
        "            linewidth=2, marker='o', markersize=3, label='Consumption')\n",
        "axes[0].set_title('One Week Detail: Household 0', fontsize=16, fontweight='bold')\n",
        "axes[0].set_ylabel('Consumption (kWh)', fontsize=12)\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Temperature\n",
        "axes[1].plot(one_week['timestamp'], one_week['temperature'], \n",
        "            linewidth=2, marker='o', markersize=3, color='orange', label='Temperature')\n",
        "axes[1].set_xlabel('Time', fontsize=12)\n",
        "axes[1].set_ylabel('Temperature (¬∞C)', fontsize=12)\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Weekly pattern visible:\")\n",
        "print(\"  - Daily cycles clear\")\n",
        "print(\"  - Temperature correlation\")\n",
        "print(\"  - Perfect for multi-horizon forecasting!\")"
    ]
})

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å
notebook['cells'] = cells

output_path = '/home/user/test/notebooks/phase4_transformers/03_temporal_fusion_transformer.ipynb'
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f'‚úÖ Part 1 —Å–æ–∑–¥–∞–Ω–∞: {output_path}')
print(f'–Ø—á–µ–µ–∫: {len(cells)}')
print('–°–ª–µ–¥—É—é—â–∞—è —á–∞—Å—Ç—å: Data Preparation –∏ TFT Components...')
