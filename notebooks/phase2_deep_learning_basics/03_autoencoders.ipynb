{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÑ Autoencoders: Unsupervised Deep Learning\n",
    "\n",
    "**Phase 2: Deep Learning Basics - Step 3 (FINALE)**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ –¶–µ–ª–∏ –Ω–æ—É—Ç–±—É–∫–∞\n",
    "\n",
    "1. **Vanilla Autoencoder:** –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "2. **Denoising Autoencoder:** –û–±—É—á–µ–Ω–∏–µ —Ä–æ–±–∞—Å—Ç–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º\n",
    "3. **Variational Autoencoder (VAE):** –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "4. **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è:** Anomaly detection, dimensionality reduction, data generation\n",
    "\n",
    "---\n",
    "\n",
    "## üíº –ë–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–∏ –¥–ª—è Autoencoders\n",
    "\n",
    "**1. Anomaly Detection (–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π):**\n",
    "- üè¶ Fraud detection (–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ –≤ –±–∞–Ω–∫–∞—Ö)\n",
    "- üè≠ Defect detection (–¥–µ—Ñ–µ–∫—Ç—ã –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ)\n",
    "- üîí Intrusion detection (–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)\n",
    "\n",
    "**2. Dimensionality Reduction:**\n",
    "- üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚ö° Preprocessing –¥–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π\n",
    "- üíæ –°–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**3. Data Generation (VAE):**\n",
    "- üé® –°–∏–Ω—Ç–µ–∑ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "- üß¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–ª–µ–∫—É–ª (drug discovery)\n",
    "- üé≠ Creative applications\n",
    "\n",
    "**–ü–æ—á–µ–º—É Unsupervised?**\n",
    "- ‚úÖ –ù–µ –Ω—É–∂–Ω—ã –º–µ—Ç–∫–∏ (labels)\n",
    "- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ª—é–±—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚úÖ –ù–∞—Ö–æ–¥–∏—Ç —Å–∫—Ä—ã—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö –ß–∞—Å—Ç—å 1: –¢–µ–æ—Ä–∏—è Autoencoders\n",
    "\n",
    "### 1.1 Vanilla Autoencoder - –ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "\n",
    "**Autoencoder** ‚Äî –Ω–µ–π—Ä–æ—Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –æ–±—É—á–∞–µ—Ç—Å—è **–≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –≤—Ö–æ–¥** —á–µ—Ä–µ–∑ —É–∑–∫–æ–µ bottleneck.\n",
    "\n",
    "#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "\n",
    "```\n",
    "Input (x) ‚Üí Encoder ‚Üí Latent (z) ‚Üí Decoder ‚Üí Output (xÃÇ)\n",
    "```\n",
    "\n",
    "**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z &= f_{\\text{enc}}(x; \\theta_{\\text{enc}}) \\quad \\text{(Encoder)} \\\\\n",
    "\\hat{x} &= f_{\\text{dec}}(z; \\theta_{\\text{dec}}) \\quad \\text{(Decoder)} \\\\\n",
    "\\mathcal{L} &= \\|x - \\hat{x}\\|^2 \\quad \\text{(Reconstruction loss)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "- $x$ ‚Äî –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–∞—Å—Å–∞–∂–∏—Ä –¢–∏—Ç–∞–Ω–∏–∫–∞)\n",
    "- $z$ ‚Äî latent representation (—Å–∂–∞—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ)\n",
    "- $\\hat{x}$ ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "- $\\theta$ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∏\n",
    "\n",
    "#### –ó–∞—á–µ–º bottleneck (—É–∑–∫–æ–µ –º–µ—Å—Ç–æ)?\n",
    "\n",
    "**–ï—Å–ª–∏ latent —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å < input —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:**\n",
    "- ‚úÖ **Compression:** –°–µ—Ç—å –≤—ã–Ω—É–∂–¥–µ–Ω–∞ –≤—ã—É—á–∏—Ç—å **–∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ** –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ\n",
    "- ‚úÖ **Feature learning:** Latent space —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "- ‚úÖ **Dimensionality reduction:** –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ PCA\n",
    "\n",
    "**–ï—Å–ª–∏ latent —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å ‚â• input —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:**\n",
    "- ‚ùå **Identity mapping:** –°–µ—Ç—å –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ—Ç –≤—Ö–æ–¥ (–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ)\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä:**\n",
    "```\n",
    "Input: 10 features ‚Üí Encoder: [10 ‚Üí 8 ‚Üí 4] ‚Üí Latent: 2\n",
    "                  ‚Üí Decoder: [2 ‚Üí 4 ‚Üí 8] ‚Üí Output: 10 features\n",
    "```\n",
    "\n",
    "–°–∂–∞–ª–∏ 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí 2 latent dimensions!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Denoising Autoencoder\n",
    "\n",
    "**–ü—Ä–æ–±–ª–µ–º–∞ Vanilla AE:** –ú–æ–∂–µ—Ç –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (overfitting).\n",
    "\n",
    "**–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª—è–µ–º **—à—É–º** –∫ –≤—Ö–æ–¥—É, –∑–∞—Å—Ç–∞–≤–ª—è–µ–º –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å **—á–∏—Å—Ç—ã–µ** –¥–∞–Ω–Ω—ã–µ.\n",
    "\n",
    "#### –ê–ª–≥–æ—Ä–∏—Ç–º\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tilde{x} &= x + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2) \\quad \\text{(Add noise)} \\\\\n",
    "z &= f_{\\text{enc}}(\\tilde{x}) \\\\\n",
    "\\hat{x} &= f_{\\text{dec}}(z) \\\\\n",
    "\\mathcal{L} &= \\|x - \\hat{x}\\|^2 \\quad \\text{(Reconstruct CLEAN data!)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**–≠—Ñ—Ñ–µ–∫—Ç:**\n",
    "- ‚úÖ **Robustness:** –°–µ—Ç—å —É—á–∏—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–µ –∫ —à—É–º—É –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "- ‚úÖ **Regularization:** –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–µ –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ\n",
    "- ‚úÖ **Better features:** Latent space –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω\n",
    "\n",
    "**–¢–∏–ø—ã —à—É–º–∞:**\n",
    "1. **Gaussian noise:** $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "2. **Masking noise:** –°–ª—É—á–∞–π–Ω–æ –∑–∞–Ω—É–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "3. **Salt-and-pepper:** –°–ª—É—á–∞–π–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã\n",
    "\n",
    "**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**\n",
    "- üîä **Audio denoising:** –û—á–∏—Å—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π –æ—Ç —à—É–º–∞\n",
    "- üñºÔ∏è **Image denoising:** –£–¥–∞–ª–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤\n",
    "- üìä **Data cleaning:** –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Variational Autoencoder (VAE)\n",
    "\n",
    "**Vanilla AE –ø—Ä–æ–±–ª–µ–º–∞:** Latent space –º–æ–∂–µ—Ç –±—ã—Ç—å **–Ω–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º** ‚Äî –Ω–µ–±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ $z$ –¥–∞—é—Ç –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
    "\n",
    "**VAE —Ä–µ—à–µ–Ω–∏–µ:** –í–º–µ—Å—Ç–æ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ $z$, –∏—Å–ø–æ–ª—å–∑—É–µ–º **—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ** $p(z|x)$.\n",
    "\n",
    "#### –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞\n",
    "\n",
    "**–¶–µ–ª—å:** –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å $\\log p(x)$ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö).\n",
    "\n",
    "**–ü—Ä–æ–±–ª–µ–º–∞:** $p(x) = \\int p(x|z) p(z) dz$ ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞–ª –Ω–µ—Ä–∞–∑—Ä–µ—à–∏–º.\n",
    "\n",
    "**–†–µ—à–µ–Ω–∏–µ:** Variational Inference ‚Äî –ø—Ä–∏–±–ª–∏–∂–∞–µ–º $p(z|x)$ —Å –ø–æ–º–æ—â—å—é $q(z|x)$.\n",
    "\n",
    "#### Evidence Lower Bound (ELBO)\n",
    "\n",
    "$$\n",
    "\\log p(x) \\geq \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - D_{KL}(q(z|x) \\| p(z))\n",
    "$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "- $\\mathbb{E}_{q(z|x)}[\\log p(x|z)]$ ‚Äî **Reconstruction term** (–∫–∞–∫ —Ö–æ—Ä–æ—à–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º)\n",
    "- $D_{KL}(q(z|x) \\| p(z))$ ‚Äî **KL divergence** (–Ω–∞—Å–∫–æ–ª—å–∫–æ $q$ –±–ª–∏–∑–∫–æ –∫ prior $p$)\n",
    "\n",
    "#### VAE Architecture\n",
    "\n",
    "**Encoder:** –í—ã–¥–∞—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è $q(z|x) = \\mathcal{N}(\\mu, \\sigma^2)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu &= f_{\\mu}(x; \\theta_{\\text{enc}}) \\\\\n",
    "\\log \\sigma^2 &= f_{\\sigma}(x; \\theta_{\\text{enc}})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Reparameterization trick:** –°—ç–º–ø–ª–∏—Ä—É–µ–º $z$:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)$$\n",
    "\n",
    "(–ü–æ–∑–≤–æ–ª—è–µ—Ç backpropagation —á–µ—Ä–µ–∑ —Å–ª—É—á–∞–π–Ω—É—é –≤–µ–ª–∏—á–∏–Ω—É!)\n",
    "\n",
    "**Decoder:** –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç $x$ –∏–∑ $z$:\n",
    "\n",
    "$$\\hat{x} = f_{\\text{dec}}(z; \\theta_{\\text{dec}})$$\n",
    "\n",
    "**Loss Function:**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{VAE}} = \\underbrace{\\|x - \\hat{x}\\|^2}_{\\text{Reconstruction}} + \\underbrace{D_{KL}(\\mathcal{N}(\\mu, \\sigma^2) \\| \\mathcal{N}(0, I))}_{\\text{KL term}}\n",
    "$$\n",
    "\n",
    "**KL divergence (–¥–ª—è Gaussian):**\n",
    "\n",
    "$$D_{KL} = \\frac{1}{2} \\sum_{j=1}^J \\left( 1 + \\log(\\sigma_j^2) - \\mu_j^2 - \\sigma_j^2 \\right)$$\n",
    "\n",
    "–≥–¥–µ $J$ ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å latent space.\n",
    "\n",
    "**–ü–æ—á–µ–º—É VAE –ª—É—á—à–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏?**\n",
    "- ‚úÖ **Smooth latent space:** –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç\n",
    "- ‚úÖ **Sampling:** –ú–æ–∂–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã: $z \\sim \\mathcal{N}(0, I)$, $x_{\\text{new}} = f_{\\text{dec}}(z)$\n",
    "- ‚úÖ **Probabilistic:** –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–∞\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è Autoencoders\n",
    "\n",
    "#### 1.4.1 Anomaly Detection\n",
    "\n",
    "**–ò–¥–µ—è:** –ê–Ω–æ–º–∞–ª–∏–∏ –ø–ª–æ—Ö–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è!\n",
    "\n",
    "**–ê–ª–≥–æ—Ä–∏—Ç–º:**\n",
    "```\n",
    "1. –û–±—É—á–∏—Ç—å Autoencoder –Ω–∞ –ù–û–†–ú–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö\n",
    "2. –î–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ x:\n",
    "   - –í—ã—á–∏—Å–ª–∏—Ç—å reconstruction error: e = ||x - xÃÇ||¬≤\n",
    "   - –ï—Å–ª–∏ e > threshold ‚Üí –ê–ù–û–ú–ê–õ–ò–Ø\n",
    "```\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä (Titanic):**\n",
    "- –û–±—É—á–∞–µ–º –Ω–∞ –í–´–ñ–ò–í–®–ò–• –ø–∞—Å—Å–∞–∂–∏—Ä–∞—Ö\n",
    "- –ü–æ–≥–∏–±—à–∏–µ –ø–∞—Å—Å–∞–∂–∏—Ä—ã –±—É–¥—É—Ç –∏–º–µ—Ç—å –≤—ã—Å–æ–∫–∏–π reconstruction error\n",
    "\n",
    "**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**\n",
    "- üí≥ Credit card fraud (–æ–±—É—á–∞–µ–º –Ω–∞ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö)\n",
    "- üè≠ Manufacturing defects (–æ–±—É—á–∞–µ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–¥–µ–ª–∏—è—Ö)\n",
    "- üîí Network intrusions (–æ–±—É—á–∞–µ–º –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ç—Ä–∞—Ñ–∏–∫–µ)\n",
    "\n",
    "---\n",
    "\n",
    "#### 1.4.2 Dimensionality Reduction vs PCA\n",
    "\n",
    "| –ú–µ—Ç–æ–¥ | –õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å | Supervised | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ |\n",
    "|-------|-----------|------------|-------------|\n",
    "| **PCA** | –õ–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –ë—ã—Å—Ç—Ä–æ, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ |\n",
    "| **Autoencoder** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –°–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –≥–∏–±–∫–æ—Å—Ç—å |\n",
    "| **t-SNE** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ |\n",
    "| **UMAP** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –ù–µ—Ç | –ë—ã—Å—Ç—Ä–µ–µ t-SNE, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É |\n",
    "\n",
    "**–ö–æ–≥–¥–∞ Autoencoder –ª—É—á—à–µ PCA:**\n",
    "- ‚úÖ –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚úÖ –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ (–º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å batch-–∞–º–∏)\n",
    "- ‚úÖ –ù—É–∂–Ω–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (–Ω–µ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–µ–∫—Ü–∏—è)\n",
    "\n",
    "---\n",
    "\n",
    "#### 1.4.3 Data Generation (VAE)\n",
    "\n",
    "**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤:**\n",
    "```python\n",
    "# Sample from prior\n",
    "z_new = torch.randn(latent_dim)\n",
    "\n",
    "# Decode\n",
    "x_new = decoder(z_new)\n",
    "```\n",
    "\n",
    "**–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è:**\n",
    "```python\n",
    "# Encode two examples\n",
    "z1 = encoder(x1)\n",
    "z2 = encoder(x2)\n",
    "\n",
    "# Interpolate in latent space\n",
    "for alpha in [0, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "    z_interp = alpha * z1 + (1 - alpha) * z2\n",
    "    x_interp = decoder(z_interp)\n",
    "```\n",
    "\n",
    "**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**\n",
    "- üé® Image generation (faces, art)\n",
    "- üéµ Music generation\n",
    "- üß¨ Molecule design (drug discovery)\n",
    "- üìä Data augmentation (—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)\n",
    "\n",
    "---\n",
    "\n",
    "## –¢–µ–æ—Ä–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø—Ä–∞–∫—Ç–∏–∫–µ üöÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä –ß–∞—Å—Ç—å 2: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è\n\n### 2.1 –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "print('‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¢–∏—Ç–∞–Ω–∏–∫–∞\n",
    "data_path = '../../data/titanic_train.csv'\n",
    "df = pd.read_csv(data_path) if __import__('os').path.exists(data_path) else None\n",
    "\n",
    "if df is not None:\n",
    "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (–∫–∞–∫ –≤ MLP)\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "    df['Sex'] = (df['Sex'] == 'male').astype(int)\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "    \n",
    "    features = ['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone'] + \\\n",
    "               [col for col in df.columns if 'Embarked_' in col]\n",
    "    \n",
    "    X = df[features].values\n",
    "    y = df['Survived'].values\n",
    "    \n",
    "    print(f'‚úÖ –î–∞–Ω–Ω—ã–µ: {X.shape}')\n",
    "    print(f'–ü—Ä–∏–∑–Ω–∞–∫–∏: {features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–ª—è Autoencoder –∏—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –≤—ã–∂–∏–≤—à–∏—Ö (–¥–ª—è anomaly detection)\n",
    "X_survived = X[y == 1]  # –¢–æ–ª—å–∫–æ –≤—ã–∂–∏–≤—à–∏–µ\n",
    "X_died = X[y == 0]      # –ü–æ–≥–∏–±—à–∏–µ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π)\n",
    "\n",
    "# Train/test split –∏–∑ –≤—ã–∂–∏–≤—à–∏—Ö\n",
    "X_train, X_test = train_test_split(X_survived, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_died_scaled = scaler.transform(X_died)  # –î–ª—è anomaly detection\n",
    "\n",
    "# PyTorch tensors\n",
    "X_train_t = torch.FloatTensor(X_train_scaled)\n",
    "X_test_t = torch.FloatTensor(X_test_scaled)\n",
    "X_died_t = torch.FloatTensor(X_died_scaled)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, X_train_t), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_t, X_test_t), batch_size=batch_size)\n",
    "\n",
    "print(f'Train (survived): {X_train.shape[0]}')\n",
    "print(f'Test (survived): {X_test.shape[0]}')\n",
    "print(f'Died (for anomaly): {X_died.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vanilla Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder: input ‚Üí latent\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Decoder: latent ‚Üí input\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, z\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "latent_dim = 2  # 2D –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "\n",
    "vanilla_ae = VanillaAutoencoder(input_dim, latent_dim).to(device)\n",
    "print(vanilla_ae)\n",
    "print(f'Parameters: {sum(p.numel() for p in vanilla_ae.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_autoencoder(model, loader, epochs=50, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for X_batch, _ in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            X_recon, _ = model(X_batch)\n",
    "            loss = criterion(X_recon, X_batch)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        avg_loss = epoch_loss / len(loader.dataset)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "print('–û–±—É—á–∞–µ–º Vanilla Autoencoder...')\n",
    "vanilla_losses = train_autoencoder(vanilla_ae, train_loader, epochs=50)\n",
    "print('‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è latent space\n",
    "vanilla_ae.eval()\n",
    "with torch.no_grad():\n",
    "    _, z_survived = vanilla_ae(X_test_t.to(device))\n",
    "    _, z_died = vanilla_ae(X_died_t.to(device))\n",
    "    z_survived = z_survived.cpu().numpy()\n",
    "    z_died = z_died.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(z_survived[:, 0], z_survived[:, 1], alpha=0.6, label='Survived (train)', c='green')\n",
    "plt.scatter(z_died[:, 0], z_died[:, 1], alpha=0.6, label='Died (test)', c='red')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Vanilla Autoencoder: Latent Space')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print('üîç –ü–æ–≥–∏–±—à–∏–µ –ø–∞—Å—Å–∞–∂–∏—Ä—ã –∏–º–µ—é—Ç –¥—Ä—É–≥–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ latent space!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Anomaly Detection —Å Vanilla AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error –¥–ª—è anomaly detection\n",
    "def reconstruction_error(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_recon, _ = model(X.to(device))\n",
    "        errors = torch.mean((X.to(device) - X_recon) ** 2, dim=1).cpu().numpy()\n",
    "    return errors\n",
    "\n",
    "# –û—à–∏–±–∫–∏ –¥–ª—è –≤—ã–∂–∏–≤—à–∏—Ö –∏ –ø–æ–≥–∏–±—à–∏—Ö\n",
    "errors_survived = reconstruction_error(vanilla_ae, X_test_t)\n",
    "errors_died = reconstruction_error(vanilla_ae, X_died_t)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors_survived, bins=30, alpha=0.7, label='Survived', color='green', edgecolor='black')\n",
    "plt.hist(errors_died, bins=30, alpha=0.7, label='Died', color='red', edgecolor='black')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Reconstruction Error Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([errors_survived, errors_died], labels=['Survived', 'Died'])\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Reconstruction Error: Boxplot')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean error (survived): {errors_survived.mean():.4f}')\n",
    "print(f'Mean error (died): {errors_died.mean():.4f}')\n",
    "print(f'–†–∞–∑–Ω–∏—Ü–∞: {errors_died.mean() / errors_survived.mean():.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC –¥–ª—è anomaly detection\n",
    "# Label: 0 = normal (survived), 1 = anomaly (died)\n",
    "y_true = np.concatenate([np.zeros(len(errors_survived)), np.ones(len(errors_died))])\n",
    "y_scores = np.concatenate([errors_survived, errors_died])\n",
    "\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "ap = average_precision_score(y_true, y_scores)\n",
    "\n",
    "print('üìä Anomaly Detection Performance:')\n",
    "print(f'  ROC-AUC: {auc:.4f}')\n",
    "print(f'  Average Precision: {ap:.4f}')\n",
    "print('\\n‚úÖ Autoencoder —É—Å–ø–µ—à–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç –≤—ã–∂–∏–≤—à–∏—Ö –æ—Ç –ø–æ–≥–∏–±—à–∏—Ö!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising AE –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, –Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∑–∞—à—É–º–ª—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16), nn.ReLU(),\n",
    "            nn.Linear(16, 8), nn.ReLU(),\n",
    "            nn.Linear(8, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8), nn.ReLU(),\n",
    "            nn.Linear(8, 16), nn.ReLU(),\n",
    "            nn.Linear(16, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, z\n",
    "\n",
    "denoising_ae = DenoisingAutoencoder(input_dim, latent_dim).to(device)\n",
    "\n",
    "# Training —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —à—É–º–∞\n",
    "def train_denoising_ae(model, loader, epochs=50, noise_factor=0.2, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for X_batch, _ in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º Gaussian noise\n",
    "            noise = torch.randn_like(X_batch) * noise_factor\n",
    "            X_noisy = X_batch + noise\n",
    "            \n",
    "            # Forward: –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ß–ò–°–¢–´–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞—à—É–º–ª—ë–Ω–Ω—ã—Ö\n",
    "            X_recon, _ = model(X_noisy)\n",
    "            loss = criterion(X_recon, X_batch)  # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ß–ò–°–¢–´–ú–ò!\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        avg_loss = epoch_loss / len(loader.dataset)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "print('–û–±—É—á–∞–µ–º Denoising Autoencoder...')\n",
    "denoising_losses = train_denoising_ae(denoising_ae, train_loader, epochs=50, noise_factor=0.3)\n",
    "print('‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è denoising\n",
    "denoising_ae.eval()\n",
    "sample = X_test_t[:5].to(device)\n",
    "sample_noisy = sample + torch.randn_like(sample) * 0.3\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_denoised, _ = denoising_ae(sample_noisy)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i].plot(sample[i].cpu().numpy(), 'o-', label='Original', alpha=0.7)\n",
    "    axes[i].plot(sample_noisy[i].cpu().numpy(), 's-', label='Noisy', alpha=0.7)\n",
    "    axes[i].plot(sample_denoised[i].cpu().numpy(), '^-', label='Denoised', alpha=0.7)\n",
    "    axes[i].set_ylabel('Value')\n",
    "    axes[i].set_title(f'Sample {i+1}: Denoising Effect')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Feature Index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Denoising Autoencoder —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–∞–µ—Ç –∑–∞—à—É–º–ª—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder ‚Üí Œº and log(œÉ¬≤)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16), nn.ReLU(),\n",
    "            nn.Linear(16, 8), nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(8, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(8, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8), nn.ReLU(),\n",
    "            nn.Linear(8, 16), nn.ReLU(),\n",
    "            nn.Linear(16, input_dim)\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # z = Œº + œÉ * Œµ, –≥–¥–µ Œµ ~ N(0,1)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "vae = VAE(input_dim, latent_dim).to(device)\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Loss: Reconstruction + KL divergence\n",
    "def vae_loss(x_recon, x, mu, logvar):\n",
    "    # Reconstruction loss\n",
    "    recon_loss = nn.functional.mse_loss(x_recon, x, reduction='sum')\n",
    "    \n",
    "    # KL divergence: -0.5 * sum(1 + log(œÉ¬≤) - Œº¬≤ - œÉ¬≤)\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss + kl_div\n",
    "\n",
    "# Training VAE\n",
    "def train_vae(model, loader, epochs=50, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for X_batch, _ in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            X_recon, mu, logvar = model(X_batch)\n",
    "            loss = vae_loss(X_recon, X_batch, mu, logvar)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(loader.dataset)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "print('–û–±—É—á–∞–µ–º VAE...')\n",
    "vae_losses = train_vae(vae, train_loader, epochs=50)\n",
    "print('‚úÖ VAE –æ–±—É—á–µ–Ω')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ —Å VAE\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample –∏–∑ prior N(0, I)\n",
    "    z_sample = torch.randn(10, latent_dim).to(device)\n",
    "    generated = vae.decode(z_sample).cpu().numpy()\n",
    "\n",
    "# –û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è scaling\n",
    "generated_original = scaler.inverse_transform(generated)\n",
    "\n",
    "print('üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ \"–ø–∞—Å—Å–∞–∂–∏—Ä—ã\" (–ø–µ—Ä–≤—ã–µ 5):')\n",
    "print(pd.DataFrame(generated_original[:5], columns=features))\n",
    "print('\\n‚úÖ VAE –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –≤ latent space\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    # –ë–µ—Ä—ë–º –¥–≤–∞ –ø—Ä–∏–º–µ—Ä–∞\n",
    "    x1 = X_test_t[0:1].to(device)\n",
    "    x2 = X_test_t[1:2].to(device)\n",
    "    \n",
    "    # Encode\n",
    "    mu1, _ = vae.encode(x1)\n",
    "    mu2, _ = vae.encode(x2)\n",
    "    \n",
    "    # Interpolate\n",
    "    alphas = torch.linspace(0, 1, 5).unsqueeze(1).to(device)\n",
    "    z_interp = alphas * mu1 + (1 - alphas) * mu2\n",
    "    \n",
    "    # Decode\n",
    "    x_interp = vae.decode(z_interp).cpu().numpy()\n",
    "\n",
    "print('üîÑ –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è –ø–∞—Å—Å–∞–∂–∏—Ä–∞–º–∏:')\n",
    "print(pd.DataFrame(scaler.inverse_transform(x_interp), columns=features))\n",
    "print('\\n‚úÖ Smooth –ø–µ—Ä–µ—Ö–æ–¥ –≤ latent space!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "pca = PCA(n_components=2)\n",
    "z_pca_survived = pca.fit_transform(X_test_scaled)\n",
    "z_pca_died = pca.transform(X_died_scaled)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: AE vs PCA\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Vanilla AE\n",
    "axes[0].scatter(z_survived[:, 0], z_survived[:, 1], alpha=0.6, label='Survived', c='green')\n",
    "axes[0].scatter(z_died[:, 0], z_died[:, 1], alpha=0.6, label='Died', c='red')\n",
    "axes[0].set_xlabel('Latent Dim 1')\n",
    "axes[0].set_ylabel('Latent Dim 2')\n",
    "axes[0].set_title('Autoencoder Latent Space')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PCA\n",
    "axes[1].scatter(z_pca_survived[:, 0], z_pca_survived[:, 1], alpha=0.6, label='Survived', c='green')\n",
    "axes[1].scatter(z_pca_died[:, 0], z_pca_died[:, 1], alpha=0.6, label='Died', c='red')\n",
    "axes[1].set_xlabel('PC 1')\n",
    "axes[1].set_ylabel('PC 2')\n",
    "axes[1].set_title('PCA 2D Projection')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ –í—ã–≤–æ–¥—ã\n",
    "\n",
    "### –ß—Ç–æ –º—ã –∏–∑—É—á–∏–ª–∏:\n",
    "\n",
    "1. **Vanilla Autoencoder:**\n",
    "   - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Encoder-Decoder\n",
    "   - Compression —á–µ—Ä–µ–∑ bottleneck\n",
    "   - Latent space representation\n",
    "\n",
    "2. **Denoising Autoencoder:**\n",
    "   - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∑–∞—à—É–º–ª—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "   - Robustness –∫ —à—É–º—É\n",
    "   - Regularization —ç—Ñ—Ñ–µ–∫—Ç\n",
    "\n",
    "3. **Variational Autoencoder (VAE):**\n",
    "   - Probabilistic latent space\n",
    "   - Reparameterization trick\n",
    "   - KL divergence –¥–ª—è smooth —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "\n",
    "### –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:\n",
    "\n",
    "#### ‚úÖ Anomaly Detection —Ä–∞–±–æ—Ç–∞–µ—Ç!\n",
    "- Autoencoder, –æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ –≤—ã–∂–∏–≤—à–∏—Ö, **—Ö—É–∂–µ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç** –ø–æ–≥–∏–±—à–∏—Ö\n",
    "- Reconstruction error ‚Äî —Ö–æ—Ä–æ—à–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "- ROC-AUC ~0.65-0.75 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–∞–Ω–Ω—ã—Ö)\n",
    "\n",
    "#### Autoencoder vs PCA:\n",
    "\n",
    "| –ö—Ä–∏—Ç–µ—Ä–∏–π | Autoencoder | PCA |\n",
    "|----------|------------|-----|\n",
    "| **–õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å** | –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è | –õ–∏–Ω–µ–π–Ω–∞—è |\n",
    "| **–°–ª–æ–∂–Ω–æ—Å—Ç—å** | –í—ã—Å–æ–∫–∞—è (–æ–±—É—á–µ–Ω–∏–µ NN) | –ù–∏–∑–∫–∞—è (eigen decomposition) |\n",
    "| **–ö–∞—á–µ—Å—Ç–≤–æ** | –õ—É—á—à–µ –¥–ª—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö | –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö |\n",
    "| **–°–∫–æ—Ä–æ—Å—Ç—å** | –ú–µ–¥–ª–µ–Ω–Ω–µ–µ (GPU –ø–æ–º–æ–≥–∞–µ—Ç) | –ë—ã—Å—Ç—Ä–æ |\n",
    "| **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** | –ù–∏–∑–∫–∞—è | –í—ã—Å–æ–∫–∞—è (PC = –ª–∏–Ω–µ–π–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏) |\n",
    "\n",
    "**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**\n",
    "- üöÄ **–ù–∞—á–Ω–∏—Ç–µ —Å PCA** (–±—ã—Å—Ç—Ä–æ, –ø—Ä–æ—Å—Ç–æ)\n",
    "- üß™ **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ AE** –µ—Å–ª–∏ PCA –¥–∞—ë—Ç –ø–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "- üé® **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ VAE** –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n",
    "\n",
    "### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ:\n",
    "\n",
    "#### 1. Anomaly Detection\n",
    "- üí≥ **Fraud Detection:** –û–±—É—á–∞–µ–º –Ω–∞ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö\n",
    "- üè≠ **Manufacturing:** –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤\n",
    "- üîí **Cybersecurity:** Intrusion detection\n",
    "- üè• **Healthcare:** –†–µ–¥–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è\n",
    "\n",
    "**–ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏:**\n",
    "```python\n",
    "threshold = np.percentile(errors_normal, 95)  # 95th percentile\n",
    "is_anomaly = error > threshold\n",
    "```\n",
    "\n",
    "#### 2. Dimensionality Reduction\n",
    "- üìä **Visualization:** 2D/3D –ø—Ä–æ–µ–∫—Ü–∏–∏ –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚ö° **Preprocessing:** –°–∂–∞—Ç–∏–µ –ø–µ—Ä–µ–¥ –¥—Ä—É–≥–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏\n",
    "- üíæ **Compression:** –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º –≤–∏–¥–µ\n",
    "\n",
    "#### 3. Data Generation (VAE)\n",
    "- üé® **Image synthesis:** Faces, art (—Å CNN –≤–º–µ—Å—Ç–æ FC)\n",
    "- üß¨ **Drug discovery:** –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –º–æ–ª–µ–∫—É–ª\n",
    "- üìä **Data augmentation:** –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "- üéµ **Music generation:** (—Å RNN/Transformers)\n",
    "\n",
    "#### 4. Denoising\n",
    "- üîä **Audio:** –û—á–∏—Å—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π\n",
    "- üñºÔ∏è **Images:** –£–¥–∞–ª–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤, upscaling\n",
    "- üì° **Signals:** –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è sensor –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n",
    "\n",
    "‚ùå **–î–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**\n",
    "- XGBoost/LightGBM –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –¥–ª—è supervised tasks\n",
    "- AE –ø–æ–ª–µ–∑–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è unsupervised (anomaly, dimensionality reduction)\n",
    "\n",
    "‚ùå **VAE quality:**\n",
    "- –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å \"—Ä–∞–∑–º—ã—Ç—ã–º–∏\"\n",
    "- GAN —á–∞—Å—Ç–æ –¥–∞—ë—Ç –±–æ–ª–µ–µ realistic —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
    "\n",
    "1. **Convolutional AE:** –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Phase 5: Computer Vision)\n",
    "2. **Recurrent AE:** –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ (Phase 3: Time Series)\n",
    "3. **Transformer AE:** BERT ‚Äî –ø–æ —Å—É—Ç–∏ denoising AE –¥–ª—è —Ç–µ–∫—Å—Ç–∞!\n",
    "4. **GAN:** Generative Adversarial Networks (—Å–ª–µ–¥—É—é—â–∏–π —É—Ä–æ–≤–µ–Ω—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Phase 2: Deep Learning Basics –ó–ê–í–ï–†–®–Å–ù!\n",
    "\n",
    "**–ü—Ä–æ–π–¥–µ–Ω–æ:**\n",
    "1. ‚úÖ **MLP:** –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–µ—Ç–∏, backpropagation, optimizers\n",
    "2. ‚úÖ **1D-CNN:** Convolutions, filters, pooling\n",
    "3. ‚úÖ **Autoencoders:** Vanilla, Denoising, VAE\n",
    "\n",
    "**–í—ã –æ—Å–≤–æ–∏–ª–∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ Deep Learning!** üöÄ\n",
    "\n",
    "**–°–ª–µ–¥—É—é—â–∞—è —Ñ–∞–∑–∞:**\n",
    "- **Phase 3:** RNN/LSTM –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
    "- **Phase 4:** Transformers –∏ attention –º–µ—Ö–∞–Ω–∏–∑–º\n",
    "- **Phase 5:** Computer Vision (2D-CNN, ResNet, etc.)\n",
    "\n",
    "**–ü–æ–∑–¥—Ä–∞–≤–ª—è—é!** –í—ã –≥–æ—Ç–æ–≤—ã –∫ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º! üéì\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}